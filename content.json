{"meta":{"title":"Xiao's Blog","subtitle":"生命太短暂，不要去做一些根本没有人想要的东西。","description":"当你选择了一种语言，意味着你还选择了一组技术、一个社区","author":"任重道远","url":"http://yoursite.com"},"pages":[{"title":"标签","date":"2018-10-24T07:20:20.000Z","updated":"2018-10-24T07:23:31.193Z","comments":true,"path":"tags/index.html","permalink":"http://yoursite.com/tags/index.html","excerpt":"","text":""},{"title":"关于","date":"2018-05-17T09:03:49.000Z","updated":"2019-12-23T03:05:01.450Z","comments":true,"path":"about/index.html","permalink":"http://yoursite.com/about/index.html","excerpt":"","text":"不善言辞的宅男码农一枚"},{"title":"分类","date":"2018-10-24T07:17:04.000Z","updated":"2018-10-24T07:18:21.919Z","comments":true,"path":"categories/index.html","permalink":"http://yoursite.com/categories/index.html","excerpt":"","text":""}],"posts":[{"title":"mysql基础","slug":"mysql-base","date":"2020-05-02T01:06:48.000Z","updated":"2020-05-02T01:26:55.218Z","comments":true,"path":"Mysql/mysql-base.html","link":"","permalink":"http://yoursite.com/Mysql/mysql-base.html","excerpt":"mysql逻辑架构","text":"mysql逻辑架构 连接器连接器负责和客户端建立连接，获取权限，维持和管理连接。连接命令：mysql -h$ip -P$port -u$user -p 查询缓存mysql会缓存一些查询，下次查询如果命中就可以直接返回。但是我们不建议使用查询缓存，因为对一个表的任何更新操作都会使该表的缓存失效。mysql8.0已经删掉这个功能了。 分析器分析器对sql语句进行解析。首先是词法分析：将关键字以及表名列名等识别出来；之后是语法分析：判断这个sql语句是否满足mysql语法。 优化器优化器一般是在有多个索引时，决定使用哪个索引，或者关键查询时，决定连接顺序； 执行器执行器是调用存储引擎接口来执行语句获取结果。执行之前会判断对该表是否有权限，如果有权限，就打开表，根据存储引擎提供的接口，扫描数据行获取结果集返回。 redo log和binlogWAL（Write-Ahead Logging）：先写日志，再写磁盘。mysql更新数据时，会写入redo log和binlog，并更新内存，这样一个更新就算完成了，等系统空闲或者需要的时候再将内存中数据刷回磁盘。虽然写redo log和binlog也会刷盘，但是是顺序写，效率很高。 redo log：innodb特有的，物理日志，记录的是某个页上修改了什么内容。redolog是固定大小的（这个大小可以配置），所以是循环写入的。write pos记录的是redolog中当前写入的位置，check point记录的是要擦除的位置。每次擦除时需要将数据刷到磁盘中。redolog保证了mysql异常重启，之前提交的记录也不会丢失，这个能力成为crash-safe。 binlog：mysql server层提供的。主要作用是主从复制以及恢复数据。binlog有三种形式：statement，row，mixed。statement格式记录的就是sql语句，row格式会记录行的内容，记两条，更新前后都有。mixed其实就是前面两种的结合，mysql会根据不同场景选用前面的两种格式。 redolog和binlog的不同点： redolog是innodb引擎特有的，binlog是server层提供的，所有引擎都可以使用。 redolog是物理日志，记录的是某个数据页做了什么修改。binlog是逻辑日志，记录的是这个语句的原始逻辑。 redolog是循环写的，写完了又会从头开始写。binlog是追加写，写完一个文件之后会重新开一个文件写入。 根据上图我们介绍下mysql innodb引擎更新过程： 首先根据条件取出要更新的行，如果在内存中，则直接返回，不再内存中则从磁盘中读取再返回。 对数据进行更新，然后更新到内存。 redo log和binlog的写入采用两阶段提交。首先innodb引擎写入redolog，并且处于prepare阶段。 然后server层执行器写binlog，并把binlog写入磁盘。 innodb将之前的prepare状态的redolog提交，更新完成。 这里redolog和binlog采用两阶段提交，可以保证一致性。假设数据库宕机，当数据库恢复后。遍历prepare状态的redolog，根据事务id找binlog，如果binlog没有写入，则回滚这条redolog，如果binlog已经写入，则提交这条redolog。 事务与事务隔离级别事务四个特性：ACID（原子性，一致性，隔离性，持久性） 隔离级别：当数据库有多个事务同时执行时，就会有可能出现脏读，不可重复读，幻读等问题。为了解决这些问题，就需要引入隔离级别的概念。 读未提交（read-uncommitted）：一个事务可以读到其他事务未提交的数据。 读提交（read-committed）：一个事务只能读取别的事务已经提交的数据。 可重复读（repeatable-read）：一个事务执行过程中看到的数据，总和事务启动时的一致。 串行化（serializable）：事务都是串行执行，事务在读写一行数据时会加锁，其他事务只能等待获取锁。 上面四个重点理解中间两个隔离级别就行。读提交级别会读取到别的事务已经提交的数据，这样就有可能造成前后两次读取的数据不一致，造成不可重复读问题。可重复读保证了事务中读取到的数据一致， 事务隔离实现在实现上，数据库会创建一个视图，在访问数据时以视图为准。在可重复读级别下，这个视图是在事务启动时创建的，整个事务过程中都会使用这个视图。在读提交级别下，这个视图是在每个sql语句执行时创建的。 在mysql中，数据库会为每条sql更新语句记录一条对应的undo log。通过undo log可以找到前面版本的数据，这样同一条记录在数据库中就存在多个版本，这就是数据库的多版本并发控制（MVCC）。可重复读会使用事务开启时数据的read-view版本，读提交使用sql执行时的数据read-view版本。 当系统中没有比undo log更早的read-view时，这时候undo log会删除。所以我们程序中尽量不要使用长事务，否则undo log有可能保存很久。 索引索引常见模型：1.哈希表：适合只有等值查询的场景 2.有序数组：在等值查询查询和范围查询场景中性能都不错，但是更新成本太高，只适合静态存储引擎。 3.搜索树：二叉搜索树在查询和更新都是O(logN)，但是二叉搜索树在存储大量数据时，树的高度会很高，而且索引数据不可能全部存在内存中，需要存到磁盘中，这个时候就会导致多次磁盘IO。所以数据库索引一般使用N叉搜索树，也就是B+树。 Innodb索引模型Innodb使用B+树存储索引，B+树中非叶子节点存储的是索引，所有数据都是存储在最下面一层的叶子节点。 Innodb数据是以页为单位存储的，一个页大小默认是16K。按照bigint的8字节，加上指针6字节，一个索引页存储的索引树大概是161024/（8+6）=1170。按照一行数据1k，一个数据页大概可以存储16行数据。这样一颗高度为3的B+树就可以存储11701170*16（2千多万）的数据，这样访问一条数据最多也就需要3次磁盘IO，所以B+ 树能够很好地配合磁盘的读写特性，减少单次查询的磁盘访问次数。 在插入和删除时，为了维护索引的有序，需要对B+树进行维护。具体插入删除操作就不介绍了。这个操作具体到页上就是当一个页满了之后，需要申请新的页，将数据移动到新的页，这个叫做页分裂，会影响到性能，同时也会影响页的利用率。当然有分裂就有合并，删除数据时，相邻两个页如果页利用率很低，就会进行合并操作。基于上面的维护过程，我们一般建议数据库表主键定义为自增主键，这样每次新增一条记录时，都是追加操作，不会涉及挪动其他数据。 索引分类 基于叶子存储的数据可以分成主键索引和非主键索引。主键索引叶子节点存储的是整行数据，非主键索引存储的是索引和主键的对应关系。通过主键索引查询数据时直接在主键索 引树上搜索就可以了。通过非主键索引查询数据时，由于非主键索引树存储的只是关键字和主键的关系，所以需要再到主键索引树上搜索数据，这个过程就称为回表。 上面我们知道通过非主键索引查询时一般需要回表，那有没有可能不需要回表。答案就是覆盖索引，如果我们查询的字段是非主键索引包含的字段或者主键时，这个时候就不需要回表，直接返回。由于覆盖索引可以减少树的搜索次数，显著提升查询性能，所以使用覆盖索引是一个常用的性能优化手段。 最左前缀原则如果查询是根据联合索引的最左N个字段或者是根据字符串索引的最左M个字符来查询，这个时候查询就能根据最左前缀原则使用索引来查询。 联合索引中，如果中间某个字段是通过in或者&gt;、&lt;等来查询，则后面的字段使用不上索引了。如下：有一个联合索引index(a,b,c)，只能使用索引上的ab字段。select * from t where a=1 and b&gt;2 and c=3; 索引下推就拿上面的例子来说，由于只能使用索引的ab字段，假如根a=1 and b&gt;2的条件查询到100条数据，其中c=3的有20条，c!=3的有80条。在mysql5.6之前，只能将这100条数据回表，在主键索引上一条条查询，判断c是否等于3。而在mysql5.6之后，引入了索引下推的优化，可以在遍历联合索引树中就会对c!=3的数据进行过滤，过滤之后剩20条，再对这20条进行回表查询。 锁根据加锁范围，mysql的锁可以分成三类：全局锁，表级锁，行级锁。 全局锁全局锁就是对整个数据库实例加锁，mysql提供一个加全局读锁的方法，命令是Flush table with read lock（FTWRL）。使用这个命令之后，数据库更新语句（增删改），数据库定义语句（建表修改表等）和更新类事务提交语句都会被阻塞。 全局锁使用的典型场景就是做全库数据备份。使用FTWRL是防止备份过程中数据被修改了，但是我们使用innodb时，由于事务隔离级别时可重复读，我们可以在备份时开启一个事务，这样就有一个全局一致性的视图，后面的更新对备份操作没有影响。具体命令就是使用mysqldump ，带上参数–single-transaction。 表级锁表级锁分为两种，一种是表锁，一种是元数据锁（meta data lock，MDL）。表锁一般就是lock tables … read/rewrite 。不过innodb支持行级锁，我们很少在innodb中会用到表锁。 另一种表级锁是MDL。MDL不需要显式使用，在对一个表进行增删改查时，会默认加上MDL读锁，对表结构进行修改时，会默认加上MDL写锁。读锁之间不互斥，读写锁或者写锁之间会互斥。 行级锁在innodb事务中，行锁是在需要的时候加上的，但是并不是使用完就立马释放，而是在事务结束之后才会释放，这就是两阶段锁协议。鉴于此，我们在事务中需要锁住多个行时，要把最有可能造成锁冲突，最有可能影响并发度的加锁操作放在最后。比如下单操作：1、生成订单；2、扣减账户金额；3、扣减商品库存。由于第三步最有可能造成锁冲突，我们需要把这个操作放在最后，减少加锁时间。 死锁和死锁检测当并发系统中不同线程出现循环资源依赖，涉及的线程都在等待别的线程释放资源时，就会导致这几个线程都进入无限等待的状态，称为死锁。 数据库出现死锁后，一般有两种策略：1、一个是直接等待，直到超时，这个超时时间是通过innodb_lock_wait_timeout参数设置，默认是50s；2、发起死锁检测，发现死锁后，主动回滚链条中的某个事务，让其他事务继续进行。将参数 innodb_deadlock_detect 设置为 on，表示开启这个逻辑。 主动死锁检测在发生死锁的时候能快速检测到死锁并处理，但是它也是有负担的。每个新来的被堵住的线程，都会判断会不会由于自己的加入导致死锁，这是一个时间复杂度O(n)的操作，假设有1000个并发同时来更新一行数据，那么死锁检测操作的量级就是100万，虽然最后检测是没有死锁，这期间也耗费了大量CPU资源。","categories":[{"name":"Mysql","slug":"Mysql","permalink":"http://yoursite.com/categories/Mysql/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"http://yoursite.com/tags/mysql/"}],"keywords":[{"name":"Mysql","slug":"Mysql","permalink":"http://yoursite.com/categories/Mysql/"}]},{"title":"Mysql查询性能优化","slug":"mysql-optimization","date":"2020-02-20T01:47:02.000Z","updated":"2020-02-23T04:58:31.871Z","comments":true,"path":"Mysql/mysql-optimization.html","link":"","permalink":"http://yoursite.com/Mysql/mysql-optimization.html","excerpt":"为什么查询会慢如果把查询看作是一个任务，那么它由一系列子任务组成，每个子任务都会消耗一定时间。如果要优化查询，实际上是优化其子任务，要么消除其中一些子任务，要么减少子任务的执行次数，要么让子任务执行更快。 查询的生命周期大致可以分为：从客户端，到服务器，然后在服务器上进行解析，生成执行计划，执行，并返回结果给客户端。在完成这些任务的时候，查询需要在不同 的地方花费时间，包括网络，CPU计算，生成统计信息和执行计划，锁等待，互斥等待等操作，尤其是像底层存储引擎检索数据的调用操作，这些调用需要在内存操作，CPU操作和内存不足时导致的I/O操作上消耗时间。根据存储引擎不同，可能还会产生大量的上下文切换以及系统调用。","text":"为什么查询会慢如果把查询看作是一个任务，那么它由一系列子任务组成，每个子任务都会消耗一定时间。如果要优化查询，实际上是优化其子任务，要么消除其中一些子任务，要么减少子任务的执行次数，要么让子任务执行更快。 查询的生命周期大致可以分为：从客户端，到服务器，然后在服务器上进行解析，生成执行计划，执行，并返回结果给客户端。在完成这些任务的时候，查询需要在不同 的地方花费时间，包括网络，CPU计算，生成统计信息和执行计划，锁等待，互斥等待等操作，尤其是像底层存储引擎检索数据的调用操作，这些调用需要在内存操作，CPU操作和内存不足时导致的I/O操作上消耗时间。根据存储引擎不同，可能还会产生大量的上下文切换以及系统调用。 在每一个消耗大量时间的查询案列中，我们都能看到一些不必要的额外操作，某些操作被额外的重复了很多次，某一个操作执行的太慢等。优化查询的目的就是减少和消除这些操作所花费的时间。 优化数据访问避免请求不需要的数据有些查询会请求超过实际需要的数据，然后这些多余的数据会被应用程序丢弃，这会给Mysql服务器带来额外的负担，并增加网络开销，另外也会消耗应用服务器的CPU和内存资源。 避免查询不需要的记录：处理分页时，应该使用LIMIT限制MySql只返回一页的数据，而不是向应用程序返回全部数据后，再由应用程序过滤不需要的行。 避免查询全部列：使用SELECT *这种方式会返回全部列，但有时我们不需要这么多列，我们应该使用SELECT后面加具体的列名还查询需要的列。当然有时候返回更多列也不是坏事，因为这可以提高代码片段的复用性，可以简化开发，所以我们在实际开发中根据自己的需要可以适当返回更多的列。 避免多表关联时返回全部列：这个和第二点其实差不多，我们在多表关联查询时应指定需要返回的列，避免返回所有表的全部列。 避免重复查询相同的数据：我们有时会重复执行相同的查询，然后每次都返回相同的数据，这时我们可以在初次查询时将数据缓存起来，这样性能会更好。 避免扫描额外的记录分析查询时，查看改查询扫描的行数是非常有帮助的。理想情况下扫描的行数和返回的行数应该是相同的，但实际情况很难达到这种完美情况，通常扫描的行数和返回的行数比值在1:1和10:1之间。 在Explain语句中type列反应了访问类型，rows列反应了扫描的行数。访问的类型有很多种，从全表扫描到索引扫描，返回扫描，唯一索引扫描，常数引用等，这些的速度是从慢到快，扫描的行数也是从多到少。如果查询没有办法找到合适的访问类型，那么解决的最好办法通常就是增加一个合适的索引。 如果发现查询需要扫描大量的数据但只返回少数的行，可以通过尝试下面的技巧去优化它： 使用索引覆盖扫描，把所有需要用的列都放到索引中，这样存储引擎无须回表就可以返回结果。 改变库表结构。例如使用单独的汇总表。 重写这个复杂的查询，让Mysql优化器能够以更优化的方式执行这个查询。 重构查询的方式在优化有问题的查询时，目标应该是找到一个更有的方法获得实际需要的结果。此时我们可以将查询转换一种写法让其返回一样的结果，但是性能更好，也可以通过修改应用代码，用另一种方式完成查询，最终达到一样的目的。 切分查询有时候对于一个大查询我们需要分而治之，将大查询切分成小查询，每个查询功能完全一样，只完成一小部分，每次只返回一小部分查询结果。 删除旧的数据就是一个很好的例子。定期的清除大量数据时，如果用一个大的语句一次性完成的话，则可能需要一次锁住很多数据，占满整个事务日志，耗尽系统资源，阻塞很多小的但重要的查询。将一个大的delete语句切分成多个较小的查询可以尽可能小的影响Mysql性能，同时还可以减少Mysql复制的延迟。 分解关联查询很多高性能的应用都会对关联查询进行分解。简单地，可以对每一个表进行一次单表查询，然后将结果在应用程序中进行关联。例如，下面这个查询： 1234SELECT * FROM tag JOIN tag_post ON tag_post.tag_id=tag.id JOIN post ON tag_post.post_id=post.idWHERE tag.tag = &apos;mysql&apos;; 可以分解成下面这些查询来代替： 123SELECT * FROM tag WHERE tag = &apos;mysql&apos;;SELECT * FROM tag_post WHERE tag_id = 1234;SELECT * FROM post WHERE post.id in (123,456,567,9098,8904); 用分解关联查询的方式重构查询有如下优势： 让缓存效率更高。如果缓存的是关联表结果，如果关联中的某个表发生了变化，那么缓存就失效了，而拆分后，如果某个表变化，并不会影响所有的缓存。 将查询分解后，执行单个查询可以减少锁的竞争。 在应用层做关联，可以更容易对数据库进行拆分，更容易做到高性能和可扩展。 查询本身的效率也可能会有所提升。例如上面用IN()代替关联查询比随机的关联更加高效。 可以减少冗余记录的查询。在应用层做关联查询，意味着对某条记录应用只需要查询一次，而在数据库中做关联查询，则可能需要重复的访问一部分数据。 查询执行过程当希望Mysql能够以更高的性能运行查询时，最好的办法就是弄清楚Mysql是如何优化和执行查询的。Mysql的查询过程根据上图可知： 客户端发送一条查询给服务器。 服务器先检查查询缓存，如果命中了缓存，则立刻返回存储在缓存中的结果。否则进入下一阶段。 服务器进行SQL解析，预处理，再由优化器生成对应的执行计划。 Mysql根据生成的执行计划，调用存储引擎的API来执行查询。 将结果返回给客户端。 Mysql客户端服务器通信协议Mysql酷护短和服务器之间的通信协议是半双工的，这意味着，在任何一个时刻，要么是服务器向客户端发送数据，要么是客户端向服务器发送数据，这两个动作不能同时发生。这种协议让Mysql通信简单快速，但是也从很多地方限制了Mysql。一个明显的限制就是没发进行流量控制，一旦一端开始发送消息，另一端要接受完整个消息才能响应它。 查询缓存在解析一个查询语句前，如果查询缓存是打开的，Mysql会先检查这个查询是否命中缓存中的数据，这个检查是通过一个对大小写敏感的哈希查找实现的。命中了则直接返回结果，否则进行下一阶段处理。 查询优化处理查询的生命周期下一步是讲一个SQL转换成一个执行计划，Mysql再依照这个执行计划和存储引擎进行交互。这个阶段包含多个子阶段：解析SQL、预处理、优化SQL执行计划。 语法解析器和预处理首先Mysql通过关键字将SQL语句进行解析，并生成一颗对应的解析树。Mysql解析器将使用语法规则验证和解析查询，包括验证是否使用错误关键字、使用关键字顺序是否正确。预处理器则根据一些Mysql规则进一步检查解析树是否合法，包括检查数据表和数据列是否存在，还会解析名字和别名，看看它们是否有歧义。 查询优化器解析树需要由查询优化器将其转化成执行计划，一个查询可以有很多种执行方式。优化器的作用就是找到这其中最好的执行计划。Mysql的查询优化器是一个非常复杂的部件，它使用了很多优化策略来生成一个最优的执行计划。优化策略可以简单的分为两种，一种是静态优化，一种是动态优化。 关联查询优化器多表关联时，可以有多种不同的关联顺序来获得相同的执行结果，关联查询优化器通过评估不同顺序时的成本来选择一个代价最小的关联顺序。 排序优化Mysql可以通过索引进行排序，当不能使用索引生成排序结果的时候，Mysql需要自己进行排序。如果数据量小，则使用快速排序在内存中操作，如果内存不够，那么Mysql会先将数据分块，对每个独立的块使用快速排序进行排序，并将结果存放在磁盘上，最后将结果合并。Mysql主要有两种排序算法：一是两次传输排序（旧版本使用），读取行指针和需要排序的字段，对其进行排序，然后再根据排序结果读取需要的数据行；二是单词传输排序（新版本使用），先读取查询所需要的所有列，然后再根据给定列进行排序，最后直接返回排序结果。第一种方式缺点是需要两次数据传输，第二种缺点时需要返回的列非常多时会额外占用大量的空间。 查询执行引擎Mysql的查询执行引擎根据执行计划来完成整个查询。相比于查询优化阶段，查询执行阶段不是那么复杂，Mysql只是简单的根据执行计划给出的指令逐步执行。在根据执行计划逐步执行的过程中，有大量的操作需要通过调用存储引擎实现的接口来完成，这些接口也就是我们称为“handler api”的接口。 返回结果给客户端查询执行过程的最后一个阶段是将结果返回给客户端。解释查询不需要返回结果集给客户端，Mysq仍然会返回这个查询的一些信息，如该查询影响到的行数。Mysql将结果集返回客户端是一个增量、逐步返回的过程，开始生成第一条结果时，Mysql就可以开始向客户端逐步返回结果集了。这样有两个好处：一是服务器无须存储太多的结果；二是客户端可以第一时间获得返回的结果。 优化特定类型的查询优化COUNT()查询count()是一个特殊的函数，有两种非常不同的作用：一是可以统计某个列值的数量，此时要求列值是非空的；一是统计结果集行数。通常来说，count()需要扫描大量的行才能获得精确的结果，在mysql层面能做的优化只有通过索引覆盖扫描。 优化关联查询 确保on子句中的列上有索引。在创建索引的时候就要考虑到关联的顺序。当表A和表B用列c关联的时候，如果优化器的关联顺序是B，A，那么就不需要在B表对应的列上建上索引。没有用到的索引只会带来额外的负担。一般来说，除非有其他理由，否则只需要在关联顺序中的第二个表的相应列上创建索引。 确保任何的group by 和order by 中的表达式只涉及一个表中的列，这样Mysql才有可能使用索引来优化这个过程。 优化子查询关于子查询优化最重要的优化建议就是尽可能使用关联查询代替。 优化LIMIT分页在系统中需要进行分页操作的时候，我们通常会使用limit加上偏移量的办法实现，同时加上合适的order by子句。如果有对应的索引，通常效率会不错，否则，Mysql需要做大量的文件排序操作。 在偏移量非常大的时候，例如可能是limit 10000，20这样的查询，这时Mysql需要查询10020条记录然后只返回最后20条记录，前面10000条记录被抛弃，这样的代价非常高。优化此类分页查询的一个最简单的办法就是尽可能的使用索引覆盖扫描，而不是查询所有的列，然后再根据需要做一次关联操作再返回所需要的列。例如下面的列子：1select film_id,description from sakila.film order by title limit 5000, 5; 如果这个表非常的大，可以改成下面的样子：1234SELECT film.film_id, film.description FROM sakila.filmINNER JOIN (SELECT film_id FROM sakila.film ORDER BY title LIMIT 5000,5) AS limUSING(film_id); 注意优化中关联的子查询，因为只查询film_id一个列，数据量小，使得一个内存页可以容纳更多的数据，这让MySQL扫描尽可能少的页面。在获取到所需要的所有行之后再与原表进行关联以获得需要的全部列。 优化UNION查询Mysql总是通过创建并填充临时表的方式来执行union查询，因此很多优化策略在union查询中都没法很好的使用。除非确实需要服务器消除重复的行，否则一定要使用union all，这一点很重要，如果没有all关键字，Mysql会给临时表加上distinct选项，这会导致对整个临时表的数据做唯一性检查，这样做的代价非常高。","categories":[{"name":"Mysql","slug":"Mysql","permalink":"http://yoursite.com/categories/Mysql/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"http://yoursite.com/tags/mysql/"}],"keywords":[{"name":"Mysql","slug":"Mysql","permalink":"http://yoursite.com/categories/Mysql/"}]},{"title":"一文详解二叉树","slug":"binary-tree","date":"2020-01-16T03:50:05.000Z","updated":"2020-01-21T09:35:31.154Z","comments":true,"path":"data-struct/binary-tree.html","link":"","permalink":"http://yoursite.com/data-struct/binary-tree.html","excerpt":"树是一种重要的数据结构，它的定义： 树(Tree)是n(n≥0)个结点的有限集。n=0时称为空树。在任意一颗非空树中：（1）有且仅有一个特定的称为 根（root） 的结点（2）当n&gt;1时，其余结点可以分为m(m&gt;0)个互不相交的有限集T1,T1,…,Tm，其中每一个本身又是一棵树，并且称为根的 子树（sub tree）","text":"树是一种重要的数据结构，它的定义： 树(Tree)是n(n≥0)个结点的有限集。n=0时称为空树。在任意一颗非空树中：（1）有且仅有一个特定的称为 根（root） 的结点（2）当n&gt;1时，其余结点可以分为m(m&gt;0)个互不相交的有限集T1,T1,…,Tm，其中每一个本身又是一棵树，并且称为根的 子树（sub tree） 树的术语 结点的度：结点拥有的子树个数。 树的度：树内各结点的度的最大值。 叶结点或终端结点：度为0的结点。 子结点，父结点：结点的子树的根称为该结点的子结点，对应的，该结点是子结点的父结点。 根结点：没有父结点的是根结点。 结点的层次：根结点是第一层，根的子结点是第二层，依此类推。 树的深度或高度：树中结点最大的层次称为树的深度或高度。 二叉树定义 二叉树（Binary Tree）是n（n≥0）个结点的有限集合，该集合或者为空集（空二叉树），或者由一个根结点和两棵互不相交的，分别称为根结点的左子树右子树的二叉树组成。 简单点说，树中所有结点的度不超过2，这样的树就是二叉树。 二叉树特点 每个结点最多有两棵树。 左子树和右子树是有顺序的，不能颠倒。 即使树中某结点只有一个子树，也要区分是左子树还是右子树。 特殊二叉树 斜树：所有结点都只有左子树的二叉树叫做左斜树，所有结点都只有右子树的二叉树叫做右斜树，这两者统称为斜树。 满二叉树：所有分支结点都存在左子树和右子树，并且所有叶子结点都在最下面一层，这样的称为满二叉树。（满二叉树的结点个数为2^ｎ-1，ｎ为数的深度)。） 完全二叉树：若二叉树中最多只有最下面两层的结点的度数可以小于2，并且最下面一层的叶子结点都是依次排列在该层最左边的位置上，则称为完全二叉树。 二叉树的存储结构顺序存储当二叉树是完全二叉树时，我们可以使用顺序存储来存储二叉树，如下图所示：按层序遍历（下面会介绍）依次把结点存储在一个数组中。 对于非完全二叉树，也可以按顺序存储，但是相比完全二叉树缺少的结点用 ^ 代替，这样空间利用率不高，一般非完全二叉树不建议用顺序存储。 链式存储二叉树每个结点最多只有两个孩子结点，所以为它设计一个数据域和两个指针域是比较好的做法，我们称这样的链表叫做二叉链表。结点的结构如下图所示： 下面是我们二叉链表结构定义代码： 12345static class Node&lt;E&gt; &#123; E item; Node&lt;E&gt; leftChild; Node&lt;E&gt; rightChild; &#125; 利用指针域我们便可以完美的存储非完全二叉树，如下： 如果有需要，我们还可以增加一个指向父结点的指针域，那样就称之为三叉链表。 二叉树遍历前序遍历若二叉树为空，则直接返回，否则先访问根结点，然后前序遍历左子树，再前序遍历右子树。 递归算法实现： 12345678public void firstOrderTraversal(Node&lt;E&gt; node) &#123; if (node == null) &#123; return; &#125; printNode(node); firstOrderTraversal(node.leftChild); firstOrderTraversal(node.rightChild); &#125; 非递归算法实现： 12345678910111213141516public void firstOrderTraversal2(Node&lt;E&gt; node) &#123; if (node == null) &#123; return; &#125; Stack&lt;Node&lt;E&gt;&gt; stack = new Stack&lt;&gt;(); stack.push(node); while (!stack.isEmpty()) &#123; Node&lt;E&gt; pop = stack.pop(); if (pop != null) &#123; printNode(pop); stack.push(pop.rightChild); stack.push(pop.leftChild); &#125; &#125; &#125; 中序遍历若二叉树为空，则直接返回，否则先从根结点开始（注意不是先从根结点访问），中序遍历根结点的左子树，然后访问根结点，最后中序遍历根结点的右子树。 算法实现： 123456789public void inOrderTraversal(Node&lt;E&gt; node) &#123; if (node == null) &#123; return; &#125; inOrderTraversal(node.leftChild); printNode(node); inOrderTraversal(node.rightChild); &#125; 非递归算法实现： 1234567891011121314151617public void inOrderTraversal2(Node&lt;E&gt; node) &#123; if (node == null) &#123; return; &#125; Stack&lt;Node&lt;E&gt;&gt; stack = new Stack&lt;&gt;(); while (node != null || !stack.isEmpty()) &#123; if (node != null) &#123; stack.push(node); node = node.leftChild; &#125; else &#123; Node&lt;E&gt; pop = stack.pop(); printNode(pop); node = pop.rightChild; &#125; &#125;&#125; 后序遍历若二叉树为空，则直接返回，否则先从根结点开始，后序遍历根结点的左子树，然后中序遍历根结点的右子树，最后访问根结点。 算法实现： 12345678public void postOrderTraversal(Node&lt;E&gt; node) &#123; if (node == null) &#123; return; &#125; postOrderTraversal(node.leftChild); postOrderTraversal(node.rightChild); printNode(node); &#125; 非递归算法实现： 123456789101112131415161718192021222324252627282930/** * 主要思想：首先遍历root根节点的所有左结点，并依次入栈。对出栈的元素，如果没有右子树或者虽然有右子树 * 但右子树已完成遍历，即可完成出栈；否则，再次入栈，并把右子树入栈，遍历右子树的所有左子树。 * * @param node */public void postOrderTraversal2(Node&lt;E&gt; node) &#123; if (node == null) &#123; return; &#125; Stack&lt;Node&lt;E&gt;&gt; stack = new Stack&lt;&gt;(); Node&lt;E&gt; prePop = null; while (node != null || !stack.isEmpty()) &#123; if (node != null) &#123; stack.push(node); node = node.leftChild; &#125; else &#123; Node&lt;E&gt; pop = stack.pop(); if (pop.rightChild == null || pop.rightChild == prePop) &#123; printNode(pop); prePop = pop; node = null; &#125; else &#123; stack.push(pop); stack.push(pop.rightChild); node = pop.rightChild.leftChild; &#125; &#125; &#125;&#125; 层序遍历若二叉树为空，则直接返回，否则先从树的第一层，也就是根结点开始，从上而下逐层遍历，同一层中，按从左至右依次访问各个结点。 算法实现： 123456789101112131415public void levelOrderTraversal(Node&lt;E&gt; node) &#123; if (node == null) &#123; return; &#125; LinkedList&lt;Node&lt;E&gt;&gt; queue = new LinkedList&lt;&gt;(); queue.push(node); while (!queue.isEmpty()) &#123; Node&lt;E&gt; pop = queue.poll(); if (pop != null) &#123; printNode(pop); queue.add(pop.leftChild); queue.add(pop.rightChild); &#125; &#125; &#125;","categories":[{"name":"数据结构和算法","slug":"data-struct","permalink":"http://yoursite.com/categories/data-struct/"}],"tags":[{"name":"数据结构","slug":"数据结构","permalink":"http://yoursite.com/tags/数据结构/"}],"keywords":[{"name":"数据结构和算法","slug":"data-struct","permalink":"http://yoursite.com/categories/data-struct/"}]},{"title":"Mysql explain 详解","slug":"explain","date":"2020-01-03T10:02:33.000Z","updated":"2020-01-06T08:40:50.318Z","comments":true,"path":"Mysql/explain.html","link":"","permalink":"http://yoursite.com/Mysql/explain.html","excerpt":"","text":"explain可以提供Mysql执行语句的信息，根据这些信息，我们可以对执行语句进行优化，比如调整索引和连接顺序。explain可以用于select，insert，update，delete，replace语句。 explain输出项1. id列","categories":[{"name":"Mysql","slug":"Mysql","permalink":"http://yoursite.com/categories/Mysql/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"http://yoursite.com/tags/mysql/"}],"keywords":[{"name":"Mysql","slug":"Mysql","permalink":"http://yoursite.com/categories/Mysql/"}]},{"title":"Rocketmq源码解析-2.Namesrv","slug":"rocketmq-namesrv","date":"2019-12-19T12:10:25.000Z","updated":"2020-01-16T09:07:06.758Z","comments":true,"path":"middleware/rocketmq-namesrv.html","link":"","permalink":"http://yoursite.com/middleware/rocketmq-namesrv.html","excerpt":"Namesrv简介Namesrv可以理解为一个注册中心，类似于kafka的zookeeper，但是比zk更加轻量，主要包含两块功能： 管理一些KV配置信息。 管理broker和topic的注册信息。","text":"Namesrv简介Namesrv可以理解为一个注册中心，类似于kafka的zookeeper，但是比zk更加轻量，主要包含两块功能： 管理一些KV配置信息。 管理broker和topic的注册信息。 Namesrv启动过程 启动过程主要涉及NamesrvStartup和NamesrvController两个类。 执行sh mqnamesrv命令会启动NamesrvStartup类中的main方法，首先会执行createNamesrvController方法，解析命令行中的参数到各种config对象中（主要是NettyServerConfig和NamesrvConfig）。然后会使用这两个config对象创建NamesrvController实例对象。接下来执行NamesrvController 对象的initialize()、start()方法，并且配置ShutdownHook。initialize()方法中会依次执行加载所有kv配置、创建NettyServer、创建processor线程池、注册processor、使用scheduledExecutorService启动各种scheduled task（包括broker的心跳检测）。start()方法会执行启动NettyServer。 不仅Namesrv的启动过程是这样，其他的组件启动过程也是startup/config/controller这样一个流程。 Namesrv主要组件 KVConfigManager 定义一个HashMap configTable存储配置信息。键为namespace，值为真正存储kv信息的map，这样就可以将同样namespace的配置放入同一个map。 12private final HashMap&lt;String/* Namespace */, HashMap&lt;String/* Key */, String/* Value */&gt;&gt; configTable = new HashMap&lt;String, HashMap&lt;String, String&gt;&gt;(); 使用读写锁控制配置信息的加载和读取。 1private final ReadWriteLock lock = new ReentrantReadWriteLock(); KVConfigManager类中load()方法用于启动namesrv时通过configpath读取配置文件，再将配置存入map，另外还提供添加，删除，获取配置方法用于后续操作 RouteInfoManager 定义五个map分别存储topic、broker、cluster、brokerliveinfo、filter信息。 123456private final ReadWriteLock lock = new ReentrantReadWriteLock();private final HashMap&lt;String/* topic */, List&lt;QueueData&gt;&gt; topicQueueTable;private final HashMap&lt;String/* brokerName */, BrokerData&gt; brokerAddrTable;private final HashMap&lt;String/* clusterName */, Set&lt;String/* brokerName */&gt;&gt; clusterAddrTable;private final HashMap&lt;String/* brokerAddr */, BrokerLiveInfo&gt; brokerLiveTable;private final HashMap&lt;String/* brokerAddr */, List&lt;String&gt;/* Filter Server */&gt; filterServerTable; DefaultRequestProcessor namesrv启动时会注册processor 1234567private void registerProcessor() &#123; if (namesrvConfig.isClusterTest()) &#123; this.remotingServer.registerDefaultProcessor(new ClusterTestRequestProcessor(this, namesrvConfig.getProductEnvName()), this.remotingExecutor); &#125; else &#123; this.remotingServer.registerDefaultProcessor(new DefaultRequestProcessor(this), this.remotingExecutor); &#125; &#125; 当namesrv有请求过来时，会使用DefaultRequestProcessor去处理请求，处理过程会在线程池this.remotingExecutor中执行，通过processRequest方法处理请求，根据request中不同code进行不同处理。 123456789101112131415161718192021222324252627282930313233343536373839404142switch (request.getCode()) &#123; case RequestCode.PUT_KV_CONFIG: return this.putKVConfig(ctx, request); case RequestCode.GET_KV_CONFIG: return this.getKVConfig(ctx, request); case RequestCode.DELETE_KV_CONFIG: return this.deleteKVConfig(ctx, request); case RequestCode.REGISTER_BROKER: Version brokerVersion = MQVersion.value2Version(request.getVersion()); if (brokerVersion.ordinal() &gt;= MQVersion.Version.V3_0_11.ordinal()) &#123; return this.registerBrokerWithFilterServer(ctx, request); &#125; else &#123; return this.registerBroker(ctx, request); &#125; case RequestCode.UNREGISTER_BROKER: return this.unregisterBroker(ctx, request); case RequestCode.GET_ROUTEINTO_BY_TOPIC: return this.getRouteInfoByTopic(ctx, request); case RequestCode.GET_BROKER_CLUSTER_INFO: return this.getBrokerClusterInfo(ctx, request); case RequestCode.WIPE_WRITE_PERM_OF_BROKER: return this.wipeWritePermOfBroker(ctx, request); case RequestCode.GET_ALL_TOPIC_LIST_FROM_NAMESERVER: return getAllTopicListFromNameserver(ctx, request); case RequestCode.DELETE_TOPIC_IN_NAMESRV: return deleteTopicInNamesrv(ctx, request); case RequestCode.GET_KVLIST_BY_NAMESPACE: return this.getKVListByNamespace(ctx, request); case RequestCode.GET_TOPICS_BY_CLUSTER: return this.getTopicsByCluster(ctx, request); case RequestCode.GET_SYSTEM_TOPIC_LIST_FROM_NS: return this.getSystemTopicListFromNs(ctx, request); case RequestCode.GET_UNIT_TOPIC_LIST: return this.getUnitTopicList(ctx, request); case RequestCode.GET_HAS_UNIT_SUB_TOPIC_LIST: return this.getHasUnitSubTopicList(ctx, request); case RequestCode.GET_HAS_UNIT_SUB_UNUNIT_TOPIC_LIST: return this.getHasUnitSubUnUnitTopicList(ctx, request); default: break; &#125; 其他 namesrv是无状态的，可以任意水平扩展，每一个broker都与所有namesrv保持长链接(有个scheduled task会按一定频率给所有namesrv做register broker的操作)，所以namesrv之间没有主从关系，他们之间也不需要复制数据。client(producer/consumer)会随机选择一个namesrv进行连接。 client和broker中的namesrv地址有以下四种获取方式： 通过命令行或者配置文件设置namesrv地址。 在启动之前通过指定java选项rocketmq.namesrv.addr。 设置NAMESRV_ADDR环境变量，brokers和clients会去读取这个环境变量。 通过一个定时任务每两分钟去一个web服务中获取并更新namesrvaddr的列表。","categories":[{"name":"middleware","slug":"middleware","permalink":"http://yoursite.com/categories/middleware/"}],"tags":[{"name":"rocketmq","slug":"rocketmq","permalink":"http://yoursite.com/tags/rocketmq/"}],"keywords":[{"name":"middleware","slug":"middleware","permalink":"http://yoursite.com/categories/middleware/"}]},{"title":"Rocketmq源码解析-1.Rocketmq介绍","slug":"rocketmq-structure","date":"2019-12-18T12:16:13.000Z","updated":"2019-12-19T09:19:57.412Z","comments":true,"path":"middleware/rocketmq-structure.html","link":"","permalink":"http://yoursite.com/middleware/rocketmq-structure.html","excerpt":"Rocketmq优势： rocketmq原生就支持分布式，而activemq原生存在单点性。 rocketmq可以严格的保证消息的顺序，而activemq不能保证。 rocketmq可以提供亿级消息的堆积能力，不过这不是重点，重点是堆积了亿级消息还能保持低延迟写入。","text":"Rocketmq优势： rocketmq原生就支持分布式，而activemq原生存在单点性。 rocketmq可以严格的保证消息的顺序，而activemq不能保证。 rocketmq可以提供亿级消息的堆积能力，不过这不是重点，重点是堆积了亿级消息还能保持低延迟写入。 丰富的消息推拉模式（push和pull）：push好理解，在消费者端设置消息listener回调；pull需要应用主动的调用拉消息的方法从broker拉取消息，这里存在一个记录消费位置的问题，如果不记录会存在重复消费的问题。 一般mq分布式协调使用zookeeper，rocketmq自己实现了一个nameserver，更加轻量级，性能更好。 消息失败重试机制、高效的订阅者水平扩展能力、强大的api、事务机制等等。 rocketmq有group的概念，通过group机制可以实现天然的消息负载均衡。 Rocketmq部署模式： 单master模式：无需多言，一旦单个broker重启或宕机，一切都结束了！显然，线上不可以使用。 多master模式：全是master，没有slave。一个broker宕机了，应用没有影响，缺点在于宕机的master上未被消费的消息在master没有恢复之前不可以订阅。 多master多slave模式（异步复制）：高可用，采用异步复制的方式，主备之间短暂延迟，ms级别。master宕机，消费者可以从slave上消费，但是master的宕机会导致丢失掉极少量的消息。 多master多slave模式（同步双写）：和上面的区别在于采用的是同步方式，也就是master、slave都写成功才会向应用返回成功。可见不论是数据，还是服务都没有单点，都非常可靠！缺点在于同步的性能比异步稍低。 Rocketmq项目结构： acl：访问权限控制模块 broker：消息代理模块，串联 Producer/Consumer 和 Store client：客户端模块，包含producer和consumer，负责消息的发送和消费 common：公共模块，供其他模块使用 distribution：包含一些 sh 脚本和 配置，主要供部署时使用 example：一些rocketmq使用的示例代码 filter：过滤器模块 logappender：接入日志需要的appender模块 logging：日志模块 namesrv：rocketmq的注册中心，broker，produce，consumer以及topic信息会在namesrv中注册 openmessaging：忽略，没了解过 remoting：远程调用模块，基于Netty实现，produer，consumer，broker之间通过这个模块通信。 srvutil：解析命令行的工具类ServerUtil store：消息存储模块 test：测试用例模块 tools：一些工具类，基于它们可以写一些 sh 工具来管理、查看MQ系统的一些信息 对于这些模块我们不需要都去研究源码，只需要挑几个重点去关注。这里面比较重要的是broker，client，common，namesrv，remoting，store这几个模块。 Rocketmq逻辑部署架构 这是 Rocketmq 的逻辑部署结构(参考《RocketMQ原理简介 v3.1.1》)，包括 producer/broker/namesrv/consumer 四大部分。namesrv 起到注册中心的作用，部署的时候会用到 rocketmq-namesrv/rocketmq-common/rocketmq-remoting 三个模块的代码；broker 部署的时候会用到 rocketmq-broker/rocketmq-store/rocketmq-common/rocketmq-remoting 四个模块的代码；producer 和 consumer 会用到 rocketmq-client/rocketmq-common/rocketmq-remoting 三个模块的代码，这里虽然将它们分开画了，但实际上一个应用往往既是producer又是consumer。","categories":[{"name":"middleware","slug":"middleware","permalink":"http://yoursite.com/categories/middleware/"}],"tags":[{"name":"rocketmq","slug":"rocketmq","permalink":"http://yoursite.com/tags/rocketmq/"}],"keywords":[{"name":"middleware","slug":"middleware","permalink":"http://yoursite.com/categories/middleware/"}]},{"title":"Rocketmq安装部署","slug":"rocketmq-install","date":"2019-12-17T11:34:20.000Z","updated":"2019-12-20T10:47:49.148Z","comments":true,"path":"middleware/rocketmq-install.html","link":"","permalink":"http://yoursite.com/middleware/rocketmq-install.html","excerpt":"获取源码,打包编译 从github下载源码，git clone https://github.com/apache/rocketmq.git 编译源码，进入到主目录，然后执行命令： mvn -Prelease-all -DskipTests clean install -U 编译完之后我们只需要下图红框之内的目录进行部署。","text":"获取源码,打包编译 从github下载源码，git clone https://github.com/apache/rocketmq.git 编译源码，进入到主目录，然后执行命令： mvn -Prelease-all -DskipTests clean install -U 编译完之后我们只需要下图红框之内的目录进行部署。 上图中bin目录是存放部署启动的脚本，conf目录存放的是配置文件，lib目录是打包好之后的所有jar包。 启动Namesrv首先设置好系统JAVA_HOME变量（必须使用64位JDK），然后在主目录下执行nohup sh bin/mqnamesrv &amp;，启动成功之后可以查看到进程，端口默认是9876。(启动默认指定的堆内存是4G，我们自己测试时可以通过修改runserver.sh文件中参数适当改小) 启动broker&nbsp;&nbsp;&nbsp;broker集群主要有四种配置方式：单master，多master，多master多slave同步双写，多master多slave异步复制。（现在好像多了一种dledger的方式，暂时还没研究，不太明白）。&nbsp;&nbsp;&nbsp;Master和Slave的配置文件参考conf目录下的配置文件。Master与Slave通过指定相同的brokerName参数来配对，Master的BrokerId必须是0，Slave的BrokerId必须是大于0的数。&nbsp;&nbsp;&nbsp;启动命令：nohup sh bin/mqbroker -n localhost:9876 -c conf/2m-2s-async/broker-a.properties &amp; 其他 查看日志namesrv和broker的日志默认存在下面所示目录中：tail -f ~/logs/rocketmqlogs/namesrv.logtail -f ~/logs/rocketmqlogs/broker.log 关闭服务器分别关闭broker和namesrv:sh bin/mqshutdown brokersh bin/mqshutdown namesrv 其他命令查看集群情况： ./bin/mqadmin clusterList -n localhost:9876查看broker状态： ./bin/mqadmin brokerStatus -n localhost:9876 -b localhost:10911查看topic列表： ./bin/mqadmin topicList -n localhost9876查看topic状态： ./bin/mqadmin topicStatus -n localhost:9876 -t MyTopic (换成想查询的 topic)查看topic路由： ./bin/mqadmin topicRoute -n localhost:9876 -t MyTopic Rocketmq-Console安装 使用git命令下载项目源码，由于我们仅需要rocketmq-console，故下载此项目对应分支即可。git clone -b release-rocketmq-console-1.0.0 https://github.com/apache/rocketmq-externals.git 进入项目文件夹并修改配置文件 cd rocketmq-externals/rocketmq-console/ vi src/main/resources/application.properties (可以修改rocketmq.config.namesrvAddr，当然也可以后面启动时通过参数指定) 执行maven命令打成jar包：mvn clean package -Dmaven.test.skip=true 启动： java -jar -n localhost:9876 rocketmq-console-ng-1.0.0.jar &amp; 浏览器访问http://localhost:8080就可以查看管理界面。","categories":[{"name":"middleware","slug":"middleware","permalink":"http://yoursite.com/categories/middleware/"}],"tags":[{"name":"rocketmq","slug":"rocketmq","permalink":"http://yoursite.com/tags/rocketmq/"}],"keywords":[{"name":"middleware","slug":"middleware","permalink":"http://yoursite.com/categories/middleware/"}]},{"title":"Java锁介绍","slug":"lock","date":"2019-11-07T14:38:14.000Z","updated":"2020-02-27T10:23:29.917Z","comments":true,"path":"Java/lock.html","link":"","permalink":"http://yoursite.com/Java/lock.html","excerpt":"&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;锁是用来控制多个线程访问共享资源的方式，一般来说，一个锁能够防止多个线程同时访问共享资源（但是有些锁可以允许多个线程并发的访问共享资源，比如读写锁）。在Lock接口出现之前，Java程序是靠synchronized关键字实现锁功能的，而Java SE 5之后，并发包中新增了Lock接口（以及相关实现类）用来实现锁功能，它提供了与synchronized关键字类似的同步功能，只是在使用时需要显式地获取和释放锁。虽然它缺少了（通过synchronized块或者方法所提供的）隐式获取释放锁的便捷性，但是却拥有了锁获取与释放的可操作性、可中断的获取锁以及超时获取锁等多种synchronized关键字所不具备的同步特性。","text":"&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;锁是用来控制多个线程访问共享资源的方式，一般来说，一个锁能够防止多个线程同时访问共享资源（但是有些锁可以允许多个线程并发的访问共享资源，比如读写锁）。在Lock接口出现之前，Java程序是靠synchronized关键字实现锁功能的，而Java SE 5之后，并发包中新增了Lock接口（以及相关实现类）用来实现锁功能，它提供了与synchronized关键字类似的同步功能，只是在使用时需要显式地获取和释放锁。虽然它缺少了（通过synchronized块或者方法所提供的）隐式获取释放锁的便捷性，但是却拥有了锁获取与释放的可操作性、可中断的获取锁以及超时获取锁等多种synchronized关键字所不具备的同步特性。 synchronized锁&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;JVM基于进入和退出Monitor对象来实现方法同步和代码块同步。代码块同步是使用monitorenter和monitorexit指令实现的，monitorenter指令是在编译后插入到同步代码块的开始位置，而monitorexit是插入到方法结束处和异常处。任何对象都有一个monitor与之关联，当且一个monitor被持有后，它将处于锁定状态。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;根据虚拟机规范的要求，在执行monitorenter指令时，首先要去尝试获取对象的锁，如果这个对象没被锁定，或者当前线程已经拥有了那个对象的锁，把锁的计数器加1；相应地，在执行monitorexit指令时会将锁计数器减1，当计数器被减到0时，锁就释放了。如果获取对象锁失败了，那当前线程就要阻塞等待，直到对象锁被另一个线程释放为止。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;synchronized与java.util.concurrent包中的ReentrantLock相比，由于JDK1.6中加入了针对锁的优化措施（见后面），使得synchronized与ReentrantLock的性能基本持平。ReentrantLock只是提供了synchronized更丰富的功能，而不一定有更优的性能，所以在synchronized能实现需求的情况下，优先考虑使用synchronized来进行同步 Java对象头&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;synchronized用的锁是存在Java对象头里的。如果对象是数组类型，则虚拟机用3个字宽（Word）存储对象头，如果对象是非数组类型，则用2字宽存储对象头。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Java对象头里的Mark Word里默认存储对象的HashCode、分代年龄和锁标记位。在运行期间，Mark Word里存储的数据会随着锁标志位的变化而变化。Mark Word可能变化为存储以下4种数据，如下所示 锁优化&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Java SE 1.6为了减少获得锁和释放锁带来的性能消耗，引入了“偏向锁”和“轻量级锁”：锁一共有4种状态，级别从低到高依次是：无锁状态、偏向锁状态、轻量级锁状态和重量级锁状态。锁可以升级但不能降级。 无锁&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;无锁没有对资源进行锁定，所有的线程都能访问并修改同一个资源，但同时只有一个线程能修改成功。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;无锁的特点就是修改操作在循环内进行，线程会不断的尝试修改共享资源。如果没有冲突就修改成功并退出，否则就会继续循环尝试。如果有多个线程修改同一个值，必定会有一个线程能修改成功，而其他修改失败的线程会不断重试直到修改成功。上面我们介绍的CAS原理及应用即是无锁的实现。无锁无法全面代替有锁，但无锁在某些场合下的性能是非常高的。 偏向锁&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;大多数情况下，锁不仅不存在多线程竞争，而且总是由同一线程多次获得，为了让线程获得锁的代价更低而引入了偏向锁。当一个线程访问同步块并获取锁时，会在对象头和栈帧中的锁记录里存储锁偏向的线程ID，以后该线程在进入和退出同步块时不需要进行CAS操作来加锁和解锁，只需简单地测试一下对象头的Mark Word里是否存储着指向当前线程的偏向锁。如果测试成功，表示线程已经获得了锁。如果测试失败，则需要再测试一下Mark Word中偏向锁的标识是否设置成1（表示当前是偏向锁）：如果没有设置，则使用CAS竞争锁；如果设置了，则尝试使用CAS将对象头的偏向锁指向当前线程。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;偏向锁使用了一种等到竞争出现才释放锁的机制，所以当其他线程尝试竞争偏向锁时，持有偏向锁的线程才会释放锁。偏向锁的撤销，需要等待全局安全点。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;偏向锁在Java 6和Java 7里是默认启用的，但是它在应用程序启动几秒钟之后才激活，如有必要可以使用JVM参数来关闭延迟：-XX:BiasedLockingStartupDelay=0。如果你确定应用程序里所有的锁通常情况下处于竞争状态，可以通过JVM参数关闭偏向锁：-XX:-UseBiasedLocking=false，那么程序默认会进入轻量级锁状态。 轻量级锁&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;当锁是偏向锁的时候，被另外的线程所访问，偏向锁就会升级为轻量级锁，其他线程会通过自旋的形式尝试获取锁，不会阻塞，从而提高性能。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;线程在执行同步块之前，JVM会先在当前线程的栈桢中创建用于存储锁记录的空间，并将对象头中的Mark Word复制到锁记录中，官方称为Displaced Mark Word。然后线程尝试使用CAS将对象头中的Mark Word替换为指向锁记录的指针。如果成功，当前线程获得锁，如果失败，表示其他线程竞争锁，当前线程便尝试使用自旋来获取锁。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;轻量级解锁时，会使用原子的CAS操作将Displaced Mark Word替换回到对象头，如果成功，则表示没有竞争发生。如果失败，表示当前锁存在竞争，锁就会膨胀成重量级锁。下图是两个线程同时争夺锁，导致锁膨胀的流程图。 重量级锁&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;升级为重量级锁时，锁标志的状态值变为“10”，此时Mark Word中存储的是指向重量级锁的指针，此时等待锁的线程都会进入阻塞状态。 综上，偏向锁通过对比Mark Word解决加锁问题，避免执行CAS操作。而轻量级锁是通过用CAS操作和自旋来解决加锁问题，避免线程阻塞和唤醒而影响性能。重量级锁是将除了拥有锁的线程以外的线程都阻塞。 其他锁优化（锁消除和锁粗化） 锁消除&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;锁消除即删除不必要的加锁操作。虚拟机即时编辑器在运行时，对一些“代码上要求同步，但是被检测到不可能存在共享数据竞争”的锁进行消除。根据代码逃逸技术，如果判断到一段代码中，堆上的数据不会逃逸出当前线程，那么可以认为这段代码是线程安全的，不必要加锁。 看下面这段程序： 1234567891011121314public class SynchronizedTest &#123; public static void main(String[] args) &#123; SynchronizedTest test = new SynchronizedTest(); for (int i = 0; i &lt; 100000000; i++) &#123; test.append(&quot;abc&quot;, &quot;def&quot;); &#125; &#125; public void append(String str1, String str2) &#123; StringBuffer sb = new StringBuffer(); sb.append(str1).append(str2); &#125;&#125; 虽然StringBuffer的append是一个同步方法，但是这段程序中的StringBuffer属于一个局部变量，并且不会从该方法中逃逸出去（即StringBuffer sb的引用没有传递到该方法外，不可能被其他线程拿到该引用），所以其实这过程是线程安全的，可以将锁消除。 锁粗化&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;如果一系列的连续操作都对同一个对象反复加锁和解锁，甚至加锁操作是出现在循环体中的，那即使没有出现线程竞争，频繁地进行互斥同步操作也会导致不必要的性能损耗。如果虚拟机检测到有一串零碎的操作都是对同一对象的加锁，将会把加锁同步的范围扩展（粗化）到整个操作序列的外部。 举个例子： 123456789public class StringBufferTest &#123; StringBuffer stringBuffer = new StringBuffer(); public void append()&#123; stringBuffer.append(&quot;a&quot;); stringBuffer.append(&quot;b&quot;); stringBuffer.append(&quot;c&quot;); &#125;&#125; 这里每次调用stringBuffer.append方法都需要加锁和解锁，如果虚拟机检测到有一系列连串的对同一个对象加锁和解锁操作，就会将其合并成一次范围更大的加锁和解锁操作，即在第一次append方法时进行加锁，最后一次append方法结束后进行解锁。 自旋锁与自适应自旋锁 引入自旋锁的原因：互斥同步对性能最大的影响是阻塞的实现，因为挂起线程和恢复线程的操作都需要转入内核态中完成，这些操作给系统的并发性能带来很大的压力。同时虚拟机的开发团队也注意到在许多应用上面，共享数据的锁定状态只会持续很短一段时间，为了这一段很短的时间频繁地阻塞和唤醒线程是非常不值得的。 自旋锁：让该线程执行一段无意义的忙循环（自旋）等待一段时间，不会被立即挂起（自旋不放弃处理器的执行时间），看持有锁的线程是否会很快释放锁。自旋锁在JDK 1.4.2中引入，默认关闭，但是可以使用-XX:+UseSpinning开开启；在JDK1.6中默认开启。 自旋锁的缺点：自旋等待不能替代阻塞，虽然它可以避免线程切换带来的开销，但是它占用了处理器的时间。如果持有锁的线程很快就释放了锁，那么自旋的效率就非常好；反之，自旋的线程就会白白消耗掉处理器的资源，它不会做任何有意义的工作，这样反而会带来性能上的浪费。所以说，自旋等待的时间（自旋的次数）必须要有一个限度，例如让其循环10次，如果自旋超过了定义的时间仍然没有获取到锁，则应该被挂起（进入阻塞状态）。通过参数-XX:PreBlockSpin可以调整自旋次数，默认的自旋次数为10。 自适应的自旋锁：JDK1.6引入自适应的自旋锁，自适应就意味着自旋的次数不再是固定的，它是由前一次在同一个锁上的自旋时间及锁的拥有者的状态来决定：如果在同一个锁的对象上，自旋等待刚刚成功获得过锁，并且持有锁的线程正在运行中，那么虚拟机就会认为这次自旋也很有可能再次成功，进而它将允许自旋等待持续相对更长的时间。如果对于某个锁，自旋很少成功获得过，那在以后要获取这个锁时将可能省略掉自旋过程，以避免浪费处理器资源。简单来说，就是线程如果自旋成功了，则下次自旋的次数会更多，如果自旋失败了，则自旋的次数就会减少。 自旋锁使用场景：从轻量级锁获取的流程中我们知道，当线程在获取轻量级锁的过程中执行CAS操作失败时，是要通过自旋来获取重量级锁的。 公平锁和非公平锁&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;公平锁是指多个线程按照申请锁的顺序来获取锁，线程直接进入队列中排队，队列中的第一个线程才能获得锁。公平锁的优点是等待锁的线程不会饿死。缺点是整体吞吐效率相对非公平锁要低，等待队列中除第一个线程以外的所有线程都会阻塞，CPU唤醒阻塞线程的开销比非公平锁大。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;非公平锁是多个线程加锁时直接尝试获取锁，获取不到才会到等待队列的队尾等待。但如果此时锁刚好可用，那么这个线程可以无需阻塞直接获取到锁，所以非公平锁有可能出现后申请锁的线程先获取锁的场景。非公平锁的优点是可以减少唤起线程的开销，整体的吞吐效率高，因为线程有几率不阻塞直接获得锁，CPU不必唤醒所有线程。缺点是处于等待队列中的线程可能会饿死，或者等很久才会获得锁 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;synchronized锁实现是非公平锁，当我们需要使用公平锁的时候，我们可以使用ReentrantLock。根据代码可知，ReentrantLock里面有一个内部类Sync，Sync继承AQS，添加锁和释放锁的大部分操作实际上都是在Sync中实现的。它有公平锁FairSync和非公平锁NonfairSync两个子类。ReentrantLock默认使用非公平锁，也可以通过构造器来显示的指定使用公平锁。 可重入锁和非可重入锁&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;可重入锁是是指当一个线程在外层方法中获取了一把锁，进入到内层方法再次遇到同样一把锁时可以直接获取该锁，而不需要阻塞。synchronized和ReentrantLock都是可重入锁。可重入锁的一个优点是可一定程度避免死锁。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;ReentrantLock实现可重入锁是基于它定义的一个int型变量state，当一个线程来获取锁时，判断state是否为0，是0的话代表没有线程获取锁，线程就可以通过CAS将state自增+1。如果state不为0，表示已经有线程获取了锁，此时判断获取锁的线程是不是当前线程，是当前线程的话也可以获取锁（这个就实现了可重入锁），同样通过CAS将state自增+1。释放锁的过程刚好相反，每次通过CAS将state减1。加了多少次锁，就需要解多少次锁，不然很容易造成死锁。 独享锁和共享锁&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;独享锁也叫排他锁，是指该锁一次只能被一个线程所持有。如果线程T对数据A加上排它锁后，则其他线程不能再对A加任何类型的锁。获得排它锁的线程即能读数据又能修改数据。JDK中的synchronized和JUC中ReentrantLock就是互斥锁。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;共享锁是指该锁可被多个线程所持有。如果线程T对数据A加上共享锁后，则其他线程只能对A再加共享锁，不能加排它锁。获得共享锁的线程只能读数据，不能修改数据。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; ReentrantReadWriteLock包含一个readLock和一个writeLock，readLock是共享锁，writeLock是独享锁。ReentrantLock的实现是通过AQS中的state变量(int类型，32位)，而ReentrantReadWriteLock包含读写两把锁，如果在state一个整型变量上维护多种状态，就一定需要“按位切割使用”这个变量，读写锁将变量切分成了两个部分，高16位表示读，低16位表示写，划分方式如下图所示 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 锁降级指的是写锁降级成为读锁。如果当前线程拥有写锁，然后将其释放，最后再获取读锁，这种分段完成的过程不能称之为锁降级。锁降级是指把持住（当前拥有的）写锁，再获取到读锁，随后释放（先前拥有的）写锁的过程。反之由读锁升级到写锁是不允许的。 参考资料 《java并发编程的艺术》 不可不说的Java“锁”事 Java synchronized原理总结","categories":[{"name":"Java","slug":"Java","permalink":"http://yoursite.com/categories/Java/"}],"tags":[{"name":"并发","slug":"concurrent","permalink":"http://yoursite.com/tags/concurrent/"},{"name":"lock","slug":"lock","permalink":"http://yoursite.com/tags/lock/"}],"keywords":[{"name":"Java","slug":"Java","permalink":"http://yoursite.com/categories/Java/"}]},{"title":"Java GC总结","slug":"java-gc","date":"2019-02-19T09:43:27.000Z","updated":"2020-02-19T12:22:34.386Z","comments":true,"path":"Java/java-gc.html","link":"","permalink":"http://yoursite.com/Java/java-gc.html","excerpt":"1. Jvm内存结构","text":"1. Jvm内存结构 2. GC介绍优化一个Java程序，主要关注点有两个：响应时间和吞吐量。所以我们在做GC优化的时候会考虑这两个方面：当程序需要低延迟时，我们应该考虑减少GC的停顿时间；当程序需要高吞吐量时，我们应该考虑降低整体GC时间。 2.1 JVM分代回收 由上图可以看出大部分对象的存活时间很短，基本在一次gc后就会被回收，所以当代主流虚拟机（Hotspot VM）的垃圾回收都采用“分代回收”的算法。“分代回收”是基于这样一个事实：对象的生命周期不同，所以针对不同生命周期的对象可以采取不同的回收方式，以便提高回收效率。 新生代（Young Generation）：大多数对象都在新生代中被分配，当新生代被填满后就会触发Minor GC，经过Minor GC后会回收大部分对象，所以新生代很适合采用复制算法。回收时会现将eden区和一块survivor区中的存活对象标记，然后复制到另一块survivor区，然后回收eden区和其中的一块survivor区。新生代中的对象每经过一次Minor GC，年龄会加1，当达到一定年龄后会进入老年代。这个值默认是15，可以通过参数MaxTenuringThreshold来设置。 老年代（Old Generation）：在新生代中经历了N次垃圾回收后仍然存活的对象，就会被放到年老代，该区域中对象存活率高。老年代的垃圾回收（又称Major GC）通常使用“标记-清理”或“标记-整理”算法。整堆包括新生代和老年代的垃圾回收称为Full GC（HotSpot VM里，除了CMS之外，其它能收集老年代的GC都会同时收集整个GC堆，包括新生代）。 永久代（Perm Generation）：主要存放元数据，例如Class、Method的元信息，与垃圾回收要回收的Java对象关系不大。相对于新生代和年老代来说，该区域的划分对垃圾回收影响比较小。 2.2 垃圾收集算法判断对象是否存活： 引用计数法：缺点是不能解决循环引用问题 可达性分析法：根据对象到GCRoots是否可达来判断对象是否存活，可以作为GCRoots有以下一些：虚拟机栈中引用的对象、方法区中类静态属性引用的对象、方法区中常量引用的对象、本地方法栈JNI引用的对象。 回收算法： 标记清除算法：会产生内存碎片 标记整理算法：不会产生碎片，比标记清除效率更低 复制算法：需要额外的内存空间 2.3 STW（stop the world）Hotspot VM判断对象是否存活使用的是可达性分析法。为了保证整个分析过程期间对象的引用关系不发生变化，需要暂停所有java执行线程，这个就叫做STW。 OopMap由于目前的主流Java虚拟机使用的都是准确式GC，所以当执行STW后，并不需要一个不漏地检查完所有执行上下文和全局的引用位置，虚拟机应当是有办法直接得知哪些地方存放着对象引用。在HotSpot的实现中，是使用一组称为OopMap的数据结构来达到这个目的的，在类加载完成的时候，HotSpot就把对象内什么偏移量上是什么类型的数据计算出来，在JIT编译过程中，也会在特定的位置记录下栈和寄存器中哪些位置是引用。这样，GC在扫描时就可以直接得知这些信息了。 安全点HotSpot并没有为每条指令都生成OopMap，只有在特定的位置记录这个信息，这些位置称为安全点（SaftPoint）。安全点的选定基本上是以程序“是否具有让程序长时间执行的特征”为标准进行选定的。长时间执行的最明显特征就是指令序列复用，例如方法调用、循环跳转、异常跳转等。 安全区域程序不执行的时候，也就是没有分配CPU的时候，典型的就是线程sleep或者blocked状态时，这个时候不能响应中断请求。JVM不太可能等到线程重新分配CPU然后走到安全点。这样就需要安全区域解决这个问题。安全区域是指在一段区域内引用关系不会发生变化，在这中间任何一个地方GC都是安全的。我们可以把Safe Region看成是扩展的safe point。 2.4 垃圾收集器 Serial和Serial Old收集器：单线程的收集器，分别对应新生代和老年代。client模式下默认的收集器。这两个的特点是简单、易实现、效率高。 ParNew收集器：Serial收集器的多线程版，可以充分的利用CPU资源，减少回收的时间。 Parallel Scavenge和Parallel Old收集器：并行的多线程垃圾收集器，目标是达到一个可控制的吞吐量。提供了两个参数用于精确控制吞吐量，分别是控制最大垃圾收集停顿时间的-XX:MaxGCPauseMillis参数以及直接设置吞吐量大小的-XX:GCTimeRatio参数。 CMS收集器：基于标记清除算法。目标是降低GC停顿时间。 G1收集器：可预测的停顿时间。 2.5 常用GC参数设置 参数 说明 -Xms、-Xmx 设置堆的最小内存和最大内存。设置成一样，固定堆的大小，避免堆内存动态变化带来的性能损失。 -Xmn 设置堆中新生代的大小。 -XX:NewRatio 设置新生代与老年代的比值 -XX:SurvivorRatio 设置eden区和survivor区的比值 -XX:PretenureSizeThreshold 设置直接进入老年代的对象大小阈值 -XX:MaxTenuringThreshold 设置新生代对象晋升到老年代的年龄 -XX:+UseSerialGC 使用Serial+Serial Old收集器 -XX:+UseParNewGC 使用ParNew+Serial Old收集器 -XX:+UseConcMarkSweepGC 使用ParNew+CMS收集器 -XX:+UseParallelGC 使用Parallel+PS MarkSweep收集器 -XX:+UseParallelOldGC 使用Parallel+Paralle Old收集器 -XX:+UseG1GC 使用G1 收集器 -XX:GCTImeRatio 设置GC时间占总时间百分比 -XX:MaxGCPauseMillis 设置最大停顿时间 -XX:ParallelGCThreads 设置并行GC时回收线程数 -XX:PrintGCDetails 输出GC详细日志 -XX:+UseAdaptiveSizePolicy 动态调整堆中各个区域的大小以及进入老年代的年龄 2.6 GC日志每一种回收器的日志格式都是由其自身的实现决定的，换而言之，每种回收器的日志格式都可以不一样。但虚拟机设计者为了方便用户阅读，将各个回收器的日志都维持一定的共性。 Yong GCFull GC 3. CMS收集器3.1 CMS介绍CMS收集器是一款老年代的并发垃圾收集器，它的主要目标是降低GC停顿时间。对于要求服务器响应时间的应用上适合采用CMS收集器。开启CMS的参数是-XX:+UseConcMarkSweepGC. 3.2 CMS过程 初始标记：暂停程序所有线程任务，然后确定从GC Roots可达的对象集，最后重新恢复程序。 并发标记：在程序执行时并发标记所有可达的对象。 并发预清理：这个阶段会追溯第二阶段中改变的对象引用。 重新标记：暂停应用程序，重新标记并发阶段可以发生的对象引用关系。 并发清理：并发清理不可达的对象。 并发重置：重置CMS收集器的数据结构，等待下一次垃圾回收。 3.3 CMS缺点 CMS是基于标记清除算法的，所以会产生内存碎片。 需要更多的CPU资源，并发阶段CMS线程和用户并发执行，这样就需要更多的CPU。 CMS的另一个缺点是它需要更大的堆空间。因为CMS标记阶段应用程序的线程还是在执行的，那么就会有堆空间继续分配的情况，为了保证在CMS回收完堆之前还有空间分配给正在运行的应用程序，必须预留一部分空间。也就是说，CMS不会在老年代满的时候才开始收集。相反，它会尝试更早的开始收集，已避免上面提到的情况：在回收完成之前，堆没有足够空间分配！默认当老年代使用68%的时候，CMS就开始行动了。 – XX:CMSInitiatingOccupancyFraction =n 来设置这个阀值。 4. G1收集器4.1 G1介绍G1是一种服务器端的垃圾收集器，应用在多处理器和大容量内存环境中，在实现高吞吐量的同时，尽可能的满足垃圾收集暂停时间的要求。G1和CMS的目标都是降低停顿时间。G1相比CMS的优势在于没有内存碎片，可以实现可预测的停顿时间。 4.2 G1的几个概念 Region G1的各代存储地址是不连续的，每一代都使用了n个不连续的大小相同的Region，每个Region占有一块连续的虚拟内存地址。如下图所示：在上图中，我们注意到还有一些Region标明了H，它代表Humongous，这表示这些Region存储的是巨大对象（humongous object，H-obj），即大小大于等于region一半的对象。为了减少连续H-objs分配对GC的影响，需要把大对象变为普通的对象，建议增大Region size。一个Region的大小可以通过参数-XX:G1HeapRegionSize设定，取值范围从1M到32M，且是2的指数。如果不设定，那么G1会根据Heap大小自动决定。总的region数量不超过2048个。 SATB 全称是Snapshot-At-The-Beginning，由字面理解，是GC开始时活着的对象的一个快照。它是通过Root Tracing得到的，作用是维持并发GC的正确性。 SATB抽象的说就是在一次GC开始的时候是活的对象就被认为是活的，此时的对象图形成一个逻辑“快照”（snapshot）；然后在GC过程中新分配的对象都当作是活的。其它不可到达的对象就是死的了。 如何知道哪些对象是一次GC开始之后新分配的：每个region记录着两个top-at-mark-start（TAMS）指针，分别为prevTAMS和nextTAMS。在TAMS以上的对象就是新分配的，因而被视为隐式marked。 在并发标记阶段，有可能一个死亡对象被重新引用，这样就有可能导致活对象被回收。SATB通过write barrier 将引用记录下来，回收的时候会扫描这个引用记录。 当然，很可能有对象在snapshot中是活的，但随着并发GC的进行它已经死了，但SATB还是会让它活过这次GC，在下一次GC中再回收，这样就会造成浮动垃圾。 Remembered Sets（RSets） 全称是Remembered Set，是辅助GC过程的一种结构，典型的空间换时间工具。还有一种数据结构也是辅助GC的：Collection Set（CSet），它记录了GC要收集的Region集合，集合里的Region可以是任意年代的。G1中每个Region都有一个RSet，RSet记录了其他Region中的对象引用本Region中对象的关系，GC的时候可以通过扫描RSet来避免全堆的扫描。 Pause Prediction Model Pause Prediction Model即停顿预测模型。G1通过Pause Prediction Model来满足用户定义的目标停顿时间，并根据指定的目标停顿时间来选择要收集的region数量。 目标停顿时间可以通过参数-XX:MaxGCPauseMillis来指定，默认是200ms。 G1收集器之所以能建立可预测的停顿时间模型，是因为它可以有计划地避免在整个Java堆中进行全区域的垃圾收集。G1跟踪各个Region里面的垃圾堆积的价值大小（回收所获得的空间大小以及回收所需时间的经验值），在后台维护一个优先列表，每次根据允许的收集时间，优先回收价值最大的Region（这也就是Garbage-First名称的来由）。 4.3 G1 GC模式G1提供了两种GC模式，Young GC和Mixed GC，两种都是完全Stop The World的。 Yong GCG1的Yong GC和其他收集器的Minor GC过程类似，将年轻代region中存活的对象复制移动到Survivor区中的region，或者晋升到老年代。为了下一次Yong GC，还会动态调整Eden区和Survivor区的大小。 Mixed GC除了年轻代region中的存活对象，还会根据global concurrent marking统计得出收集收益高的若干老年代Region。在用户指定的开销目标范围内尽可能选择收益高的老年代Region。在G1通过几个Mixed GC回收足够的老年代region之后，会恢复执行Yong GC直到下一global 次concurrent marking完成。 Mixed GC不是Full GC，它只能回收部分老年代的Region，如果Mixed GC实在无法跟上程序分配内存的速度，导致老年代填满无法继续进行Mixed GC，就会使用Full GC来收集整个GC heap。 4.4 标记周期过程 初始标记（Initial mark）标记那些会存在对老年代引用的survivor regions (root regions)，会发生STW，伴随一次Yong GC发生。 扫描根引用区（Root region scanning ）扫描 Survivor到老年代的引用，该阶段必须在下一次 Young GC 发生前结束。这个阶段不能发生Yong GC，如果中途Eden区真的满了，也要等待这个阶段结束才能进行Young GC。 并发标记（Concurrent marking）寻找整个堆的存活对象。这个阶段和程序并发运行的，可以被Yong GC打断。 重新标记（Remark）会发生STW，标记最后可能存活的对象。这个阶段使用了SATB。 清理（Cleanup）对存活对象和空Region进行统计（STW）；清除Remembered Sets（STW）；清除空Region并加入到free list（并发执行）。 4.5 G1参数 参数 说明 -XX:+UseG1GC 开启G1收集器 -XX:G1HeapRegionSize=n 设置每个region大小 -XX:MaxGCPauseMillis=200 设置最大停顿时间 -XX:G1NewSizePercent=5 设置新生代占堆的百分比 -XX:G1MaxNewSizePercent=60 设置新生代占堆的最大百分比 -XX:ParallelGCThreads=n 设置STW后并行工作的线程数（通常和cpu核心数一样） -XX:ConcGCThreads=n 设置并发标记时工作的线程数（通常约等于1/4ParallelGCThreads） -XX:InitiatingHeapOccupancyPercent=45 设置触发标记周期时堆占用阈值 -XX:G1MixedGCLiveThresholdPercent=85 设置触发包含老年代region的Mixed GC的堆占用阈值 -XX:G1HeapWastePercent=5 设置浪费的堆内存百分比，当可回收百分比小于这个时，不会触发Mixed GC -XX:G1OldCSetRegionThresholdPercent=10 设置在Mixed GC中要回收的老年代region上限 -XX:G1MixedGCCountTarget=8 设置Mixed GC的目标数量 -XX:G1ReservePercent=10 设置空闲内存的百分比，以减少内存空间溢出的风险 4.6 G1 使用建议 避免通过-Xmn或者-XX:NewRatio等相关参数设置新生代的大小，因为这会让设置的停顿时间MaxGCPauseMillis失效。 当优化GC时，总存在延迟与吞吐量之间的权衡。G1的目标是10%的垃圾收集时间，Parallel收集器的目标是1%的垃圾收集时间。当使用G1时想要更高的吞吐量，就需要适当增加延迟时间。设置MaxGCPauseMillis过低的话会让吞吐量降低。 优化Mixed GC：使用-XX:InitiatingHeapOccupancyPercent参数改变触发标记时阈值；使用XX:G1MixedGCLiveThresholdPercent and -XX:G1HeapWastePercent这两个参数控制触发Mixed GC时机；使用-XX:G1MixedGCCountTarget and -XX:G1OldCSetRegionThresholdPercent这两个参数调整Mixed GC回收老年代region数量。 5. Jvm性能监控工具 jps：虚拟机进程状况工具列出正在执行的虚拟机进程。jps [options] [hostid]-q参数 只输出LVMID，省略主类的名称。-l参数输出主类的全名，如果执行的是jar包，输出jar的包路径。-m参数输出虚拟机进程启动时传给主类main函数的参数。-v参数输出虚拟机进程启动时的JVM参数。 jstat:虚拟机统计信息监视工具监视虚拟机各种运行状态信息。jstat [ generalOption | outputOptions vmid [ interval[s|ms] [ count ] ]主要参数有class、compiler、gc、gccapacity、gcutil等。 jinfo:Java配置信息工具实时查看和调整虚拟机各项参数。jinfo [ option ] pid jmap:Java 内存映像工具jmap [ options ] pid-dump:[live,] format=b, file=filename-heap-histo[:live] jhat:虚拟机堆转储快照分析工具jhat与jmap搭配使用，来分析jmap生成的堆转储快照。jhat [ options ] heap-dump-file jstack:Java堆栈跟踪工具输出当前java进程中的线程堆栈快照。jstack [ options ] pid 6. GC优化6.1 技巧 减少进入老年代的对象数量。老年代GC相对来说会比新生代GC更耗时，因此，减少进入老年代的对象数量可以显著降低Full GC的频率。所以需要设置合理的新生代大小。 减少Full GC的时间。通过减少老年代内存大小可以降低Full GC时间，但是这样会导致Full GC频率升高甚至出现OOM，所以要设置一个合理的老年代大小。 6.2 过程 监控GC状态 分析监控结果后决定是否需要优化GC。 设置GC类型/内存大小（可以在多台服务器上试验不同参数） 分析结果（将结果满意的参数应用到所有服务器上）","categories":[{"name":"Java","slug":"Java","permalink":"http://yoursite.com/categories/Java/"}],"tags":[{"name":"JVM虚拟机","slug":"jvm","permalink":"http://yoursite.com/tags/jvm/"}],"keywords":[{"name":"Java","slug":"Java","permalink":"http://yoursite.com/categories/Java/"}]},{"title":"Java8中HashMap和ConcurrentHashMap解析","slug":"hashmap","date":"2019-01-17T05:57:10.000Z","updated":"2020-03-12T07:18:17.108Z","comments":true,"path":"Java/hashmap.html","link":"","permalink":"http://yoursite.com/Java/hashmap.html","excerpt":"HashMap是我们平时开发中用的比较多的集合容器，但是它不是线程安全的。当需要在多线程时保证安全我们会选择使用ConcurrentHashMap。下面对这两个集合介绍（基于Java8的源码，同时会与Java7的简单对比）。","text":"HashMap是我们平时开发中用的比较多的集合容器，但是它不是线程安全的。当需要在多线程时保证安全我们会选择使用ConcurrentHashMap。下面对这两个集合介绍（基于Java8的源码，同时会与Java7的简单对比）。 HashMapJava8的HashMap底层结构是基于数组+链表/红黑树，相比Java7多了一个红黑树。红黑树主要解决了当冲突过多，链表太长，查询时间复杂度会变成O(N)的问题，Java8中当链表存储元素大于8之后将转成红黑树的存储方式，这样最坏时间复杂度由O(N)变成了O(logN)。 下图是HashMap的简单结构示意图：Java7 中使用 Entry 来代表每个 HashMap 中的数据节点，Java8 中使用 Node，基本没有区别，都是 key，value，hash 和 next 这四个属性，不过，Node 只能用于链表的情况，红黑树的情况需要使用 TreeNode。我们根据数组元素中，第一个节点数据类型是 Node 还是 TreeNode 来判断该位置下是链表还是红黑树的。 常量介绍1234567891011static final int DEFAULT_INITIAL_CAPACITY = 1 &lt;&lt; 4; //默认容量16static final int MAXIMUM_CAPACITY = 1 &lt;&lt; 30; //最大容量static final float DEFAULT_LOAD_FACTOR = 0.75f; //负载因子static final int TREEIFY_THRESHOLD = 8; //链表转换为红黑树的阈值static final int UNTREEIFY_THRESHOLD = 6; //红黑树转换为链表的阈值static final int MIN_TREEIFY_CAPACITY = 64; //链表转换为红黑树需满足的最小容量 put方法分析12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061 public V put(K key, V value) &#123; return putVal(hash(key), key, value, false, true); &#125;// 第四个参数 onlyIfAbsent 如果是 true，那么只有在不存在该 key 时才会进行 put 操作// 第五个参数 evict 我们这里不关心final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i; //第一次put的时候table还没初始化，在resize方法中初始化table (第一次 resize 和后续的扩容有些不一样) if ((tab = table) == null || (n = tab.length) == 0) n = (tab = resize()).length; //根据hash值找到数组下标的位置，如果此位置没有值，则初始化一个node放入该位置 if ((p = tab[i = (n - 1) &amp; hash]) == null) tab[i] = newNode(hash, key, value, null); else &#123; //此位置已经有值 Node&lt;K,V&gt; e; K k; //首先判断该位置的第一个数据和我们要插入的数据，key 是不是\"相等\"，如果是，取出这个节点 if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) e = p; //如果该结点是红黑树的结点，调用红黑树的方法put进去。 else if (p instanceof TreeNode) e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value); else &#123; //到这里说明该位置上的node是一个链表 for (int binCount = 0; ; ++binCount) &#123; // 插入到链表的最后面(Java7 是插入到链表的最前面) if ((e = p.next) == null) &#123; p.next = newNode(hash, key, value, null); //链表数量达到8个转成红黑树 if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st treeifyBin(tab, hash); break; &#125; //如果找到相同key，则直接返回该结点 if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) break; p = e; &#125; &#125; //e!=null说明map已经存在key相同的，下面判断是否需要覆盖。 if (e != null) &#123; // existing mapping for key V oldValue = e.value; if (!onlyIfAbsent || oldValue == null) e.value = value; afterNodeAccess(e); return oldValue; &#125; &#125; ++modCount; // 如果 HashMap 由于新插入这个值导致 size 已经超过了阈值，需要进行扩容 //Java7中是先扩容再插入，这里是先插入再扩容 if (++size &gt; threshold) resize(); afterNodeInsertion(evict); return null; &#125; 扩容resize方法分析1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586final Node&lt;K,V&gt;[] resize() &#123; Node&lt;K,V&gt;[] oldTab = table; int oldCap = (oldTab == null) ? 0 : oldTab.length; int oldThr = threshold; int newCap, newThr = 0; if (oldCap &gt; 0) &#123; if (oldCap &gt;= MAXIMUM_CAPACITY) &#123; threshold = Integer.MAX_VALUE; return oldTab; &#125; // 将数组大小扩大一倍 else if ((newCap = oldCap &lt;&lt; 1) &lt; MAXIMUM_CAPACITY &amp;&amp; oldCap &gt;= DEFAULT_INITIAL_CAPACITY) // 将阈值扩大一倍 newThr = oldThr &lt;&lt; 1; // double threshold &#125; else if (oldThr &gt; 0) // initial capacity was placed in threshold(设置了初始容量的时候) newCap = oldThr; else &#123; // zero initial threshold signifies using defaults（默认初始容量） newCap = DEFAULT_INITIAL_CAPACITY; newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY); &#125; if (newThr == 0) &#123; float ft = (float)newCap * loadFactor; newThr = (newCap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; (float)MAXIMUM_CAPACITY ? (int)ft : Integer.MAX_VALUE); &#125; threshold = newThr; //创建一个新的数组，赋值给table Node&lt;K,V&gt;[] newTab = (Node&lt;K,V&gt;[])new Node[newCap]; table = newTab;//第一次put调用resize到这就结束了，下面是数据迁移 if (oldTab != null) &#123; // 开始遍历原数组，进行数据迁移。 for (int j = 0; j &lt; oldCap; ++j) &#123; Node&lt;K,V&gt; e; if ((e = oldTab[j]) != null) &#123; oldTab[j] = null; //如果原数组某个位置的node只有一个元素，则直接迁移到新的数组就行 if (e.next == null) newTab[e.hash &amp; (newCap - 1)] = e; //如果是红黑树，具体我们就不展开了 else if (e instanceof TreeNode) ((TreeNode&lt;K,V&gt;)e).split(this, newTab, j, oldCap); else &#123; // preserve order // 这块是处理链表的情况， // 需要将此链表拆成两个链表，放到新的数组中，并且保留原来的先后顺序 // loHead、loTail 对应一条链表，hiHead、hiTail 对应另一条链表 Node&lt;K,V&gt; loHead = null, loTail = null; Node&lt;K,V&gt; hiHead = null, hiTail = null; Node&lt;K,V&gt; next; do &#123; next = e.next; if ((e.hash &amp; oldCap) == 0) &#123; if (loTail == null) loHead = e; else loTail.next = e; loTail = e; &#125; else &#123; if (hiTail == null) hiHead = e; else hiTail.next = e; hiTail = e; &#125; &#125; while ((e = next) != null); if (loTail != null) &#123; loTail.next = null; // 第一条链表 newTab[j] = loHead; &#125; if (hiTail != null) &#123; hiTail.next = null; // 第二条链表的新的位置是 j + oldCap newTab[j + oldCap] = hiHead; &#125; &#125; &#125; &#125; &#125; return newTab; &#125; get方法分析HashMap的get操作相当简单，根据key的hash值去数组中找对应的位置的node，如果该位置第一个元素就是要找的就直接返回，否则判断node是红黑树还是链表，遍历红黑树或者链表找到对应的value返回。 123456789101112131415161718192021222324252627public V get(Object key) &#123; Node&lt;K,V&gt; e; return (e = getNode(hash(key), key)) == null ? null : e.value; &#125; final Node&lt;K,V&gt; getNode(int hash, Object key) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; first, e; int n; K k; if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (first = tab[(n - 1) &amp; hash]) != null) &#123; //头结点是的话直接返回 if (first.hash == hash &amp;&amp; // always check first node ((k = first.key) == key || (key != null &amp;&amp; key.equals(k)))) return first; if ((e = first.next) != null) &#123; //遍历红黑树查找 if (first instanceof TreeNode) return ((TreeNode&lt;K,V&gt;)first).getTreeNode(hash, key); //遍历链表查找 do &#123; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) return e; &#125; while ((e = e.next) != null); &#125; &#125; return null; &#125; HashMap线程不安全的体现 多个线程同时插入时，如果两个键的hash冲突了，有可能同时操作同一个结点，会造成数据覆盖的问题。 扩容时，会新建一个table，然后把数据迁移到新的table，如果在迁移时有线程来获取数据，就会造成获取数据为空。 hashCode的计算1234static final int hash(Object key) &#123; int h; return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16);&#125; HashMap的hash值都是通过将key的hashCode()高16位与低16位进行异或运算，这样可以保留高位的特征，避免一些key的hashCode高位不同，低位相同，造成hash冲突。 HashMap扩容扩容过程HashMap有一个负载因子，默认0.75，当容量达到最大容量0.75时，发生扩容，新的容量为原来的两倍。然后遍历老的数组，当数组结点只有一个元素时，直接通过hash计算放入新的数组；当数组结点是红黑树时，进行红黑树的处理；当数组结点时一个链表时，遍历链表，根据hash&amp;(2\\length)是0还是1判断放入oldIndex还是oldIndex+length。 扩容是否需要rehash在Java8以后，不再需要rehash了，元素存储在数组中的位置是根据hash%length来决定的，扩容之后length变成2*length，由于length是2的N次幂，hash&amp;(2*length)的最后结果只有0或者1，当是0时，元素在数组中的位置还是之前的oldIndex，当是1时，元素在数组中的位置变成了oldIndex+length。（这个在上面的源码中也体现了）。 HashMap的容量必须是2的N次幂，因为： 计算数组位置时，因为hash&amp;(length-1)=hash%length，可以通过hash&amp;(length-1)来计算，位运算的效率更高。 方便扩容时不用rehash，直接根据hash&amp;(2*length)的结果是0还是1来判断新的位置。 ConcurrentHashMapJava8的ConcurrentHashMap底层结构和HashMap是一致的，不过由于要保证线程安全，使用了cas和synchronized锁。Java7的ConcurrentHashMap使用了分段锁，引入了Segment，一个ConcurrentHashMap由Segment数组组成，Segment继承了ReentrantLock来进行加锁，所以每次操作时只需要对每个Segment进行加锁，其他Segment不受影响，这样并发度就高了。 put方法分析1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980 public V put(K key, V value) &#123; return putVal(key, value, false); &#125; final V putVal(K key, V value, boolean onlyIfAbsent) &#123; if (key == null || value == null) throw new NullPointerException(); //计算hash值 int hash = spread(key.hashCode()); int binCount = 0; //无限循环，直到put成功 for (Node&lt;K,V&gt;[] tab = table;;) &#123; Node&lt;K,V&gt; f; int n, i, fh; //tab==null或者长度为0，初始化table if (tab == null || (n = tab.length) == 0) tab = initTable(); //根据hash值找到tab结点，并得到首结点f else if ((f = tabAt(tab, i = (n - 1) &amp; hash)) == null) &#123; //当f为null，则使用cas将该f结点设置为需要添加的结点，成功跳出循环，失败继续循环 if (casTabAt(tab, i, null, new Node&lt;K,V&gt;(hash, key, value, null))) break; // no lock when adding to empty bin &#125; else if ((fh = f.hash) == MOVED) //f结点的hash值为-1，则说明正在扩容，需要去帮助扩容 tab = helpTransfer(tab, f); else &#123; //到这里说明f结点不为null， V oldVal = null; synchronized (f) &#123; if (tabAt(tab, i) == f) &#123; //头结点的hash值大于0说明是链表 if (fh &gt;= 0) &#123; binCount = 1; // 用于记录链表长度 for (Node&lt;K,V&gt; e = f;; ++binCount) &#123; K ek; //如果找到了相等的key，则判断是否需要覆盖 if (e.hash == hash &amp;&amp; ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek)))) &#123; oldVal = e.val; if (!onlyIfAbsent) e.val = value; break; &#125; //将新结点插入链表最后 Node&lt;K,V&gt; pred = e; if ((e = e.next) == null) &#123; pred.next = new Node&lt;K,V&gt;(hash, key, value, null); break; &#125; &#125; &#125; else if (f instanceof TreeBin) &#123; //红黑树 Node&lt;K,V&gt; p; binCount = 2; //调用红黑树的插值方法插入新节点 if ((p = ((TreeBin&lt;K,V&gt;)f).putTreeVal(hash, key, value)) != null) &#123; oldVal = p.val; if (!onlyIfAbsent) p.val = value; &#125; &#125; &#125; &#125; if (binCount != 0) &#123; // 判断是否要将链表转换为红黑树 if (binCount &gt;= TREEIFY_THRESHOLD) treeifyBin(tab, i); if (oldVal != null) return oldVal; break; &#125; &#125; &#125; addCount(1L, binCount); return null;&#125; 初始化table1234567891011121314151617181920212223242526private final Node&lt;K,V&gt;[] initTable() &#123; Node&lt;K,V&gt;[] tab; int sc; while ((tab = table) == null || tab.length == 0) &#123; //sizeCtl&lt;0说明有其他线程正在初始化table if ((sc = sizeCtl) &lt; 0) Thread.yield(); // lost initialization race; just spin //使用cas将sizeCtl设置为-1，代表初始化table。 else if (U.compareAndSwapInt(this, SIZECTL, sc, -1)) &#123; try &#123; if ((tab = table) == null || tab.length == 0) &#123; int n = (sc &gt; 0) ? sc : DEFAULT_CAPACITY; //初始化数组，长度为默认的16或者初始化时提供的长度 Node&lt;K,V&gt;[] nt = (Node&lt;K,V&gt;[])new Node&lt;?,?&gt;[n]; table = tab = nt; // 如果 n 为 16 的话，那么这里 sc = 12 // 其实就是 0.75 * n sc = n - (n &gt;&gt;&gt; 2); &#125; &#125; finally &#123; sizeCtl = sc; &#125; break; &#125; &#125; return tab; &#125; 参考资料：Java7/8 中的 HashMap 和 ConcurrentHashMap 全解析","categories":[{"name":"Java","slug":"Java","permalink":"http://yoursite.com/categories/Java/"}],"tags":[{"name":"集合","slug":"collection","permalink":"http://yoursite.com/tags/collection/"}],"keywords":[{"name":"Java","slug":"Java","permalink":"http://yoursite.com/categories/Java/"}]},{"title":"分布式锁介绍及其实现方式","slug":"distributedLock","date":"2019-01-15T03:15:14.000Z","updated":"2020-01-16T09:05:12.232Z","comments":true,"path":"distributed/distributedLock.html","link":"","permalink":"http://yoursite.com/distributed/distributedLock.html","excerpt":"&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;提到锁，我们最先想到的是Java的synchronized关键字和JUC包中的ReentrantLock，这两个锁可以满足我们在多线程中对共享资源的安全访问，但是随着分布式的发展，本地锁已经没办法满足我们的需求了。为了在分布式环境也能对一个共享资源进行安全访问，我们需要引入分布式锁。","text":"&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;提到锁，我们最先想到的是Java的synchronized关键字和JUC包中的ReentrantLock，这两个锁可以满足我们在多线程中对共享资源的安全访问，但是随着分布式的发展，本地锁已经没办法满足我们的需求了。为了在分布式环境也能对一个共享资源进行安全访问，我们需要引入分布式锁。 分布式锁特点 互斥性：和本地锁一样，必须保证只有一个线程能够获取到锁。 可重入性：同一个节点的同一个线程获取到锁之后可以再次获取同一把锁。 锁超时：分布式锁应该有一个超时时间，这样可以防止死锁。 高效，高可用：加锁和解锁必须性能高效，同时也需要保证高可用防止分布式锁失效。 支持阻塞和非阻塞(可选)：和ReentrantLock一样支持lock和trylock以及tryLock(long timeOut)。 支持公平锁和非公平锁(可选)：公平锁的意思是按照请求加锁的顺序获得锁，非公平锁就相反是无序的。这个一般可以不用实现。 分布式锁实现方式分布式锁的实现方式有很多种，一般主要有以下几种： 基于数据库实现 基于Redis实现 基于Zookeeper实现 自研分布式锁(如谷歌的Chubby) 基于数据库实现基于数据库实现分布式锁主要有两张方案，但是他们也都有一些缺陷。 利用主键唯一规则： 利用数据库主键唯一规则，当有多个插入请求同时提交到数据库时，数据库可以保证只有一条数据能插入成功，这样可以认为插入数据成功的那个线程获取到了锁，当方法执行完毕后，删除这条数据库记录即可释放锁。 这种方式依赖数据库的可用性，所以要保证高可用就必须部署数据库集群。其次这把锁没有失效时间，一旦解锁失败，会导致锁一直存在，其他线程不能再次获取锁，解决方案是有定时任务一直去删除过期的锁。另外要保证阻塞的话，需要我们手动去循环获取锁。这把锁是非重入的，同一个线程在没有释放锁之前无法再次获得该锁。因为数据中数据已经存在了，要解决这个需要记录获取锁的主机信息以及线程信息，并同时用一个count字段记录获取锁的次数。最后这把锁是非公平锁，所有等待锁的线程凭运气去争夺锁，要实现成公平锁需要另外建一张表顺序记录获取锁的线程。 利用数据库行锁特性： 在查询语句后面显示加for update，这样可以利用行级锁的排他性来实现分布式锁，需要释放锁的时候直接commit就可以了。 这种方式有两个比较大的问题：一是利用事务进行加锁的时候，query需要占用数据库连接，在行锁的时候连接不释放，这就会导致连接池爆满。二是mysql使用行锁时默认要走索引，但是有时mysql根据执行计划认为全表扫描效率更高的时候就会将行锁升级为表锁，解决这个问题的话需要我们查询的时候显式制定索引。 基于Redis实现基于redis来实现分布式锁主要方案就是： 加锁： 使用SET key value [EX seconds] [PX milliseconds] [NX] 命令来实现加锁。这个命令一共五个参数：第一个为key，我们使用key来当锁，因为key是唯一的；第二个为value，我们传的是requestId，这个requestId在解锁时需要用到，保证解锁的是加锁的那个线程；第三四个代表设置过期时间；最后一个参数需要使用NX，代表当key不存在的时候写入。 有些人会使用setnx和expire两个命令代替上面的方式，但是这样会有一个问题，由于这两个操作不是原子的，如果在setnx之后expire失败了，就会导致锁没有过期时间，这样会造成死锁。 解锁： 我们使用Lua脚本来实现解锁操作 12String script = &quot;if redis.call(&apos;get&apos;, KEYS[1]) == ARGV[1] then return redis.call(&apos;del&apos;, KEYS[1]) else return 0 end&quot;;Object result = jedis.eval(script, Collections.singletonList(lockKey), Collections.singletonList(requestId)); 解锁操作使用eval命令执行一段Lua脚本，首先获取锁对应的value值，检查是否与requestId相等，如果相等则删除锁（解锁）。使用Lua脚本可以保证原子性； 基于redis实现分布式还有其他方式，比如基于Redlock和基于redisson来实现，这两种方式没做研究，这里不做过多介绍。 基于Zookeeper实现Zookeeper是一个分布式一致性协调框架，主要可以实现选主、配置管理和分布式锁等常用功能，因为Zookeeper的写入都是顺序的，在一个节点创建之后，其他请求再次创建便会失败，同时可以对这个节点进行Watch，如果节点删除会通知其他节点抢占锁。Zookeeper实现分布式锁虽然是比较重量级的，但实现的锁功能十分健全。 总结基于数据库实现的方式还是比较复杂，而且性能也不高，不推荐使用。 基于redis实现的方式比较简单，性能也比较好，引入redis集群可以保证高可用，推荐大家使用redis的方式实现。 基于Zookeeper实现的方式比较重，同时还需要维护Zookeeper集群，实现起来还是比较复杂的，实现不好的话还会引起“羊群效应”。如果不是原有系统就依赖Zookeeper，同时压力不大的情况下。一般不使用Zookeeper实现分布式锁。","categories":[{"name":"分布式","slug":"distributed","permalink":"http://yoursite.com/categories/distributed/"}],"tags":[{"name":"distributed","slug":"distributed","permalink":"http://yoursite.com/tags/distributed/"},{"name":"lock","slug":"lock","permalink":"http://yoursite.com/tags/lock/"}],"keywords":[{"name":"分布式","slug":"distributed","permalink":"http://yoursite.com/categories/distributed/"}]},{"title":"一文详解Redis","slug":"redis","date":"2019-01-10T10:03:34.000Z","updated":"2020-01-16T09:06:29.613Z","comments":true,"path":"middleware/redis.html","link":"","permalink":"http://yoursite.com/middleware/redis.html","excerpt":"Redis是一个开源的，基于内存的，也可进行持久化的，基于C语言编写的存储数据库。Redis能达到11w的QPS。Redis这么快的原因主要有以下几点: 完全基于内存，数据全部存储在内存中，读取时没有磁盘IO，所以速度非常快。 Redis采用单线程的模型，没有上下文切换的开销，也没有竞态条件，不用去考虑各种锁的问题，不存在加锁释放锁操作，没有因为可能出现死锁而导致的性能消耗。","text":"Redis是一个开源的，基于内存的，也可进行持久化的，基于C语言编写的存储数据库。Redis能达到11w的QPS。Redis这么快的原因主要有以下几点: 完全基于内存，数据全部存储在内存中，读取时没有磁盘IO，所以速度非常快。 Redis采用单线程的模型，没有上下文切换的开销，也没有竞态条件，不用去考虑各种锁的问题，不存在加锁释放锁操作，没有因为可能出现死锁而导致的性能消耗。 Redis项目中使用的数据结构都是专门设计的，例如SDS(简单动态字符串)是对C语言中的字符串频繁修改时，会频繁地进行内存分配，十分消耗性能，而SDS会使用空间预分配和惰性空间释放来避免这些问题的出现。 采用多路复用IO模型，可以同时监测多个流的IO事件能力，在空闲时，会把当前线程阻塞掉，当有一个或多个流有I/O事件时，就从阻塞态唤醒，轮询那些真正发出了事件的流，并只依次顺序的处理就绪的流。可以让单个线程高效的处理多个连接请求（尽量减少网络 I/O 的时间消耗)。 Redis使用场景 取最新N个数据的操作：可以将数据存在redis的list中。 排行榜应用，取TOP N操作：这个可以将数据存入sorted set中，把排序值设为score，根据score进行排序。 需要精准设定过期时间的应用： 计数器应用：redis的命令都是原子性的，你可以轻松的利用incr，decr命令来构建计数器系统。 unique操作，获取所有数据的排重值：可以使用redis的set pub/sub构建实时消息系统 构建队列系统 缓存 Redis和Memcached的区别 数据类型支持不同Memcached仅支持简单的key-value结构的数据记录不同，Redis支持的数据类型要丰富得多。最为常用的数据类型主要由五种：String、Hash、List、Set和Sorted Set。Memcached单个key-value大小有限，一个value最大只支持1MB，而Redis最大支持512MB 内存管理机制不同在Redis中，并不是所有的数据都一直存储在内存中的。这是和Memcached相比一个最大的区别。当物理内存用完时，Redis可以将一些很久没用到的value交换到磁盘。Redis只会缓存所有的key的信息，如果Redis发现内存的使用量超过了某一个阀值，将触发swap的操作.Redis和Memcached虽然都是基于C语言开发的，但是为了提高内存的管理效率，高效的内存管理方案都不会直接使用malloc/free调用。Redis和Memcached均使用了自身设计的内存管理机制，但是实现方法存在很大的差异。Memcached默认使用Slab Allocation机制管理内存，其主要思想是按照预先规定的大小，将分配的内存分割成特定长度的块以存储相应长度的key-value数据记录，以完全解决内存碎片问题。Redis每一个数据块都是根据数据类型和大小进行分配的，这一块数据的元数据（比如数据块大小）会存入内存块的头部。Redis使用现场申请内存的方式来存储数据，并且很少使用free-list等方式来优化内存分配，会在一定程度上存在内存碎片，Redis跟据存储命令参数，会把带过期时间的数据单独存放在一起，并把它们称为临时数据，非临时数据是永远不会被剔除的，即便物理内存不够，导致swap也不会剔除任何非临时数据（但会尝试剔除部分临时数据），这点上Redis更适合作为存储而不是cache。 数据持久化支持Redis虽然是基于内存的存储系统，但是它本身是支持内存数据的持久化的，而且提供两种主要的持久化策略：RDB快照和AOF日志。而Memcached是不支持数据持久化操作的。 集群管理的不同Memcached本身并不支持分布式，因此只能在客户端通过像一致性哈希这样的分布式算法来实现Memcached的分布式存储。当客户端向Memcached集群发送数据之前，首先会通过内置的分布式算法计算出该条数据的目标节点，然后数据会直接发送到该节点上存储。但客户端查询数据时，同样要计算出查询数据所在的节点，然后直接向该节点发送查询请求以获取数据。Redis Cluster是一个实现了分布式且允许单点故障的Redis高级版本，它没有中心节点，具有线性可伸缩的功能。为了保证单点故障下的数据可用性，Redis Cluster引入了Master节点和Slave节点。在Redis Cluster中，每个Master节点都会有对应的两个用于冗余的Slave节点。这样在整个集群中，任意两个节点的宕机都不会导致数据的不可用。当Master节点退出后，集群会自动选择一个Slave节点成为新的Master节点。 Redis数据结构Redis共有5种数据结构：string，list，set，zset，hash。 Redis内部使用一个redisObject对象来表示所有的key和value。redisObject的源码如下所示： 1234567891011121314 typedef struct redisObject &#123; // 类型 unsigned type:4; // 编码 unsigned encoding:4; // 指向底层实现数据结构的指针 void *ptr; // ...&#125; robj; type字段对应redis的5种数据结构。 encoding字段记录对象使用的编码(数据结构)，可以通过命令 object encoding key 来查看redis对象中的encoding。redis主要有以下11种encoding。 stringstring是Redis最常用的数据结构，应用场景也比较广泛，可以用于缓存，计数器，用户session共享等。 listList 是有序列表，和java的list很像，我们可以通过 List 存储一些列表型的数据结构，类似首页推荐列表、文章的评论列表之类的东西。通过 lrange 命令，读取某个闭区间内的元素，可以基于 List 实现分页查询，这个是很棒的一个功能，基于 Redis 实现简单的高性能分页，可以做类似微博那种下拉不断分页的东西，性能高。 setSet 是无序集合，类似java的set，也可以去重。set可以存储一些需要去重的数据，虽然java的HashSet可以做到，但是我们的项目一般都是分布式的，需要全局去重，这时使用Redis的set再好不过了。Set可以用来存储好友列表，这样可以通过set的取交集，差集等操作获取共同好友等。 Sorted setSorted set 是排序的 Set，去重但可以排序，写进去的时候给一个分数，自动根据分数排序。有序集合的使用场景与集合类似，但是set集合不是自动有序的，而Sorted set可以利用分数进行成员间的排序，而且是插入时就排序好。所以当你需要一个有序且不重复的集合列表时，就可以选择Sorted set数据结构作为选择方案。排行榜：有序集合经典使用场景。例如视频网站需要对用户上传的视频做排行榜，榜单维护可能是多方面：按照时间、按照播放量、按照获得的赞数等。用Sorted Sets来做带权重的队列，比如普通消息的score为1，重要消息的score为2，然后工作线程可以选择按score的倒序来获取工作任务。让重要的任务优先执行。 hash这个是类似 Map 的一种结构，这个一般就是可以将结构化的数据，比如一个对象（前提是这个对象没嵌套其他的对象）给缓存在 Redis 里，然后每次读写缓存的时候，可以就操作 Hash 里的某个字段。一般可以使用hash存储用户的信息。 Redis持久化Redis 提供了 RDB 和 AOF 两种持久化方式，RDB 是把内存中的数据集以快照形式写入磁盘，实际操作是通过 fork 子进程执行，采用二进制压缩存储；AOF 是以文本日志的形式记录 Redis 处理的每一个写入或删除操作。RDB持久化的特点是：文件小，恢复快，不影响性能，实时性低。AOF持久化的特点是：文件大，恢复慢，性能影响大，实时性高。 对于两种方式的选择，如果可以接受丢失十几分钟及更长时间的数据，可以选择RDB持久化，对性能影响小，如果只能接受秒级的数据丢失，只能选择AOF持久化。 AOF如果配置是everysec那么会每秒执行fsync操作，调用write写入磁盘一次，但是如果硬盘负载过高，fsync操作可能会超过1s，Redis主线程持续高速向aof_buf写入命令，硬盘的负载可能会越来越大，IO资源消耗更快，所以Redis的处理逻辑是会对比上次fsync成功的时间，如果超过2s，则主线程阻塞直到fsync同步完成，所以最多可能丢失2s的数据，而不是1s。 为了防止AOF文件越来越大，可以通过执行BGREWRITEAOF命令，会fork子进程出来，读取当前数据库的键值对信息，生成所需的写命令，写入新的AOF文件。在生成期间，父进程继续正常处理请求，执行修改命令后，不仅会将命令写入aof_buf缓冲区，还会写入重写aof_buf缓冲区。当新的AOF文件生成完毕后，子进程父进程发送信号，父进程将重写aof_buf缓冲区的修改命令写入新的AOF文件，写入完毕后，对新的AOF文件进行改名，原子的地替换旧的AOF文件。 Redis过期策略 惰性清除：在访问key时，如果发现key已经过期，那么会将key删除。 过期清理：Redis有定时任务会对过期的key进行清理(这个不会扫描所有过期的key)。 内存淘汰：当执行写入命令时，如果发现内存不够，那么就会按照配置的淘汰策略清理内存，淘汰策略主要由以下几种： noeviction：不删除，达到内存限制时，直接不执行命令返回错误信息。 allkeys-lru：在所有key中，使用LRU算法，优先删除最近没有使用的key。 allkeys-random：在所有key中，随机删除一部分key。 volatile-lru：在设置了过期时间的key中，使用LRU算法，优先删除最近没有使用的key。 volatile-random：在设置了过期时间的key中，随机删除一部分key。 volatile-ttl：在设置了过期时间的key中，优先删除过期时间短的key。 allkeys-lfu：在所有key中，使用LFU算法，优先删除最少使用的key。 volatile-lfu：在设置了过期时间的key中，使用LFU算法，优先删除最少使用的key。 Redis部署方式Redis主要有四种部署方式：单点（Standalone），主从（Master-Slave），哨兵（Sentinel），集群（Cluster）。 单点最简单的部署方式，采用单个redis节点进行部署。不能保证高可用，也不能实现读写分离，一般生产环境不会采用这种方式。 主从采用多个redis节点进行部署，其中一个为master节点，其他为slave节点，主从节点一般部署在不同机器上。主从模式同样不能保证高可用，主节点挂了之后需手动将从节点切换成主节点，但是可以实现读写分离，一定程度上提高吞吐量。 哨兵Redis Sentinel是社区版本推出的原生高可用解决方案，其部署架构主要包括两部分：Redis Sentinel集群和Redis数据集群。其中Redis Sentinel集群是由若干Sentinel节点组成的分布式集群，可以实现故障发现、故障自动转移、配置中心和客户端通知。Redis Sentinel的节点数量要满足2n+1（n&gt;=1）的奇数个。哨兵模式工作原理： 认定主节点主观下线：哨兵节点会定时向主节点发送ping命令，如果没有回复，代表主节点主观下线。 认定主节点客观下线：哨兵节点认定主节点主观下线后，会向其他哨兵节点发送sentinel is-master-down-by-addr命令，获取其他哨兵节点对该主节点的状态，当认定主节点下线的哨兵数量超过半数时，就认定主节点客观下线。 进行领导者哨兵选举：认定主节点客观下线后,各个哨兵之间相互通信，选举出一个领导者哨兵，由它来对主节点进行故障转移操作。 领导者哨兵进行故障转移：领导者哨兵节点首先会从从节点中选出一个节点作为新的主节点，向这个从节点发送slaveof no one命令，让其成为主节点，通过slaveof 命令让其他从节点成为它的从节点，将已下线的主节点更新为新的主节点的从节点。 集群Redis Cluster是社区版推出的Redis分布式集群解决方案，主要解决Redis分布式方面的需求，比如，当遇到单机内存，并发和流量等瓶颈的时候，Redis Cluster能起到很好的负载均衡的目的。Redis Cluster集群节点最小配置6个节点以上（3主3从），其中主节点提供读写操作，从节点作为备用节点，不提供请求，只作为故障转移使用。Redis Cluster没有使用一致性hash，而是采用虚拟槽分区，所有的键根据哈希函数映射到0～16383个整数槽内，每个节点负责维护一部分槽以及槽所印映射的键值数据。Redis Cluster并不支持处理多个keys的命令，因为这需要在不同的节点间移动数据，从而达不到像Redis那样的性能，在高负载的情况下可能会导致不可预料的错误。","categories":[{"name":"middleware","slug":"middleware","permalink":"http://yoursite.com/categories/middleware/"}],"tags":[{"name":"redis","slug":"redis","permalink":"http://yoursite.com/tags/redis/"}],"keywords":[{"name":"middleware","slug":"middleware","permalink":"http://yoursite.com/categories/middleware/"}]},{"title":"Java NIO详解","slug":"nio","date":"2018-10-24T10:26:20.000Z","updated":"2018-10-27T06:32:32.604Z","comments":true,"path":"Java/nio.html","link":"","permalink":"http://yoursite.com/Java/nio.html","excerpt":"1.NIO概念 NIO与传统IO相比最大的特点就是非阻塞。IO是阻塞的，当一个线程调用read或write方法时，线程必须等待文件读取完或者写完才能去执行其他任务；而NIO是非阻塞的，它允许线程请求从通道中读取数据，如果当前没有可用数据，线程可以继续执行其他操作，而不是一直阻塞。","text":"1.NIO概念 NIO与传统IO相比最大的特点就是非阻塞。IO是阻塞的，当一个线程调用read或write方法时，线程必须等待文件读取完或者写完才能去执行其他任务；而NIO是非阻塞的，它允许线程请求从通道中读取数据，如果当前没有可用数据，线程可以继续执行其他操作，而不是一直阻塞。 2.NIO主要组件NIO包含三个主要的类： Buffer Channel Selector NIO有许多类组成，但是buffer，channel和selector构成了核心的API。所以接下来会主要介绍这三个类。通常，NIO中的所有IO都是以channel开始。Channel其实和IO中的stream差不多。通过channel数据能被写入buffer中，同样数据能从buffer中写入channel。如下图： Buffer和Channel的主要子类如下所示： ByteBuffer -&gt;MappedByteBuffer(实现内存映射文件) CharBuffer ShortBuffer IntBuffer FloatBuffer DoubleBuffer LongBuffer FileChannel DatagramChannel SocketChannel ServerSocketChannel Selector允许一个线程操作多个Channel。如果你的应用程序打开了很多连接（Channel），但是每个连接上的通信量很低，那么这时候Selector就很方便。比如聊天服务器。下图说明了selector和channel的关系： 3.Buffer 3.1 Capacity、Position、Limitbuffer主要有三个属性：capacity、position和limit。 capacity：buffer的容量，我们在分配buffer时会指定一个容量。当buffer达到容量之后需要清除数据才能继续向buffer中写入数据。 position：buffer中数据写入的位置。初始为0，往buffer写入或读取一字节数据，position就会加1，当清除buffer 中数据或者由写模式切换为读模式时，position会重新置0，postion最大为capacity-1。 limit：在写模式中，limit就等于buffer的capacity。在读模式中，limit是指可以从buffer中读取的数据量的限制。 3.2 Allocating a Buffer想要得到一个buffer首先必须分配它，每个Buffer类中都提供了一个静态方法allocate()来分配buffer。 12ByteBuffer buf = ByteBuffer.allocate(2048);CharBuffer buf = CharBuffer.allocate(1024); 3.3 Writing Data to a Buffer往buffer中写入数据有两种方式： 一是调用buffer的put方法写入数据，如buf.put(127)； 二是将数据通过channel写入buffer，如int num = channel.read(buf);flip()方法是将buffer从写模式切换到读模式，这个会重新设置position和limit的值。 3.4 Reading Data from a Buffer从buffer中读取数据也有两种方式： 一是调用buffer的get方式读取数据，如buf.get()； 二是读取buffer数据到channel中，如int bytesWritten = inChannel.write(buf); 3.5 rewind()、clear()、compact() rewind()可以将position值重新置为0，这样就可以重新读取buffer中的数据。 clear()方法将设置poistion为0，设置limit为capacity，clear虽然不会清除buffer中的数据，但是后续写入的数据会覆盖之前的数据，相当于清空了buffer数据。 compact()和clear不同，它会将之前的数据移向左边，将position设置为最后一个未读数据，从这个基础上再开始写入。 3.6 mark()、reset()调用mark()方法可以标记当前buffer中的position，执行一些操作之后调用reset()可以可以将position回到刚才标记的位置。12345buffer.mark();//call buffer.get() a couple of times, e.g. during parsing.buffer.reset(); //set position back to mark. 4.Channel所有的NIO操作都是始于channel，数据的读取和写入都会经过channel。 4.1 FileChannel(文件通道，用于文件的读和写)不能设置为非阻塞模式，只能是阻塞模式 Open a FileChannel使用一个FileChannel之前必须先打开它，但是不可能直接打开FileChannel，必须通过InputStream，OutputStream或者RandomAccessFile来获取一个FileChannel。RandomAccessFile aFile = new RandomAccessFile(&quot;data/nio-data.txt&quot;, &quot;rw&quot;);FileChannel inChannel = aFile.getChannel(); Read Data from a FileChannelByteBuffer buf = ByteBuffer.allocate(48);int bytesRead = inChannel.read(buf);上面bytesRead如果返回-1，说明读取完了 Write Data to a FileChannelString newData = &quot;New String to write to file...&quot; + System.currentTimeMillis();ByteBuffer buf = ByteBuffer.allocate(48);buf.clear();buf.put(newData.getBytes());buf.flip();while(buf.hasRemaining()) {channel.write(buf);} Close a FileChannelchannel.close() FileChannel Position当你想在一个特定位置读取或写入FileChannel，你可以通过position()方法获取FileChannel的当前位置，然后你可以通过position(long newPosition)方法设置新的postiion。long pos=channel.position();channel.position(pos + 123); FileChannel SizeFileChannel对象的size()方法返回通道连接的文件的文件大小。 FileChannel Truncate调用FileChannel.truncate()方法来截断文件。当您截断一个文件时，您将它以给定的长度截断。channel.truncate(1024); FileChannel Forceforce()方法将所有未写入的数据从通道刷新到磁盘。force()方法以一个布尔值作为参数，告诉文件元数据(权限等)是否也应该刷新。 4.2 SocketChannel(用于通过TCP读写数据)SocketChannel是连接到TCP网络套接字的通道。它相当于Java NIO的Java网络套接字。打开一个SocketChannel的代码如下：SocketChannel socketChannel = SocketChannel.open();socketChannel.connect(new InetSocketAddress(&quot;http://xxx.com&quot;, 80));SocketChannel的读写和FileChannel没什么区别。 4.3 ServerSocketChannel(TCP对应的服务端，用来某个端口进来的请求)ServerSocketChannel可以用来监听进来的tcp连接，就像java标准网络中的ServerSocket。 12345678910//实例化ServerSocketChannel serverSocketChannel = ServerSocketChannel.open();//监听端口serverSocketChannel.socket().bind(new InetSocketAddress(9999));while(true)&#123; //监听进来的tcp连接，创建SocketChannel SocketChannel socketChannel = serverSocketChannel.accept(); //do something with socketChannel...&#125; 4.4 DatagramChannel(用于通过UDP从网络上读写数据)DatagramChannel是一个能够发送和接收UDP包的通道，由于UDP是无连接的，所以在默认情况下，您不能像从其他通道那样读写DatagramChannel。你只可以发送和接收数据包。监听端口 12DatagramChannel channel = DatagramChannel.open();channel.socket().bind(new InetSocketAddress(9999)); 接收数据123ByteBuffer buf = ByteBuffer.allocate(48);buf.clear();channel.receive(buf); 发送数据 123456String newData = &quot;New String to write to file...&quot;+ System.currentTimeMillis();ByteBuffer buf = ByteBuffer.allocate(48);buf.clear();buf.put(newData.getBytes());buf.flip();int bytesSent = channel.send(buf, new InetSocketAddress(&quot;xxx.com&quot;, 80)); 4.5 Channel Transfers在NIO中，如果其中一个channel是FileChannel时，则可以将数据直接从一个通道传到另一个通道。FileChannel中的transferFrom()方法能够将数据从一个源通道传送到FileChannel中。1234567RandomAccessFile fromFile = new RandomAccessFile(&quot;fromFile.txt&quot;, &quot;rw&quot;);FileChannel fromChannel = fromFile.getChannel();RandomAccessFile toFile = new RandomAccessFile(&quot;toFile.txt&quot;, &quot;rw&quot;);FileChannel toChannel = toFile.getChannel();long position = 0;long count = fromChannel.size();toChannel.transferFrom(fromChannel, position, count); FileChannel中的transferTo()方法可以将数据从FileChannel中传送到其他通道。1234567RandomAccessFile fromFile = new RandomAccessFile(&quot;fromFile.txt&quot;, &quot;rw&quot;);FileChannel fromChannel = fromFile.getChannel();RandomAccessFile toFile = new RandomAccessFile(&quot;toFile.txt&quot;, &quot;rw&quot;);FileChannel toChannel = toFile.getChannel();long position = 0;long count = fromChannel.size();fromChannel.transferTo(position, count, toChannel); 5.SelectorSelector可以检查一个或多个channel，并确定哪些channel准备就绪。通过这种方式，一个线程可以管理多个channel，从而管理多个网络连接。 5.1 创建Selector和注册Channel到Selector1234Selector selector = Selector.open();//设置为非阻塞模式channel.configureBlocking(false);SelectionKey key = channel.register(selector, SelectionKey.OP_READ); 上面第二行用于设置非阻塞模式，由于Selector必须工作在非阻塞模式中，所以FileChannel不能使用Selector。register方法的第二个参数是一个int型参数（使用二进制标记位，叫interest set），用于表明channel需要监听哪些感兴趣的事件，共有以下四种事件。 Read对应SelectionKey.OP_READ(值为1&lt;&lt;0)，表示channel可以读取数据。 Write对应SelectionKey.OP_WRITE(值为1&lt;&lt;2)，表示channel可以写入数据。 Connect对应SelectionKey.OP_CONNECT(值为1&lt;&lt;3)，表示channel建立连接。 Accept对应SelectionKey.OP_ACCEPT(值为1&lt;&lt;4)，表示channel可以接收传入的连接。 如果想要设置多个事件，则将对应的key进行与操作。如下： 1int interestSet = SelectionKey.OP_READ | SelectionKey.OP_WRITE; 5.2 SelectionKey上面注册channel时register方法会返回一个SelectionKey对象。这个SelectionKey对象包含以下属性： Interest SetInterest Set中是channel感兴趣的事件集合，你可以通过下面的方法获取Interest Set。 123456int interestSet = selectionKey.interestOps();boolean isInterestedInAccept = interestSet &amp; SelectionKey.OP_ACCEPT;boolean isInterestedInConnect = interestSet &amp; SelectionKey.OP_CONNECT;boolean isInterestedInRead = interestSet &amp; SelectionKey.OP_READ;boolean isInterestedInWrite = interestSet &amp; SelectionKey.OP_WRITE; Ready SetReady Set 表示的是channel已经准备好的事件集合。通常在选择一个channel之后来访问这个集合。 12345int readySet = selectionKey.readyOps();selectionKey.isAcceptable();selectionKey.isConnectable();selectionKey.isReadable();selectionKey.isWritable(); Channel + Selector获取channel和selector比较简单。 12Channel channel = selectionKey.channel();Selector selector = selectionKey.selector(); Attaching Objects可以将对象附加到SelectionKey对象上，这是识别channel或者将信息附加到channel上的方便方法。 123selectionKey.attach(theObject);Object attachedObj = selectionKey.attachment(); 也可以在register的时候附加对象。 1SelectionKey key = channel.register(selector, SelectionKey.OP_READ, theObject); 5.3 Select Channel通过Selector的select方法我们可以选择一个channel。select方法主要有三个： select()：这个方法会阻塞直到至少一个channel准备好。 select(long timeout)：和select()功能类似，只是制定了阻塞时间。 selectNow()：这个不会阻塞，不管有没有准备好的channel，都会立即返回。 上面select方法的返回值是一个int，表示有多少个通道准备好。如果没有对第一个准备好的通道做任何操作，那么会有两个准备好的通道，但是在每个select()调用之间只有一个通道准备好。 wakeUp()：这个方法是用来唤醒等待在 select() 和 select(timeout) 上的线程的。如果 wakeup() 先被调用，此时没有线程在 select 上阻塞，那么之后的一个 select() 或 select(timeout) 会立即返回，而不会阻塞，当然，它只会作用一次。 5.5 Full Selector Example1234567891011121314151617181920212223242526272829303132333435363738Selector selector = Selector.open();channel.configureBlocking(false);SelectionKey key = channel.register(selector, SelectionKey.OP_READ);while(true) &#123; int readyChannels = selector.select(); if(readyChannels == 0) continue; Set&lt;SelectionKey&gt; selectedKeys = selector.selectedKeys(); Iterator&lt;SelectionKey&gt; keyIterator = selectedKeys.iterator(); while(keyIterator.hasNext()) &#123; SelectionKey key = keyIterator.next(); if(key.isAcceptable()) &#123; // a connection was accepted by a ServerSocketChannel. &#125; else if (key.isConnectable()) &#123; // a connection was established with a remote server. &#125; else if (key.isReadable()) &#123; // a channel is ready for reading &#125; else if (key.isWritable()) &#123; // a channel is ready for writing &#125; keyIterator.remove(); &#125;&#125; 6.NIO PipeNIO Pipe是两个线程之间一个单向的数据连接。Pipe有一个source channel和一个sink channel。将数据写入sink channel，然后可以从source channel读取这些数据。123456789101112131415161718//open pipePipe pipe = Pipe.open();//write data to sink channelPipe.SinkChannel sinkChannel = pipe.sink();String newData = &quot;New String to write to file...&quot; + System.currentTimeMillis();ByteBuffer buf = ByteBuffer.allocate(48);buf.clear();buf.put(newData.getBytes());buf.flip();while(buf.hasRemaining()) &#123; sinkChannel.write(buf);&#125;//read data from source channelPipe.SourceChannel sourceChannel = pipe.source();ByteBuffer buf = ByteBuffer.allocate(48);int bytesRead = sourceChannel.read(buf);","categories":[{"name":"Java","slug":"Java","permalink":"http://yoursite.com/categories/Java/"}],"tags":[{"name":"nio","slug":"nio","permalink":"http://yoursite.com/tags/nio/"}],"keywords":[{"name":"Java","slug":"Java","permalink":"http://yoursite.com/categories/Java/"}]},{"title":"二叉搜索树Java实现","slug":"bst","date":"2018-10-23T12:16:13.000Z","updated":"2020-01-17T07:58:50.325Z","comments":true,"path":"data-struct/bst.html","link":"","permalink":"http://yoursite.com/data-struct/bst.html","excerpt":"二叉搜索树特性： 具有二叉树的所有特性。 左节点的值永远小于根结点。 有节点的值永远大于根结点。 具有较高的查找效率。 插入效率也高，比链表要高。","text":"二叉搜索树特性： 具有二叉树的所有特性。 左节点的值永远小于根结点。 有节点的值永远大于根结点。 具有较高的查找效率。 插入效率也高，比链表要高。 二叉搜索树的Java代码实现： insert方法：插入一个节点 getMin方法：获取最小节点 getMax方法：获取最大节点 search方法：查找一个节点 delete方法：删除一个节点 deleteMax方法：删除最小节点 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399public class BinarySearchTree&lt;E extends Comparable&lt;E&gt;&gt; &#123; private Node&lt;E&gt; root; static class Node&lt;E&gt; &#123; E item; Node&lt;E&gt; leftChild; Node&lt;E&gt; rightChild; public Node(E item) &#123; this.item = item; &#125; &#125; /** * 插入 * * @param e */ public void insert(E e) &#123; root = insertNode(root, e); &#125; /** * 插入节点 * * @param node * @param e * @return */ private Node&lt;E&gt; insertNode(Node&lt;E&gt; node, E e) &#123; if (node == null) &#123; return new Node&lt;&gt;(e); &#125; int cmp = e.compareTo(node.item); if (cmp &lt; 0) &#123; //要插入的节点值比当前节点值小，则向当前节点的左节点递归插入，插入后的值赋给当前节点的左节点 node.leftChild = insertNode(node.leftChild, e); &#125; else if (cmp &gt; 0) &#123; //要插入的节点值比当前节点值大，则向当前节点的右节点递归插入，插入后的值赋给当前节点的右节点 node.rightChild = insertNode(node.rightChild, e); &#125; return node; &#125; /** * 获取整个二叉树的最小节点 * * @return */ public Node&lt;E&gt; getMin() &#123; return getMin(root); &#125; /** * 获取以指定节点为根结点的子树中的最小节点 * 由二叉搜索树的特性可知道最小节点一定是最左的一个节点， * 所以一直找最左的节点 * * @param node * @return */ public Node&lt;E&gt; getMin(Node&lt;E&gt; node) &#123; //递归实现 if (node.leftChild == null) &#123; return node; &#125; return getMin(node.leftChild); //遍历实现 /*Node&lt;E&gt; min = node; while (min.leftChild != null) &#123; min = min.leftChild; &#125; return min;*/ &#125; /** * 获取整个二叉树的最大节点 * * @return */ public Node&lt;E&gt; getMax() &#123; return getMax(root); &#125; /** * 获取以指定节点为根结点的子树中的最大节点 * 由二叉搜索树的特性可知道最小节点一定是最右的一个节点， * 所以一直找最右的节点 * * @param node * @return */ public Node&lt;E&gt; getMax(Node&lt;E&gt; node) &#123; //递归实现 if (node.rightChild == null) &#123; return node; &#125; return getMax(node.rightChild); //遍历实现 /*Node&lt;E&gt; max = node; while (max.rightChild != null) &#123; max = max.rightChild; &#125; return max;*/ &#125; public Node&lt;E&gt; search(E e) &#123; return search(root, e); &#125; /** * 查找某个节点 * * @param node * @param e * @return */ public Node&lt;E&gt; search(Node&lt;E&gt; node, E e) &#123; //遍历实现 int count = 0; Node&lt;E&gt; current = node; while (current != null) &#123; count++; int cmp = current.item.compareTo(e); if (cmp &gt; 0) &#123; current = current.leftChild; &#125; else if (cmp &lt; 0) &#123; current = current.rightChild; &#125; else if (cmp == 0) &#123; System.out.println(\"查找次数为：\" + count); return current; &#125; &#125; return null; //递归实现 /*if (node == null) &#123; return null; &#125; int cmp = node.item.compareTo(e); if (cmp &gt; 0) &#123; return search(node.leftChild, e); &#125; else if (cmp &lt; 0) &#123; return search(node.rightChild, e); &#125; else &#123; return node; &#125;*/ &#125; /** * 删除值为e的节点 * * @param key */ public void delete(E key) &#123; root = delete(root, key); &#125; /** * 删除节点 * * @param node * @param key * @return */ public Node&lt;E&gt; delete(Node&lt;E&gt; node, E key) &#123; if (node == null) &#123; return null; &#125; else &#123; int cmp = key.compareTo(node.item); if (cmp &gt; 0) &#123; //判断删除节点的值比当前节点大，则向当前节点的右节点递归删除 node.rightChild = delete(node.rightChild, key); &#125; else if (cmp &lt; 0) &#123; node.leftChild = delete(node.leftChild, key); &#125; else &#123; if (node.rightChild == null) &#123; return node.leftChild; &#125; if (node.leftChild == null) &#123; return node.rightChild; &#125; Node&lt;E&gt; t = node; node = getMin(t.rightChild); node.rightChild = deleteMin(t.rightChild); node.leftChild = t.leftChild; &#125; &#125; return node; &#125; /** * 删除树中最小节点 */ public void deleteMin() &#123; root = deleteMin(root); &#125; /** * 删除最小节点 * * @param node * @return */ public Node&lt;E&gt; deleteMin(Node&lt;E&gt; node) &#123; //如果当前节点左节点为空，则当前节点为最小节点，将当前节点的右节点返回赋值给上一节点的左节点，则表示删除了改节点。 if (node.leftChild == null) &#123; return node.rightChild; &#125; //递归删除当前节点的左节点，并将返回值赋给左节点 node.leftChild = deleteMin(node.leftChild); return node; &#125; /** * 打印节点值 * * @param node */ private void printNode(Node&lt;E&gt; node) &#123; System.out.println(node.item); &#125; /** * 先序遍历 */ public void firstOrderTraversal() &#123; firstOrderTraversal(root); &#125; /** * 先序遍历(递归实现) * * @param node */ public void firstOrderTraversal(Node&lt;E&gt; node) &#123; if (node == null) &#123; return; &#125; printNode(node); firstOrderTraversal(node.leftChild); firstOrderTraversal(node.rightChild); &#125; /** * 先序遍历(非递归实现) * * @param node */ public void firstOrderTraversal2(Node&lt;E&gt; node) &#123; if (node == null) &#123; return; &#125; Stack&lt;Node&lt;E&gt;&gt; stack = new Stack&lt;&gt;(); stack.push(node); while (!stack.isEmpty()) &#123; Node&lt;E&gt; pop = stack.pop(); if (pop != null) &#123; printNode(pop); stack.push(pop.rightChild); stack.push(pop.leftChild); &#125; &#125; &#125; /** * 中序遍历 */ public void inOrderTraversal() &#123; inOrderTraversal2(root); &#125; /** * 中序遍历 * * @param node */ public void inOrderTraversal(Node&lt;E&gt; node) &#123; if (node == null) &#123; return; &#125; inOrderTraversal(node.leftChild); printNode(node); inOrderTraversal(node.rightChild); &#125; /** * 中序遍历(非递归实现) * * @param node */ public void inOrderTraversal2(Node&lt;E&gt; node) &#123; if (node == null) &#123; return; &#125; Stack&lt;Node&lt;E&gt;&gt; stack = new Stack&lt;&gt;(); while (node != null || !stack.isEmpty()) &#123; if (node != null) &#123; stack.push(node); node = node.leftChild; &#125; else &#123; Node&lt;E&gt; pop = stack.pop(); printNode(pop); node = pop.rightChild; &#125; &#125; &#125; /** * 后序遍历 */ public void postOrderTraversal() &#123; postOrderTraversal2(root); &#125; /** * 后序遍历 * * @param node */ public void postOrderTraversal(Node&lt;E&gt; node) &#123; if (node == null) &#123; return; &#125; postOrderTraversal(node.leftChild); postOrderTraversal(node.rightChild); printNode(node); &#125; /** * 主要思想：首先遍历root根节点的所有左结点，并依次入栈。对出栈的元素，如果没有右子树或者虽然有右子树 * 但右子树已完成遍历，即可完成出栈；否则，再次入栈，并把右子树入栈，遍历右子树的所有左子树。 * * @param node */ public void postOrderTraversal2(Node&lt;E&gt; node) &#123; if (node == null) &#123; return; &#125; Stack&lt;Node&lt;E&gt;&gt; stack = new Stack&lt;&gt;(); Node&lt;E&gt; prePop = null; while (node != null || !stack.isEmpty()) &#123; if (node != null) &#123; stack.push(node); node = node.leftChild; &#125; else &#123; Node&lt;E&gt; pop = stack.pop(); if (pop.rightChild == null || pop.rightChild == prePop) &#123; printNode(pop); prePop = pop; node = null; &#125; else &#123; stack.push(pop); stack.push(pop.rightChild); node = pop.rightChild.leftChild; &#125; &#125; &#125; &#125; /** * 层序遍历 */ public void levelOrderTraversal() &#123; levelOrderTraversal(root); &#125; /** * 层序遍历 * * @param node */ public void levelOrderTraversal(Node&lt;E&gt; node) &#123; if (node == null) &#123; return; &#125; LinkedList&lt;Node&lt;E&gt;&gt; queue = new LinkedList&lt;&gt;(); queue.push(node); while (!queue.isEmpty()) &#123; Node&lt;E&gt; pop = queue.poll(); if (pop != null) &#123; printNode(pop); queue.add(pop.leftChild); queue.add(pop.rightChild); &#125; &#125; &#125;&#125;","categories":[{"name":"数据结构和算法","slug":"data-struct","permalink":"http://yoursite.com/categories/data-struct/"}],"tags":[{"name":"算法","slug":"algorithms","permalink":"http://yoursite.com/tags/algorithms/"}],"keywords":[{"name":"数据结构和算法","slug":"data-struct","permalink":"http://yoursite.com/categories/data-struct/"}]},{"title":"正则表达式","slug":"regular","date":"2018-10-15T10:17:26.000Z","updated":"2018-10-24T08:58:45.121Z","comments":true,"path":"other/regular.html","link":"","permalink":"http://yoursite.com/other/regular.html","excerpt":"常用正则表达式","text":"常用正则表达式 表达式 描述 . 匹配出换行符外任意字符 \\ 转义符，可以将一些有特殊含义的字符转化为本身含义，如\\.代表点本身的含义。 [ ] 匹配中括号中字符的一个，如[abc]表示匹配a、b、c中的一个字符。 &#124; 匹配两个字符中的一个，如a&#124;b表示匹配a或者b。 [0-9A-Za-z] 字符区间，[0-9]表示0-9中的一个数。 ^ 取非匹配，[^0-9]表示不是0-9中的一个字符。 \\d 匹配数字 \\D 匹配非数字 \\w 匹配字母 \\W 匹配非字母 + 匹配一个或多个字符，如\\d+表示匹配一个或多个数字。 * 匹配0个或多个字符。 ？ 匹配0个或一个字符。 {n} 匹配多次，如\\w{3}表示匹配3个字母。 {m,n} 匹配次数是一个区间，如\\d{2,4}表示匹配2-4个数字。 {n,} 匹配至少次数的字符。 () 标记一个子表达式开始和结束 ^ 放在外面表示匹配字符串开始位置，如果是在方括号内表示取非 $ 匹配字符串结束位置 \\f 匹配一个换页符 \\n 匹配一个换行符 \\r 匹配一个回车符 \\s 匹配任何空白字符，包括空格、制表符、换页符等等。等价于 [ \\f\\n\\r\\t\\v] \\S 匹配任何非空白字符，等价于[ ^\\f\\n\\r\\t\\v] \\t 匹配一个制表符 \\v 匹配一个垂直制表符 \\b 匹配一个单词边界，即字与空格间位置 \\B 匹配一个非单词边界 ?= 向前匹配，如?=:表示匹配:然后向前匹配，最后结果不包含: ?&lt;= 向前匹配，如(?&lt;=\\$)[0-9.]+表示匹配$然后向后匹配，最后结果不包含$ 防止过度匹配 * 和+ 都是所谓的“贪婪型”元字符，它们在进行匹配时的行为模式是多多益善而不是适可而止的。它们会尽可能地从一段文本的开头一直匹配到这段文本的末尾，而不是从这段文本的开头匹配到碰到第一个匹配时为止。 为了防止这种贪婪型匹配，我们需要使用对应字符的惰性版本，* 使用 *？，+ 使用 +？，{n,}使用{n,}? 回溯引用 回溯引用指的是模式的后半部分引用在前半部分中定义的子表达式。如 &lt;hH&gt;.*?&lt;/[hH]\\1&gt;，这其中最后的\\1表示前面第一个子表达式匹配的结果，即([1-6])，依此类推，\\2表示第二个子表达式，\\n表示第n个子表达式。 回溯引用在替换操作中也很有用，如(\\d{3})(-)(\\d{3})(-)(\\d{4})这个正则表达式，使用替换的表达式($1) $3-$5，可以将匹配到的字符替换成别的格式。其中$1,$3,$5分别表示第1，第3，第5个子表达式。","categories":[{"name":"其他","slug":"other","permalink":"http://yoursite.com/categories/other/"}],"tags":[{"name":"正则","slug":"regular","permalink":"http://yoursite.com/tags/regular/"}],"keywords":[{"name":"其他","slug":"other","permalink":"http://yoursite.com/categories/other/"}]},{"title":"Java原子操作类","slug":"concurrent2","date":"2018-10-07T14:38:14.000Z","updated":"2018-10-24T08:01:34.332Z","comments":true,"path":"Java/concurrent2.html","link":"","permalink":"http://yoursite.com/Java/concurrent2.html","excerpt":"","text":"","categories":[{"name":"Java","slug":"Java","permalink":"http://yoursite.com/categories/Java/"}],"tags":[{"name":"并发","slug":"concurrent","permalink":"http://yoursite.com/tags/concurrent/"}],"keywords":[{"name":"Java","slug":"Java","permalink":"http://yoursite.com/categories/Java/"}]},{"title":"Java内存模型","slug":"concurrent1","date":"2018-10-07T07:58:29.000Z","updated":"2018-10-24T08:17:49.737Z","comments":true,"path":"Java/concurrent1.html","link":"","permalink":"http://yoursite.com/Java/concurrent1.html","excerpt":"1、Java内存模型的抽象结构 Java内存模型就是Java Memory Model（以下简称JMM），是Java虚拟机规范的一部分。JMM规定：变量存储在主存中，每个线程有自己的工作内存，线程工作内存中保存了变量在主存的副本拷贝。主存是线程共享的，工作内存变量是各个线程独享的。线程工作时，从主存中复制变量到线程的工作内存，然后在工作内存中操作变量副本，最后再把变量副本写回到主内存。","text":"1、Java内存模型的抽象结构 Java内存模型就是Java Memory Model（以下简称JMM），是Java虚拟机规范的一部分。JMM规定：变量存储在主存中，每个线程有自己的工作内存，线程工作内存中保存了变量在主存的副本拷贝。主存是线程共享的，工作内存变量是各个线程独享的。线程工作时，从主存中复制变量到线程的工作内存，然后在工作内存中操作变量副本，最后再把变量副本写回到主内存。Java内存模型是一种共享内存模型： 线程只能操作工作内存，不能直接操作主存。 每个线程只能访问自己的工作内存，不能访问其他线程的工作内存。 线程之间的数据通信必须通过主存中完成。 2、并发三问题 重排序为了提高性能，编译器和处理器会对指令进行重排序，重排序主要有三种类型： 编译器重排序：编译器在不改变单线程程序语义的前提下，可以重新安排字节码的执行顺序；也就是编译生成的机器码顺序和源代码顺序不一样。 处理器重排序：现代处理器采用指令级并行技术将多条指令重叠执行，如果不存在数据依赖性，处理器可以改变语句对应机器指令的执行顺序；也就是CPU在执行字节码时，执行顺序可能和机器码顺序不一样。 内存重排序：由于处理器使用缓存和读/写缓冲区，这使得加载和存储操作看上去可能是在乱序执行。 123456789101112131415class ReorderExample &#123; int a = 0; boolean flag = false; public void writer() &#123; a = 1; // A1 flag = true; // A2 &#125; public void reader() &#123; if (flag) &#123; // B1 int i = a * a; // B2 &#125; &#125;&#125; 线程1执行writer()方法，线程2执行reader()方法，结果怎样？ 由于writer()方法中的A1和A2操作没有依赖关系，所以可能被重排序，先执行A2，再执行A1，这种情况下由于a=0，所以i=0；reader方法中的B1、B2虽然有依赖关系，但是仍然可以重排序，B2先执行a*a=0放在缓存，当flag为true时将i赋值为0。 内存可见性内存可见性问题是由于多核缓存引起的。现在的多核cpu都有自己的一级缓存和二级缓存。Java作为高级语言，屏蔽了底层这些细节，构建了JMM规范。JMM抽象了主存和工作内存的概念。由于线程可能不能及时将工作内存中变量刷到主存，造成其他线程读取到的变量可能是错误的，这就是内存可见性问题。 原子性原子性即一个操作不可拆分。JMM只保证像read/load/store/write这样很少的操作是原子性的，甚至在32位平台下，对64位数据的读取和赋值都不能保证其原子性（long变量赋值是需要通过两个操作来完成的）。简单说，int i=10; 是原子的；i = i + 1 不是原子的；甚至long v = 100L 也可能不是原子的。 3、volatile关键字volatile关键字有两个作用：一是保证内存可见性；二是防止指令重排序。 可见性：被volatile修饰的变量，如果一个线程修改了其的值，另一个线程能够立即读取到最新的值。 禁止指令重排序：被volatile修饰的变量，保证在它前面的代码先执行，在它后面的代码后执行。 volatile小结 volatile 修饰符适用于以下场景：某个属性被多个线程共享，其中有一个线程修改了此属性，其他线程可以立即得到修改后的值。在并发包的源码中，它使用得非常多。 volatile 属性的读写操作都是无锁的，它不能替代 synchronized，因为它没有提供原子性和互斥性。因为无锁，不需要花费时间在获取锁和释放锁上，所以说它是低成本的。 volatile 只能作用于属性，我们用 volatile 修饰属性，这样 compilers 就不会对这个属性做指令重排序。 volatile 提供了可见性，任何一个线程对其的修改将立马对其他线程可见。volatile 属性不会被线程缓存，始终从主存中读取。 4、happens-before规则 happens-before用来指定两个操作之间的顺序，这两个操作可以在一个线程内，也可以在不同线程之间。因此，JMM可以通过happens-before关系向程序员提供跨线程的内存可见性。 JSR-133定义了如下happens-before规则： 程序顺序规则：一个线程中的每个操作，happens-before于该线程的任意后续操作。 监视器锁规则：对一个锁的解锁，happens-before于随后对这个锁的加锁。 volatile变量规则：对一个volatile变量的写，happens-before于随后对这个volatile变量的读。 传递性：如果A happens-before于B，B happens-before于C，可以得出A happens-before于C。 start()规则：如果线程A执行操作ThreadB.start()（启动线程B），那么A线程的ThreadB.start()操作happens-before于线程B中的任意操作。 join()规则：如果线程A执行操作ThreadB.join()并成功返回，那么线程B中的任意操作happens-before于线程A从ThreadB.join()操作成功返回。 5、synchronized关键字synchronized关键字可以实现volatile的保证内存可见性以及禁止重排序，同时它还可以保证原子性操作。但是synchronized需要进行加锁操作，效率更低。 6、final关键字final关键字可以用来修饰类、方法、变量。用来修饰变量时可以在对象初始化完成前，不要将此对象的引用写入到其他线程可以访问到的地方（不要让引用在构造函数中逸出）。如果这个条件满足，当其他线程看到这个对象的时候，那个线程始终可以看到正确初始化后的对象的 final 属性。","categories":[{"name":"Java","slug":"Java","permalink":"http://yoursite.com/categories/Java/"}],"tags":[{"name":"并发","slug":"concurrent","permalink":"http://yoursite.com/tags/concurrent/"}],"keywords":[{"name":"Java","slug":"Java","permalink":"http://yoursite.com/categories/Java/"}]},{"title":"nginx详解","slug":"nginx","date":"2018-10-06T11:00:44.000Z","updated":"2018-10-24T08:18:22.460Z","comments":true,"path":"other/nginx.html","link":"","permalink":"http://yoursite.com/other/nginx.html","excerpt":"1、概述 nginx是一个跨平台的高性能web服务器。目前我们主要使用nginx用来做反向代理服务器。 为什么选择nginx：1、更快；2、高扩展性；3、高可靠性；4、低内存消耗；5、单机支持10w以上并发连接；6、热部署。","text":"1、概述 nginx是一个跨平台的高性能web服务器。目前我们主要使用nginx用来做反向代理服务器。 为什么选择nginx：1、更快；2、高扩展性；3、高可靠性；4、低内存消耗；5、单机支持10w以上并发连接；6、热部署。 2、安装和启动2.1、编译安装 从nginx官网获取nginx的源码，然后将源码解压到准备好的目录。然后进入安装目录执行三行代码：./configure、make、make install。 configure命令做了大量的“幕后”工作，包括检测操作系统内核和已经安装的软件，参数的解析，中间目录的生成以及根据各种参数生成一些C源码文件、Makefile文件等。 make命令根据configure命令生成的Makefile文件编译Nginx工程，并生成目标文件、最终的二进制文件。 make install命令根据configure执行时的参数将Nginx部署到指定的安装目录，包括相关目录的建立和二进制文件、配置文件的复制。2.2、命令行控制 默认方式启动：./nginx 会使用默认路径下的conf文件。 另指定配置文件启动：./nginx -c /tmp/nginx.conf 使用-c参数可以指定配置文件。 另指定安装目录启动：./nginx -p /usr/local/nginx 使用-p参数指定nginx的安装目录。 测试配置信息的正确性：./nginx -t 使用-t参数测试配置文件是否正确。 在测试阶段不输出非错误信息：./nginx -t -q 测试配置选项时，使用-q参数可以不把error级别以下的信息输出到屏幕。 显示版本信息：./nginx -v 使用-v参数显示Nginx的版本信息。 快速停止服务：./nginx -s stop 可以强制停止服务。nginx程序通过nginx.pid文件得到master进程的进程ID，再向master进程发送TERM信号快速的关闭服务。 优雅停止服务：./nginx -s quit 这个会先关闭端口，停止接受新的连接，然后将当前的任务全部处理完再关闭服务。 运行中重读配置文件并生效：./nginx -s reload 可以使运行中的nginx重新加载配置文件。 3、服务架构3.1、模块化架构 nginx其实就是由很多模块组成，每个模块实现特定的功能。主要分为核心模块、标准http模块、可选http模块、邮件模块以及第三方模块等五大类。3.2、web请求处理机制 实现并行处理请求工作主要有三种方式：多进程方式、多线程方式、异步方式。nginx主要采用的是多进程机制和异步机制，异步机制使用的是异步非阻塞。3.3、事件驱动模型 异步IO的实现机制主要有两种：一是工作进程不停的查询IO是否完成；二是IO调用完成后主动通知工作进程。nginx使用的是第二种，也就是事件驱动模型。 事件收集器–&gt;事件发送器–&gt;事件处理器 常用的事件驱动模型库有：select库、poll库、epoll库。 select库：首先创建读、写、异常三类事件描述符集合，其次调用底层select函数，等待事件发生，然后轮询三个集合中的每一个事件描述符，如果有事件发生就进行处理。 poll库：poll库和select库的基本工作方式是相同的，主要区别在于select库创建了三个集合，而poll库只需要创建一个集合，是select库的优化实现。 epoll库：epoll的实现方式是把描述符列表的管理交给内核负责，一旦有某种事件发生，内核就把事件发生的描述符列表通知给进程，这样避免了轮询整个描述符列表，所以它比select库和poll库更高效。 3.4、设计架构概览 nginx的主要架构是由一个主进程(master process)，多个工作进程(worker process)组成。主进程主要进行nginx配置文件解析、数据结构初始化、模块配置和注册、信号处理、网络监听生成、工作进程生成和管理等工作，工作进程主要进行进程初始化、模块调用和请求处理等工作，是nginx服务器提供服务的主体。 4.配置下面是nginx官网基本配置的一个完整例子，更多的配置可以去官网查询相关文档。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134#用户（组）user www www;#工作进程数worker_processes 2;#进程PID存放路径pid /var/run/nginx.pid;#错误日志存放路径# [ debug | info | notice | warn | error | crit ]error_log /var/log/nginx.error_log info;#events块events &#123; #配置最大连接数 worker_connections 2000; #事件驱动模型选择 # use [kqueue|epoll|/dev/poll|select|poll]; use kqueue;&#125;#http块http &#123; #定义MIME-Type include conf/mime.types; default_type application/octet-stream; #日志格式 log_format main &apos;$remote_addr - $remote_user [$time_local] &apos; &apos;&quot;$request&quot; $status $bytes_sent &apos; &apos;&quot;$http_referer&quot; &quot;$http_user_agent&quot; &apos; &apos;&quot;$gzip_ratio&quot;&apos;; log_format download &apos;$remote_addr - $remote_user [$time_local] &apos; &apos;&quot;$request&quot; $status $bytes_sent &apos; &apos;&quot;$http_referer&quot; &quot;$http_user_agent&quot; &apos; &apos;&quot;$http_range&quot; &quot;$sent_http_content_range&quot;&apos;; client_header_timeout 3m; client_body_timeout 3m; send_timeout 3m; client_header_buffer_size 1k; large_client_header_buffers 4 4k; gzip on; gzip_min_length 1100; gzip_buffers 4 8k; gzip_types text/plain; output_buffers 1 32k; postpone_output 1460; sendfile on; tcp_nopush on; tcp_nodelay on; send_lowat 12000; keepalive_timeout 75 20; #lingering_time 30; #lingering_timeout 10; #reset_timedout_connection on; server &#123; listen one.example.com; server_name one.example.com www.one.example.com; access_log /var/log/nginx.access_log main; location / &#123; proxy_pass http://127.0.0.1/; proxy_redirect off; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; #proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; client_max_body_size 10m; client_body_buffer_size 128k; client_body_temp_path /var/nginx/client_body_temp; proxy_connect_timeout 70; proxy_send_timeout 90; proxy_read_timeout 90; proxy_send_lowat 12000; proxy_buffer_size 4k; proxy_buffers 4 32k; proxy_busy_buffers_size 64k; proxy_temp_file_write_size 64k; proxy_temp_path /var/nginx/proxy_temp; charset koi8-r; &#125; error_page 404 /404.html; location = /404.html &#123; root /spool/www; &#125; location /old_stuff/ &#123; rewrite ^/old_stuff/(.*)$ /new_stuff/$1 permanent; &#125; location /download/ &#123; valid_referers none blocked server_names *.example.com; if ($invalid_referer) &#123; #rewrite ^/ http://www.example.com/; return 403; &#125; #rewrite_log on; # rewrite /download/*/mp3/*.any_ext to /download/*/mp3/*.mp3 rewrite ^/(download/.*)/mp3/(.*)\\..*$ /$1/mp3/$2.mp3 break; root /spool/www; #autoindex on; access_log /var/log/nginx-download.access_log download; &#125; location ~* \\.(jpg|jpeg|gif)$ &#123; root /spool/www; access_log off; expires 30d; &#125; &#125;&#125; 5.反向代理与负载均衡正向代理和反向代理： 简单说，正向代理用来让局域网客户机接入外网以访问外网资源，反向代理用来让外网的客户端接入局域网中的站点以访问站点中的资源。 正向代理 1234567server &#123; resolver 192.168.1.1; #指定DNS服务器IP地址 listen 8080; location / &#123; proxy_pass http://$http_host$request_uri; #设定代理服务器的协议和地址 &#125; &#125; 反向代理 123456789server &#123; listen 80; location /demo &#123; proxy_pass http://127.0.0.1:8081; &#125; location /demo1 &#123; proxy_pass http://127.0.0.1:8082; &#125;&#125; 负载均衡 nginx是一个非常高效的HTTP负载均衡器，将流量分配给多个应用服务器，并通过nginx提高web应用程序的性能、可伸缩性和可靠性。 nginx负载均衡使用的指令主要有upstream和proxy_pass，upstream块定义一个后端集群，proxy_pass用于location块中，表示对于所有符合要求的request交给某个集群处理。 常见的由以下几种实现负载均衡的方式。 轮询（round-robin）：默认方式 12345678910111213http &#123; upstream backend &#123; server srv1.example.com; server srv2.example.com; server srv3.example.com; &#125; server &#123; listen 80; location / &#123; proxy_pass http://backend; &#125; &#125;&#125; 加权轮询（weight-round-robin） 12345upstream backend &#123; server srv1.example.com weight=3; server srv2.example.com weight=2; server srv3.example.com;&#125; 最少连接（least-connected） 123456upstream backend &#123; least_conn; server srv1.example.com; server srv2.example.com; server srv3.example.com;&#125; ip-hash：每个请求按访问ip的hash结果分配，这样每个访客固定访问一个后端服务器，可以解决session的问题。 123456upstream backend &#123; ip_hash; server srv1.example.com; server srv2.example.com; server srv3.example.com;&#125; fair（第三方）: 按后端服务器的响应时间来分配请求，响应时间短的优先分配 123456upstream backend &#123; fair; server srv1.example.com; server srv2.example.com; server srv3.example.com;&#125;","categories":[{"name":"其他","slug":"other","permalink":"http://yoursite.com/categories/other/"}],"tags":[{"name":"nginx","slug":"nginx","permalink":"http://yoursite.com/tags/nginx/"}],"keywords":[{"name":"其他","slug":"other","permalink":"http://yoursite.com/categories/other/"}]},{"title":"springboot使用mybatis加载typealias的package问题","slug":"springboot2","date":"2018-09-30T10:02:32.000Z","updated":"2018-10-24T08:17:32.929Z","comments":true,"path":"web/springboot2.html","link":"","permalink":"http://yoursite.com/web/springboot2.html","excerpt":"springboot打成jar包后运行会造成mybatis设置的别名包找不到实体类的问题，这是由于mybatis默认使用DefaultVFS扫描包，在springboot中可以改成SpringBootVFS进行包扫描。具体见下面代码。","text":"springboot打成jar包后运行会造成mybatis设置的别名包找不到实体类的问题，这是由于mybatis默认使用DefaultVFS扫描包，在springboot中可以改成SpringBootVFS进行包扫描。具体见下面代码。 1234567891011@Bean public SqlSessionFactory db1SqlSessionFactory(DataSource dataSource) throws Exception &#123; SqlSessionFactoryBean sqlSessionFactoryBean = new SqlSessionFactoryBean(); sqlSessionFactoryBean.setDataSource(dataSource); //mybatis使用默认DefaultVFS扫描包会有问题，使用SpringBootVFS sqlSessionFactoryBean.setVfs(SpringBootVFS.class); PathMatchingResourcePatternResolver resolver = new PathMatchingResourcePatternResolver(); sqlSessionFactoryBean.setMapperLocations(resolver.getResources(&quot;classpath*:/mybatis/mapper/**.xml&quot;)); sqlSessionFactoryBean.setConfigLocation(new ClassPathResource(&quot;mybatis/mybatis-config.xml&quot;)); return sqlSessionFactoryBean.getObject(); &#125; 如果使用 mybatis autoconfigure生成的 SessionFactory可能就没有这个问题了。","categories":[{"name":"web","slug":"web","permalink":"http://yoursite.com/categories/web/"}],"tags":[{"name":"springboot","slug":"springboot","permalink":"http://yoursite.com/tags/springboot/"}],"keywords":[{"name":"web","slug":"web","permalink":"http://yoursite.com/categories/web/"}]},{"title":"JVM（5）：类加载机制","slug":"jvm-classloader","date":"2018-09-27T09:41:42.000Z","updated":"2018-10-24T08:17:04.862Z","comments":true,"path":"Java/jvm-classloader.html","link":"","permalink":"http://yoursite.com/Java/jvm-classloader.html","excerpt":"JVM把class文件加载的内存，并对数据进行校验、转换解析和初始化，最终形成JVM可以直接使用的Java类型的过程就是加载机制。 类加载生命周期 加载（Loading） 验证（Verifycation） 准备（Preparation） 解析（Resolution） 初始化（Initialization） 使用（Using） 卸载（Unloading）","text":"JVM把class文件加载的内存，并对数据进行校验、转换解析和初始化，最终形成JVM可以直接使用的Java类型的过程就是加载机制。 类加载生命周期 加载（Loading） 验证（Verifycation） 准备（Preparation） 解析（Resolution） 初始化（Initialization） 使用（Using） 卸载（Unloading） 其中验证、准备、解析这三个阶段统称为连接。加载、验证、准备、初始化、卸载这五个阶段顺序是确定的。 加载在加载阶段，虚拟机需要完成三件事情： 通过一个类的全限定名来获取定义此类的二进制字节流。 将这个字节流所代表的静态存储结构转化为方法区的运行时数据结构。 在内存中生成一个代表这个类的java.lang.class的对象，作为方法区这个类的各种数据的访问入口。 验证验证是连接阶段的第一步，这一阶段的目的是为了确保Class文件字节流中包含的信息符合当前虚拟机的要求，并且不回危害虚拟机的安全。验证阶段一共包含四步：文件格式验证、愿数据验证、字节码验证、符号引用验证。 准备准备阶段是为类变量分配内存并设置初始值的阶段，这些变量所使用的内存都在方法区中。public static int value=123；这个变量在准备阶段会初始化为0而不是123，因为这个时候尚未执行任何java方法，将value赋值为123是在putstatic指令被程序编译之后。public static final int value=123；而这个会在准备阶段之后value就被初始化为123。 解析解析阶段是将常量池中的符号引用替换成直接引用的过程。 初始化初始化阶段是真正开始执行类中定义的java代码。在准备阶段，类变量已经赋值了一次系统要求的初始值，而在初始化阶段，则根据具体实际的值去初始化。 类加载器 Bootstrap ClassLoader Extension ClassLoader Application ClassLoader Custom ClassLoader 双亲委派模型 双亲委派模型要求除了顶层的启动类加载器外，其余的类加载器都应该有自己的父类加载器。这些父子类加载器之间的关系不会以继承来实现，而是使用组合来实现。 双亲委派模型的工作过程是：如果一个类加载器收到了类加载的请求，它首先不会自己去尝试加载这个类，而是把这个请求委派给父类加载器去完成，每一个层次的类加载器都是如此，因此所有的加载请求最终都应该传送到顶层的启动类加载器中，只有当父加载器反馈自己无法完成这个加载请求（它的搜索范围中没有找到所需的类）时，子加载器才会尝试自己去加载。","categories":[{"name":"Java","slug":"Java","permalink":"http://yoursite.com/categories/Java/"}],"tags":[{"name":"JVM虚拟机","slug":"jvm","permalink":"http://yoursite.com/tags/jvm/"}],"keywords":[{"name":"Java","slug":"Java","permalink":"http://yoursite.com/categories/Java/"}]},{"title":"springboot线程池优雅关闭","slug":"springboot1","date":"2018-09-27T08:46:18.000Z","updated":"2018-10-24T08:17:20.736Z","comments":true,"path":"web/springboot1.html","link":"","permalink":"http://yoursite.com/web/springboot1.html","excerpt":"在我们停止springboot项目时，我们希望线程池中的任务能够继续执行完再完全停掉服务。一般有两种做法： 线程池配置参数在spring应用中，如果需要停止服务，而线程池没有优雅的关闭，就会造成线程池中的任务被强行停止，导致部分任务执行失败。我们只需要在配置线程池时增加两个参数即可： waitForTasksToCompleteOnShutdown awaitTerminationSeconds","text":"在我们停止springboot项目时，我们希望线程池中的任务能够继续执行完再完全停掉服务。一般有两种做法： 线程池配置参数在spring应用中，如果需要停止服务，而线程池没有优雅的关闭，就会造成线程池中的任务被强行停止，导致部分任务执行失败。我们只需要在配置线程池时增加两个参数即可： waitForTasksToCompleteOnShutdown awaitTerminationSeconds 具体代码如下： 12345678910111213@Beanpublic ThreadPoolTaskExecutor treadPool() &#123; ThreadPoolTaskExecutor executor = new ThreadPoolTaskExecutor(); executor.setCorePoolSize(10); executor.setMaxPoolSize(20); executor.setQueueCapacity(10); executor.setKeepAliveSeconds(60); executor.setWaitForTasksToCompleteOnShutdown(true); executor.setAwaitTerminationSeconds(30); executor.setRejectedExecutionHandler(new ThreadPoolExecutor.CallerRunsPolicy()); executor.initialize(); return executor;&#125; 使用ApplicationListener监听关闭事件12345678910111213141516171819202122232425262728@Componentpublic class MyContextClosedHandler implements ApplicationListener&lt;ContextClosedEvent&gt;&#123; @Autowired private ThreadPoolTaskExecutor executor; @Override public void onApplicationEvent(ContextClosedEvent event) &#123; shutdownAndAwaitTermination(executor.getThreadPoolExecutor()); &#125; private void shutdownAndAwaitTermination(ExecutorService pool) &#123; pool.shutdown(); // Disable new tasks from being submitted try &#123; // Wait a while for existing tasks to terminate if (!pool.awaitTermination(30, TimeUnit.SECONDS)) &#123; pool.shutdownNow(); // Cancel currently executing tasks // Wait a while for tasks to respond to being cancelled if (!pool.awaitTermination(30, TimeUnit.SECONDS)) System.err.println(&quot;Pool did not terminate&quot;); &#125; &#125; catch (InterruptedException ie) &#123; // (Re-)Cancel if current thread also interrupted pool.shutdownNow(); // Preserve interrupt status Thread.currentThread().interrupt(); &#125; &#125;&#125;","categories":[{"name":"web","slug":"web","permalink":"http://yoursite.com/categories/web/"}],"tags":[{"name":"springboot","slug":"springboot","permalink":"http://yoursite.com/tags/springboot/"}],"keywords":[{"name":"web","slug":"web","permalink":"http://yoursite.com/categories/web/"}]},{"title":"JVM（4）：虚拟机性能监控","slug":"jvm-tools","date":"2018-09-26T07:12:08.000Z","updated":"2018-11-08T09:42:23.032Z","comments":true,"path":"Java/jvm-tools.html","link":"","permalink":"http://yoursite.com/Java/jvm-tools.html","excerpt":"要进行虚拟机性能监控光有理论还不够，还需要实践。JDK为我们提供了一些命令行工具以及图形化洁面工具进行虚拟机性能监控实践。","text":"要进行虚拟机性能监控光有理论还不够，还需要实践。JDK为我们提供了一些命令行工具以及图形化洁面工具进行虚拟机性能监控实践。 命令行工具 jps：虚拟机进程状况工具用于列出正在执行的虚拟机进程。命令格式：jps ［options］［hostid］主要选项：-q 只输出LVMID，省略主类的名称 -l 输出主类的全名，如果执行的是jar包，输出jar的包路径 -m 输出虚拟机进程启动时传给主类main函数的参数 -v 输出虚拟机进程启动时的JVM参数jps可以通过RMI协议查询开启了RMI服务的远程虚拟机进程状态，hostid为RMI注册表中注册的主机名。 jstat：虚拟机统计信息监视工具用于监视虚拟机各种运行状态信息。命令格式： jstat -&lt;option> [-t] [-h &lt;lines>] &lt;vmid> [&lt;interval> [&lt;count>]] jstat -gc 2764 250 20 每250ms查看一次进程ID2764的gc情况，一共查看20次主要选项：-class 监视类装载、卸载、总空间以及所耗费时间 -gc 监视java堆gc状况，包括Eden区、两个Survivor区、、老年代、永久带等的容量、已用空间、GC时间合计等信息 jinfo：Java配置信息工具实时查看和调整虚拟机各项参数。命令格式：jinfo [ option ] vmid jmap：Java 内存映像工具用于生成堆转储快照，一般是headdump文件或者dump文件。命令格式：jmap [ option ] vmid主要选项：-dump 生成Java堆转储快照 -heap 显示Java堆详细信息。 jhat：虚拟机堆转储快照分析工具jhat与jmap搭配使用，来分析jmap生成的堆转储快照。 jstack：Java堆栈跟踪工具用于生成虚拟机当前的线程快照，一般是threaddump文件或者javacore文件。命令格式：jstack [ option ] vmid 图形化工具 JConsole：Java监视与管理控制台 VisualVM：多合一故障处理工具","categories":[{"name":"Java","slug":"Java","permalink":"http://yoursite.com/categories/Java/"}],"tags":[{"name":"JVM虚拟机","slug":"jvm","permalink":"http://yoursite.com/tags/jvm/"}],"keywords":[{"name":"Java","slug":"Java","permalink":"http://yoursite.com/categories/Java/"}]},{"title":"JVM（3）：垃圾收集GC","slug":"jvm-gc","date":"2018-09-26T06:09:37.000Z","updated":"2018-10-24T08:16:28.419Z","comments":true,"path":"Java/jvm-gc.html","link":"","permalink":"http://yoursite.com/Java/jvm-gc.html","excerpt":"Java内存结构中程序计数器、虚拟机栈、本地方法栈都是线程私有的，随着方法的结束或者线程的结束，内存会被回收。所以垃圾收集主要针对Java堆和方法区。 判断对象是否可以回收 引用计数法 每个对象有一个引用计数器，每当有一个地方引用，计数器就加1，当引用失效，计数器就减1，计数器为0的对象会被回收。引用计数不能解决循环引用的问题。","text":"Java内存结构中程序计数器、虚拟机栈、本地方法栈都是线程私有的，随着方法的结束或者线程的结束，内存会被回收。所以垃圾收集主要针对Java堆和方法区。 判断对象是否可以回收 引用计数法 每个对象有一个引用计数器，每当有一个地方引用，计数器就加1，当引用失效，计数器就减1，计数器为0的对象会被回收。引用计数不能解决循环引用的问题。 可达性分析法 通过一系列称为“GC ROOTS”的节点作为起点，开始向下搜索，搜素所走的路径称为引用链，当一个对象到GC ROOTS没有任何引用链相连的话，就说明该对象不可用，可以被回收。 可以作为GC ROOTS的对象包含以下几种：虚拟机栈（栈帧中的本地变量表）中引用的对象、方法区中类静态属性引用的对象、方法区中常量引用的对象、本地方法中JNI引用的对象。 四种引用类型： 强引用：指在程序代码之中普遍存在的，类似“Object obj=new Object（）”这类的引用，只要强引用还存在，垃圾收集器永远不会回收掉被引用的对象。 软引用：用来描述一些还有用但是非必需的对象。在系统内存不足时进行垃圾收集会对软引用进行回收。（SoftReference） 弱引用：也是用来描述非必需的对象，但是它的强度比软引用更弱。发生GC时，不管内存是否足够都会对其进行回收。（WeakReference） 虚引用：也称为幽灵引用或者幻影引用，它是最弱的一种引用关系。一个对象是否有虚引用的存在，完全不会对其生存时间构成影响，也无法通过虚引用来取得一个对象实例。为一个对象设置虚引用关联的唯一目的就是能在这个对象被收集器回收时收到一个系统通知。（PhantomReference） 垃圾收集算法 标记清除算法 复制算法 标记整理算法 分代收集算法 算法实现 枚举根结点 在可达性分析过程中为了防止对象的引用关系发生变化，所以在执行GC时需要停顿所有java执行线程（Stop The World）。 由于目前的主流Java虚拟机使用的都是准确式GC，所以当执行系统停顿下来后，并不需要一个不漏地检查完所有执行上下文和全局的引用位置，虚拟机应当是有办法直接得知哪些地方存放着对象引用。在HotSpot的实现中，是使用一组称为OopMap的数据结构来达到这个目的的，在类加载完成的时候，HotSpot就把对象内什么偏移量上是什么类型的数据计算出来，在JIT编译过程中，也会在特定的位置记录下栈和寄存器中哪些位置是引用。这样，GC在扫描时就可以直接得知这些信息了。 安全点 HotSpot并没有为每条指令都生成OopMap，只有在特定的位置记录这个信息，这些位置称为安全点（SaftPoint）。安全点的选定基本上是以程序“是否具有让程序长时间执行的特征”为标准进行选定的。长时间执行的最明显特征就是指令序列复用，例如方法调用、循环跳转、异常跳转等。 GC停顿有两种方案：抢先式中断（基本不用）和主动式中断。主动式中断是当需要中断线程时，设置一个中断标志，各个线程去轮询这个标志，当为真的就中断挂起。 安全区域 程序不执行的时候，也就是没有分配CPU的时候，典型的就是线程sleep或者blocked状态时，这个时候不能响应中断请求。JVM不太可能等到线程重新分配CPU然后走到安全点。这样就需要安全区域解决这个问题。 安全区域是指在一段区域内引用关系不会发生变化，在这中间任何一个地方GC都是安全的。我们可以把Safe Region看成是扩展的safe point。 垃圾收集器 Serial收集器：单线程收集器，client模式下默认的新生代收集器。 ParNew收集器：Serial收集器的多线程版本。server模式首选的新生代收集器。 Parallel Scavenge收集器：并行的多线程垃圾收集器，目标是达到一个可控制的吞吐量。提供了两个参数用于精确控制吞吐量，分别是控制最大垃圾收集停顿时间的-XX：MaxGCPauseMillis参数以及直接设置吞吐量大小的-XX：GCTimeRatio参数。无法与CMS配合。 Serial Old收集器 ：Serial收集器的老年代版本，client模式下默认的老年代收集器。 Parallel Old收集器：Parallel Scavenge收集器的老年代版本。 CMS收集器：基于标记清除算法。目标是降低GC停顿时间，一共有四个步骤：初始标记、并发标记、重新标记、并发清除。这之中最耗时的并发标记和并发清除可以和用户线程一起运行，所以可以看成是并行的垃圾收集器。三个缺点：对CPU资源敏感、无法处理浮动垃圾、标记清除算法会产生内存碎片。 G1收集器：特点：并行与并发、分代收集、可预测的停顿。使用G1收集器时，Java堆的内存布局就与其他收集器有很大差别，它将整个Java堆划分为多个大小相等的独立区域（Region），虽然还保留有新生代和老年代的概念，但新生代和老年代不再是物理隔离的了，它们都是一部分Region（不需要连续）的集合。G1跟踪各个Region里面的垃圾堆积的价值大小，在后台维护一个优先列表，每次根据允许的收集时间，优先回收价值最大的Region。四个步骤：初始标记、并发标记、最终标记、筛选回收。 内存分配回收策略 对象优先在Eden区分配 大对象直接进入老年代 长期存活对象进入老年代 动态对象年龄判定 空间分配担保","categories":[{"name":"Java","slug":"Java","permalink":"http://yoursite.com/categories/Java/"}],"tags":[{"name":"JVM虚拟机","slug":"jvm","permalink":"http://yoursite.com/tags/jvm/"}],"keywords":[{"name":"Java","slug":"Java","permalink":"http://yoursite.com/categories/Java/"}]},{"title":"JVM（2）：虚拟机对象探秘","slug":"jvm-object","date":"2018-09-25T06:00:36.000Z","updated":"2018-10-24T08:16:09.627Z","comments":true,"path":"Java/jvm-object.html","link":"","permalink":"http://yoursite.com/Java/jvm-object.html","excerpt":"对象的创建对象的创建一般有四种方式：new关键字、反射、clone、序列化。对象创建主要分三步： 检查类是否加载 虚拟机遇到一条new指令时，首先将去检查这个指令的参数是否能在常量池中定位到一个类的符号引用，并且检查这个符号引用代表的类是否已被加载、解析和初始化过。如果没有，那必须先执行相应的类加载过程。","text":"对象的创建对象的创建一般有四种方式：new关键字、反射、clone、序列化。对象创建主要分三步： 检查类是否加载 虚拟机遇到一条new指令时，首先将去检查这个指令的参数是否能在常量池中定位到一个类的符号引用，并且检查这个符号引用代表的类是否已被加载、解析和初始化过。如果没有，那必须先执行相应的类加载过程。 分配内存 主要有指针碰撞和空闲列表两种方式。指针碰撞是把内存指针向空闲空间移动与对象大小相等的距离来分配内存，这种主要适用于带有整理的垃圾收集器。空闲列表是维护一个列表记录哪些内存区域可以使用，在分配的时候从列表中找出一块分配，这种适用于不带整理功能的垃圾收集器。 分配过程中还要考虑多个线程同时分配内存出现并发的问题。这个一般有两种方案：一是使用CAS机制保证更新操作的原子性；二是使用本地线程分配缓冲（TLAB）。 对象设置 分配完内存之后需要进行对象设置，主要是把这个对象是哪个类的实例、对象的哈希码、对象的GC分代年龄、对象的锁信息等存放在对象的对象头里。 对象的内存布局 对象在内存中存储的布局可以分为3块区域：对象头（Header）、实例数据（Instance Data）和对齐填充（Padding）。 对象头分成两部分：第一部分用于存储对象自身的运行时数据，如对象的哈希码、GC分代年龄、锁状态标志等，官方称之为‘MarkWord’。另外一部分是类型指针，即对象指向它的类元数据的指针，虚拟机通过这个指针来确定这个对象是哪个类的实例。 实例数据部分是对象真正存储的有效信息，也是在程序代码中所定义的各种类型的字段内容。无论是从父类继承下来的，还是在子类中定义的，都需要记录起来。 第三部分对象填充不是必须的，仅仅是占位的作用，用来保证对象的大小是８字节的整数倍。 对象的访问定位对象的访问主要两种方式： 句柄访问 Java堆中会划出一块内存作为句柄池，reference中存储的就是对象的句柄地址，而句柄中包含了对象实例数据和类型数据各自的具体地址信息。好处是对象移动时只用改动句柄中的实例数据地址，不用改变reference。 直接指针访问 reference中存储的就是对象的地址。好处就是访问快，节省了一次指针定位的开销。hotspot使用直接指针访问。","categories":[{"name":"Java","slug":"Java","permalink":"http://yoursite.com/categories/Java/"}],"tags":[{"name":"JVM虚拟机","slug":"jvm","permalink":"http://yoursite.com/tags/jvm/"}],"keywords":[{"name":"Java","slug":"Java","permalink":"http://yoursite.com/categories/Java/"}]},{"title":"JVM（1）：内存结构","slug":"jvm-memory","date":"2018-09-25T03:38:43.000Z","updated":"2018-10-24T08:15:03.063Z","comments":true,"path":"Java/jvm-memory.html","link":"","permalink":"http://yoursite.com/Java/jvm-memory.html","excerpt":"程序计数器 程序计数器是内存结构中很小的一块，属于线程私有的。字节码解释器工作时就是通过改变这个计数器的值来选取下一条需要执行的指令，分支、循环、跳转、异常处理、线程恢复都要依赖这个计数器来实现。程序计数器是内存结构中唯一一个没有定义OOM的区域。","text":"程序计数器 程序计数器是内存结构中很小的一块，属于线程私有的。字节码解释器工作时就是通过改变这个计数器的值来选取下一条需要执行的指令，分支、循环、跳转、异常处理、线程恢复都要依赖这个计数器来实现。程序计数器是内存结构中唯一一个没有定义OOM的区域。 虚拟机栈 虚拟机栈也是线程私有的，主要用于存储局部变量表、操作数栈、动态链接、方法出口等信息。每一个方法的调用对应着一个栈帧在虚拟机中的入栈出栈过程。 虚拟机栈中定义了StackOverflowError和OutOfMemeryError。当线程请求的栈深度大于虚拟机允许的最大深度，就会抛出SOF异常。如果虚拟机栈可以动态扩展，扩展时无法申请足够的内存，就会抛出OOM异常。 本地方法栈 本地方法栈和虚拟机栈一样，只不过本地方法栈是为native方法服务的。hotspot虚拟机把本地方法栈和虚拟机栈合二为一了。 JAVA堆 Java堆时内存结构中最大的一块区域，它是线程共享的，主要用于存储对象的实例。Java堆可以细分为年轻代和老年代，年轻代又可以分成Eden区，From Survivor区和To Survivor区。Java堆是垃圾收集器管理的主要区域，现在的收集器基本都采用分代收集的策略。当内存不足时，Java堆中也会出现OOM异常。 方法区 方法区也是线程共享的，主要用于存储被加载的类信息、常量、静态变量、即时编译器编译后的代码等数据。方法区中也会出现OOM异常。 直接内存 直接内存并不是虚拟机内存结构中的一块，但是这部分内存也被频繁使用，也会导致ＯＯＭ异常。JDK1.4中引入的NIO就使用了直接内存。","categories":[{"name":"Java","slug":"Java","permalink":"http://yoursite.com/categories/Java/"}],"tags":[{"name":"JVM虚拟机","slug":"jvm","permalink":"http://yoursite.com/tags/jvm/"}],"keywords":[{"name":"Java","slug":"Java","permalink":"http://yoursite.com/categories/Java/"}]},{"title":"Java代码优化","slug":"code-optimization","date":"2018-08-22T09:17:31.000Z","updated":"2018-10-24T08:18:30.450Z","comments":true,"path":"Java/code-optimization.html","link":"","permalink":"http://yoursite.com/Java/code-optimization.html","excerpt":"代码优化目标：减少代码体积，提高代码的运行效率","text":"代码优化目标：减少代码体积，提高代码的运行效率 代码优化具体细节 尽量指定类、方法的final修饰符：如果一个类是final的，则它的所有方法也是final的，java编译器会寻找机会内内联的所有final方法，可以提高50%的性能。 尽量重用对象：特别是String对象。Java虚拟机创建对象需要花费时间和空间，后期还要进行垃圾回收。 尽可能使用局部变量：局部变量存储于栈中，速度较快，而且随着方法的结束会消失。 及时关闭流和连接等：对于IO流以及数据库连接、线程池连接，在finally 中一定要将其关闭。 尽量使用懒加载策略：在使用时创建（单例模式最好使用懒汉模式）。 不要在循环中使用try…catch…：在循环外使用。 乘法和除法使用移位操作：&gt;&gt;1表示除以2，&lt;&lt;1表示乘以2。 当有大量数据复制时，使用System.arrayCopy()命令。 循环内不要不断的创建对象。","categories":[{"name":"Java","slug":"Java","permalink":"http://yoursite.com/categories/Java/"}],"tags":[{"name":"java基础","slug":"java-base","permalink":"http://yoursite.com/tags/java-base/"}],"keywords":[{"name":"Java","slug":"Java","permalink":"http://yoursite.com/categories/Java/"}]}]}