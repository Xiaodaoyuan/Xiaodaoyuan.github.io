{"meta":{"title":"Xiao's Blog","subtitle":"生命太短暂，不要去做一些根本没有人想要的东西。","description":"当你选择了一种语言，意味着你还选择了一组技术、一个社区","author":"任重道远","url":"http://yoursite.com"},"pages":[{"title":"分类","date":"2018-10-24T07:17:04.000Z","updated":"2018-10-24T07:18:21.919Z","comments":true,"path":"categories/index.html","permalink":"http://yoursite.com/categories/index.html","excerpt":"","text":""},{"title":"标签","date":"2018-10-24T07:20:20.000Z","updated":"2018-10-24T07:23:31.193Z","comments":true,"path":"tags/index.html","permalink":"http://yoursite.com/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"Rocketmq源码解析-2.Namesrv","slug":"rocketmq-namesrv","date":"2019-12-19T12:10:25.000Z","updated":"2019-12-20T09:42:43.188Z","comments":true,"path":"middleware/rocketmq-namesrv/","link":"","permalink":"http://yoursite.com/middleware/rocketmq-namesrv/","excerpt":"Namesrv简介Namesrv可以理解为一个注册中心，类似于kafka的zookeeper，但是比zk更加轻量，主要包含两块功能： 管理一些KV配置信息。 管理broker和topic的注册信息。","text":"Namesrv简介Namesrv可以理解为一个注册中心，类似于kafka的zookeeper，但是比zk更加轻量，主要包含两块功能： 管理一些KV配置信息。 管理broker和topic的注册信息。 Namesrv启动过程 启动过程主要涉及NamesrvStartup和NamesrvController两个类。 执行sh mqnamesrv命令会启动NamesrvStartup类中的main方法，首先会执行createNamesrvController方法，解析命令行中的参数到各种config对象中（主要是NettyServerConfig和NamesrvConfig）。然后会使用这两个config对象创建NamesrvController实例对象。接下来执行NamesrvController 对象的initialize()、start()方法，并且配置ShutdownHook。initialize()方法中会依次执行加载所有kv配置、创建NettyServer、创建processor线程池、注册processor、使用scheduledExecutorService启动各种scheduled task（包括broker的心跳检测）。start()方法会执行启动NettyServer。 不仅Namesrv的启动过程是这样，其他的组件启动过程也是startup/config/controller这样一个流程。 Namesrv主要组件 KVConfigManager 定义一个HashMap configTable存储配置信息。键为namespace，值为真正存储kv信息的map，这样就可以将同样namespace的配置放入同一个map。 12private final HashMap&lt;String/* Namespace */, HashMap&lt;String/* Key */, String/* Value */&gt;&gt; configTable = new HashMap&lt;String, HashMap&lt;String, String&gt;&gt;(); 使用读写锁控制配置信息的加载和读取。 1private final ReadWriteLock lock = new ReentrantReadWriteLock(); KVConfigManager类中load()方法用于启动namesrv时通过configpath读取配置文件，再将配置存入map，另外还提供添加，删除，获取配置方法用于后续操作 RouteInfoManager 定义五个map分别存储topic、broker、cluster、brokerliveinfo、filter信息。 123456private final ReadWriteLock lock = new ReentrantReadWriteLock();private final HashMap&lt;String/* topic */, List&lt;QueueData&gt;&gt; topicQueueTable;private final HashMap&lt;String/* brokerName */, BrokerData&gt; brokerAddrTable;private final HashMap&lt;String/* clusterName */, Set&lt;String/* brokerName */&gt;&gt; clusterAddrTable;private final HashMap&lt;String/* brokerAddr */, BrokerLiveInfo&gt; brokerLiveTable;private final HashMap&lt;String/* brokerAddr */, List&lt;String&gt;/* Filter Server */&gt; filterServerTable; DefaultRequestProcessor namesrv启动时会注册processor 1234567private void registerProcessor() &#123; if (namesrvConfig.isClusterTest()) &#123; this.remotingServer.registerDefaultProcessor(new ClusterTestRequestProcessor(this, namesrvConfig.getProductEnvName()), this.remotingExecutor); &#125; else &#123; this.remotingServer.registerDefaultProcessor(new DefaultRequestProcessor(this), this.remotingExecutor); &#125; &#125; 当namesrv有请求过来时，会使用DefaultRequestProcessor去处理请求，处理过程会在线程池this.remotingExecutor中执行，通过processRequest方法处理请求，根据request中不同code进行不同处理。 123456789101112131415161718192021222324252627282930313233343536373839404142switch (request.getCode()) &#123; case RequestCode.PUT_KV_CONFIG: return this.putKVConfig(ctx, request); case RequestCode.GET_KV_CONFIG: return this.getKVConfig(ctx, request); case RequestCode.DELETE_KV_CONFIG: return this.deleteKVConfig(ctx, request); case RequestCode.REGISTER_BROKER: Version brokerVersion = MQVersion.value2Version(request.getVersion()); if (brokerVersion.ordinal() &gt;= MQVersion.Version.V3_0_11.ordinal()) &#123; return this.registerBrokerWithFilterServer(ctx, request); &#125; else &#123; return this.registerBroker(ctx, request); &#125; case RequestCode.UNREGISTER_BROKER: return this.unregisterBroker(ctx, request); case RequestCode.GET_ROUTEINTO_BY_TOPIC: return this.getRouteInfoByTopic(ctx, request); case RequestCode.GET_BROKER_CLUSTER_INFO: return this.getBrokerClusterInfo(ctx, request); case RequestCode.WIPE_WRITE_PERM_OF_BROKER: return this.wipeWritePermOfBroker(ctx, request); case RequestCode.GET_ALL_TOPIC_LIST_FROM_NAMESERVER: return getAllTopicListFromNameserver(ctx, request); case RequestCode.DELETE_TOPIC_IN_NAMESRV: return deleteTopicInNamesrv(ctx, request); case RequestCode.GET_KVLIST_BY_NAMESPACE: return this.getKVListByNamespace(ctx, request); case RequestCode.GET_TOPICS_BY_CLUSTER: return this.getTopicsByCluster(ctx, request); case RequestCode.GET_SYSTEM_TOPIC_LIST_FROM_NS: return this.getSystemTopicListFromNs(ctx, request); case RequestCode.GET_UNIT_TOPIC_LIST: return this.getUnitTopicList(ctx, request); case RequestCode.GET_HAS_UNIT_SUB_TOPIC_LIST: return this.getHasUnitSubTopicList(ctx, request); case RequestCode.GET_HAS_UNIT_SUB_UNUNIT_TOPIC_LIST: return this.getHasUnitSubUnUnitTopicList(ctx, request); default: break; &#125; 其他 namesrv是无状态的，可以任意水平扩展，每一个broker都与所有namesrv保持长链接(有个scheduled task会按一定频率给所有namesrv做register broker的操作)，所以namesrv之间没有主从关系，他们之间也不需要复制数据。client(producer/consumer)会随机选择一个namesrv进行连接。 client和broker中的namesrv地址有以下四种获取方式： 通过命令行或者配置文件设置namesrv地址。 在启动之前通过指定java选项rocketmq.namesrv.addr。 设置NAMESRV_ADDR环境变量，brokers和clients会去读取这个环境变量。 通过一个定时任务每两分钟去一个web服务中获取并更新namesrvaddr的列表。","categories":[{"name":"middleware","slug":"middleware","permalink":"http://yoursite.com/categories/middleware/"}],"tags":[{"name":"rocketmq","slug":"rocketmq","permalink":"http://yoursite.com/tags/rocketmq/"}],"keywords":[{"name":"middleware","slug":"middleware","permalink":"http://yoursite.com/categories/middleware/"}]},{"title":"Rocketmq源码解析-1.Rocketmq介绍","slug":"rocketmq-structure","date":"2019-12-18T12:16:13.000Z","updated":"2019-12-19T09:19:57.412Z","comments":true,"path":"middleware/rocketmq-structure/","link":"","permalink":"http://yoursite.com/middleware/rocketmq-structure/","excerpt":"Rocketmq优势： rocketmq原生就支持分布式，而activemq原生存在单点性。 rocketmq可以严格的保证消息的顺序，而activemq不能保证。 rocketmq可以提供亿级消息的堆积能力，不过这不是重点，重点是堆积了亿级消息还能保持低延迟写入。","text":"Rocketmq优势： rocketmq原生就支持分布式，而activemq原生存在单点性。 rocketmq可以严格的保证消息的顺序，而activemq不能保证。 rocketmq可以提供亿级消息的堆积能力，不过这不是重点，重点是堆积了亿级消息还能保持低延迟写入。 丰富的消息推拉模式（push和pull）：push好理解，在消费者端设置消息listener回调；pull需要应用主动的调用拉消息的方法从broker拉取消息，这里存在一个记录消费位置的问题，如果不记录会存在重复消费的问题。 一般mq分布式协调使用zookeeper，rocketmq自己实现了一个nameserver，更加轻量级，性能更好。 消息失败重试机制、高效的订阅者水平扩展能力、强大的api、事务机制等等。 rocketmq有group的概念，通过group机制可以实现天然的消息负载均衡。 Rocketmq部署模式： 单master模式：无需多言，一旦单个broker重启或宕机，一切都结束了！显然，线上不可以使用。 多master模式：全是master，没有slave。一个broker宕机了，应用没有影响，缺点在于宕机的master上未被消费的消息在master没有恢复之前不可以订阅。 多master多slave模式（异步复制）：高可用，采用异步复制的方式，主备之间短暂延迟，ms级别。master宕机，消费者可以从slave上消费，但是master的宕机会导致丢失掉极少量的消息。 多master多slave模式（同步双写）：和上面的区别在于采用的是同步方式，也就是master、slave都写成功才会向应用返回成功。可见不论是数据，还是服务都没有单点，都非常可靠！缺点在于同步的性能比异步稍低。 Rocketmq项目结构： acl：访问权限控制模块 broker：消息代理模块，串联 Producer/Consumer 和 Store client：客户端模块，包含producer和consumer，负责消息的发送和消费 common：公共模块，供其他模块使用 distribution：包含一些 sh 脚本和 配置，主要供部署时使用 example：一些rocketmq使用的示例代码 filter：过滤器模块 logappender：接入日志需要的appender模块 logging：日志模块 namesrv：rocketmq的注册中心，broker，produce，consumer以及topic信息会在namesrv中注册 openmessaging：忽略，没了解过 remoting：远程调用模块，基于Netty实现，produer，consumer，broker之间通过这个模块通信。 srvutil：解析命令行的工具类ServerUtil store：消息存储模块 test：测试用例模块 tools：一些工具类，基于它们可以写一些 sh 工具来管理、查看MQ系统的一些信息 对于这些模块我们不需要都去研究源码，只需要挑几个重点去关注。这里面比较重要的是broker，client，common，namesrv，remoting，store这几个模块。 Rocketmq逻辑部署架构 这是 Rocketmq 的逻辑部署结构(参考《RocketMQ原理简介 v3.1.1》)，包括 producer/broker/namesrv/consumer 四大部分。namesrv 起到注册中心的作用，部署的时候会用到 rocketmq-namesrv/rocketmq-common/rocketmq-remoting 三个模块的代码；broker 部署的时候会用到 rocketmq-broker/rocketmq-store/rocketmq-common/rocketmq-remoting 四个模块的代码；producer 和 consumer 会用到 rocketmq-client/rocketmq-common/rocketmq-remoting 三个模块的代码，这里虽然将它们分开画了，但实际上一个应用往往既是producer又是consumer。","categories":[{"name":"middleware","slug":"middleware","permalink":"http://yoursite.com/categories/middleware/"}],"tags":[{"name":"rocketmq","slug":"rocketmq","permalink":"http://yoursite.com/tags/rocketmq/"}],"keywords":[{"name":"middleware","slug":"middleware","permalink":"http://yoursite.com/categories/middleware/"}]},{"title":"Rocketmq安装部署","slug":"rocketmq-install","date":"2019-12-17T11:34:20.000Z","updated":"2019-12-20T10:47:49.148Z","comments":true,"path":"middleware/rocketmq-install/","link":"","permalink":"http://yoursite.com/middleware/rocketmq-install/","excerpt":"获取源码,打包编译 从github下载源码，git clone https://github.com/apache/rocketmq.git 编译源码，进入到主目录，然后执行命令： mvn -Prelease-all -DskipTests clean install -U 编译完之后我们只需要下图红框之内的目录进行部署。","text":"获取源码,打包编译 从github下载源码，git clone https://github.com/apache/rocketmq.git 编译源码，进入到主目录，然后执行命令： mvn -Prelease-all -DskipTests clean install -U 编译完之后我们只需要下图红框之内的目录进行部署。 上图中bin目录是存放部署启动的脚本，conf目录存放的是配置文件，lib目录是打包好之后的所有jar包。 启动Namesrv首先设置好系统JAVA_HOME变量（必须使用64位JDK），然后在主目录下执行nohup sh bin/mqnamesrv &amp;，启动成功之后可以查看到进程，端口默认是9876。(启动默认指定的堆内存是4G，我们自己测试时可以通过修改runserver.sh文件中参数适当改小) 启动broker&nbsp;&nbsp;&nbsp;broker集群主要有四种配置方式：单master，多master，多master多slave同步双写，多master多slave异步复制。（现在好像多了一种dledger的方式，暂时还没研究，不太明白）。&nbsp;&nbsp;&nbsp;Master和Slave的配置文件参考conf目录下的配置文件。Master与Slave通过指定相同的brokerName参数来配对，Master的BrokerId必须是0，Slave的BrokerId必须是大于0的数。&nbsp;&nbsp;&nbsp;启动命令：nohup sh bin/mqbroker -n localhost:9876 -c conf/2m-2s-async/broker-a.properties &amp; 其他 查看日志namesrv和broker的日志默认存在下面所示目录中：tail -f ~/logs/rocketmqlogs/namesrv.logtail -f ~/logs/rocketmqlogs/broker.log 关闭服务器分别关闭broker和namesrv:sh bin/mqshutdown brokersh bin/mqshutdown namesrv 其他命令查看集群情况： ./bin/mqadmin clusterList -n localhost:9876查看broker状态： ./bin/mqadmin brokerStatus -n localhost:9876 -b localhost:10911查看topic列表： ./bin/mqadmin topicList -n localhost9876查看topic状态： ./bin/mqadmin topicStatus -n localhost:9876 -t MyTopic (换成想查询的 topic)查看topic路由： ./bin/mqadmin topicRoute -n localhost:9876 -t MyTopic Rocketmq-Console安装 使用git命令下载项目源码，由于我们仅需要rocketmq-console，故下载此项目对应分支即可。git clone -b release-rocketmq-console-1.0.0 https://github.com/apache/rocketmq-externals.git 进入项目文件夹并修改配置文件 cd rocketmq-externals/rocketmq-console/ vi src/main/resources/application.properties (可以修改rocketmq.config.namesrvAddr，当然也可以后面启动时通过参数指定) 执行maven命令打成jar包：mvn clean package -Dmaven.test.skip=true 启动： java -jar -n localhost:9876 rocketmq-console-ng-1.0.0.jar &amp; 浏览器访问http://localhost:8080就可以查看管理界面。","categories":[{"name":"middleware","slug":"middleware","permalink":"http://yoursite.com/categories/middleware/"}],"tags":[{"name":"rocketmq","slug":"rocketmq","permalink":"http://yoursite.com/tags/rocketmq/"}],"keywords":[{"name":"middleware","slug":"middleware","permalink":"http://yoursite.com/categories/middleware/"}]},{"title":"Java NIO详解","slug":"nio","date":"2018-10-24T10:26:20.000Z","updated":"2018-10-27T06:32:32.604Z","comments":true,"path":"Java/nio/","link":"","permalink":"http://yoursite.com/Java/nio/","excerpt":"1.NIO概念 NIO与传统IO相比最大的特点就是非阻塞。IO是阻塞的，当一个线程调用read或write方法时，线程必须等待文件读取完或者写完才能去执行其他任务；而NIO是非阻塞的，它允许线程请求从通道中读取数据，如果当前没有可用数据，线程可以继续执行其他操作，而不是一直阻塞。","text":"1.NIO概念 NIO与传统IO相比最大的特点就是非阻塞。IO是阻塞的，当一个线程调用read或write方法时，线程必须等待文件读取完或者写完才能去执行其他任务；而NIO是非阻塞的，它允许线程请求从通道中读取数据，如果当前没有可用数据，线程可以继续执行其他操作，而不是一直阻塞。 2.NIO主要组件NIO包含三个主要的类： Buffer Channel Selector NIO有许多类组成，但是buffer，channel和selector构成了核心的API。所以接下来会主要介绍这三个类。通常，NIO中的所有IO都是以channel开始。Channel其实和IO中的stream差不多。通过channel数据能被写入buffer中，同样数据能从buffer中写入channel。如下图： Buffer和Channel的主要子类如下所示： ByteBuffer -&gt;MappedByteBuffer(实现内存映射文件) CharBuffer ShortBuffer IntBuffer FloatBuffer DoubleBuffer LongBuffer FileChannel DatagramChannel SocketChannel ServerSocketChannel Selector允许一个线程操作多个Channel。如果你的应用程序打开了很多连接（Channel），但是每个连接上的通信量很低，那么这时候Selector就很方便。比如聊天服务器。下图说明了selector和channel的关系： 3.Buffer 3.1 Capacity、Position、Limitbuffer主要有三个属性：capacity、position和limit。 capacity：buffer的容量，我们在分配buffer时会指定一个容量。当buffer达到容量之后需要清除数据才能继续向buffer中写入数据。 position：buffer中数据写入的位置。初始为0，往buffer写入或读取一字节数据，position就会加1，当清除buffer 中数据或者由写模式切换为读模式时，position会重新置0，postion最大为capacity-1。 limit：在写模式中，limit就等于buffer的capacity。在读模式中，limit是指可以从buffer中读取的数据量的限制。 3.2 Allocating a Buffer想要得到一个buffer首先必须分配它，每个Buffer类中都提供了一个静态方法allocate()来分配buffer。 12ByteBuffer buf = ByteBuffer.allocate(2048);CharBuffer buf = CharBuffer.allocate(1024); 3.3 Writing Data to a Buffer往buffer中写入数据有两种方式： 一是调用buffer的put方法写入数据，如buf.put(127)； 二是将数据通过channel写入buffer，如int num = channel.read(buf);flip()方法是将buffer从写模式切换到读模式，这个会重新设置position和limit的值。 3.4 Reading Data from a Buffer从buffer中读取数据也有两种方式： 一是调用buffer的get方式读取数据，如buf.get()； 二是读取buffer数据到channel中，如int bytesWritten = inChannel.write(buf); 3.5 rewind()、clear()、compact() rewind()可以将position值重新置为0，这样就可以重新读取buffer中的数据。 clear()方法将设置poistion为0，设置limit为capacity，clear虽然不会清除buffer中的数据，但是后续写入的数据会覆盖之前的数据，相当于清空了buffer数据。 compact()和clear不同，它会将之前的数据移向左边，将position设置为最后一个未读数据，从这个基础上再开始写入。 3.6 mark()、reset()调用mark()方法可以标记当前buffer中的position，执行一些操作之后调用reset()可以可以将position回到刚才标记的位置。12345buffer.mark();//call buffer.get() a couple of times, e.g. during parsing.buffer.reset(); //set position back to mark. 4.Channel所有的NIO操作都是始于channel，数据的读取和写入都会经过channel。 4.1 FileChannel(文件通道，用于文件的读和写)不能设置为非阻塞模式，只能是阻塞模式 Open a FileChannel使用一个FileChannel之前必须先打开它，但是不可能直接打开FileChannel，必须通过InputStream，OutputStream或者RandomAccessFile来获取一个FileChannel。RandomAccessFile aFile = new RandomAccessFile(&quot;data/nio-data.txt&quot;, &quot;rw&quot;);FileChannel inChannel = aFile.getChannel(); Read Data from a FileChannelByteBuffer buf = ByteBuffer.allocate(48);int bytesRead = inChannel.read(buf);上面bytesRead如果返回-1，说明读取完了 Write Data to a FileChannelString newData = &quot;New String to write to file...&quot; + System.currentTimeMillis();ByteBuffer buf = ByteBuffer.allocate(48);buf.clear();buf.put(newData.getBytes());buf.flip();while(buf.hasRemaining()) {channel.write(buf);} Close a FileChannelchannel.close() FileChannel Position当你想在一个特定位置读取或写入FileChannel，你可以通过position()方法获取FileChannel的当前位置，然后你可以通过position(long newPosition)方法设置新的postiion。long pos=channel.position();channel.position(pos + 123); FileChannel SizeFileChannel对象的size()方法返回通道连接的文件的文件大小。 FileChannel Truncate调用FileChannel.truncate()方法来截断文件。当您截断一个文件时，您将它以给定的长度截断。channel.truncate(1024); FileChannel Forceforce()方法将所有未写入的数据从通道刷新到磁盘。force()方法以一个布尔值作为参数，告诉文件元数据(权限等)是否也应该刷新。 4.2 SocketChannel(用于通过TCP读写数据)SocketChannel是连接到TCP网络套接字的通道。它相当于Java NIO的Java网络套接字。打开一个SocketChannel的代码如下：SocketChannel socketChannel = SocketChannel.open();socketChannel.connect(new InetSocketAddress(&quot;http://xxx.com&quot;, 80));SocketChannel的读写和FileChannel没什么区别。 4.3 ServerSocketChannel(TCP对应的服务端，用来某个端口进来的请求)ServerSocketChannel可以用来监听进来的tcp连接，就像java标准网络中的ServerSocket。 12345678910//实例化ServerSocketChannel serverSocketChannel = ServerSocketChannel.open();//监听端口serverSocketChannel.socket().bind(new InetSocketAddress(9999));while(true)&#123; //监听进来的tcp连接，创建SocketChannel SocketChannel socketChannel = serverSocketChannel.accept(); //do something with socketChannel...&#125; 4.4 DatagramChannel(用于通过UDP从网络上读写数据)DatagramChannel是一个能够发送和接收UDP包的通道，由于UDP是无连接的，所以在默认情况下，您不能像从其他通道那样读写DatagramChannel。你只可以发送和接收数据包。监听端口 12DatagramChannel channel = DatagramChannel.open();channel.socket().bind(new InetSocketAddress(9999)); 接收数据123ByteBuffer buf = ByteBuffer.allocate(48);buf.clear();channel.receive(buf); 发送数据 123456String newData = &quot;New String to write to file...&quot;+ System.currentTimeMillis();ByteBuffer buf = ByteBuffer.allocate(48);buf.clear();buf.put(newData.getBytes());buf.flip();int bytesSent = channel.send(buf, new InetSocketAddress(&quot;xxx.com&quot;, 80)); 4.5 Channel Transfers在NIO中，如果其中一个channel是FileChannel时，则可以将数据直接从一个通道传到另一个通道。FileChannel中的transferFrom()方法能够将数据从一个源通道传送到FileChannel中。1234567RandomAccessFile fromFile = new RandomAccessFile(&quot;fromFile.txt&quot;, &quot;rw&quot;);FileChannel fromChannel = fromFile.getChannel();RandomAccessFile toFile = new RandomAccessFile(&quot;toFile.txt&quot;, &quot;rw&quot;);FileChannel toChannel = toFile.getChannel();long position = 0;long count = fromChannel.size();toChannel.transferFrom(fromChannel, position, count); FileChannel中的transferTo()方法可以将数据从FileChannel中传送到其他通道。1234567RandomAccessFile fromFile = new RandomAccessFile(&quot;fromFile.txt&quot;, &quot;rw&quot;);FileChannel fromChannel = fromFile.getChannel();RandomAccessFile toFile = new RandomAccessFile(&quot;toFile.txt&quot;, &quot;rw&quot;);FileChannel toChannel = toFile.getChannel();long position = 0;long count = fromChannel.size();fromChannel.transferTo(position, count, toChannel); 5.SelectorSelector可以检查一个或多个channel，并确定哪些channel准备就绪。通过这种方式，一个线程可以管理多个channel，从而管理多个网络连接。 5.1 创建Selector和注册Channel到Selector1234Selector selector = Selector.open();//设置为非阻塞模式channel.configureBlocking(false);SelectionKey key = channel.register(selector, SelectionKey.OP_READ); 上面第二行用于设置非阻塞模式，由于Selector必须工作在非阻塞模式中，所以FileChannel不能使用Selector。register方法的第二个参数是一个int型参数（使用二进制标记位，叫interest set），用于表明channel需要监听哪些感兴趣的事件，共有以下四种事件。 Read对应SelectionKey.OP_READ(值为1&lt;&lt;0)，表示channel可以读取数据。 Write对应SelectionKey.OP_WRITE(值为1&lt;&lt;2)，表示channel可以写入数据。 Connect对应SelectionKey.OP_CONNECT(值为1&lt;&lt;3)，表示channel建立连接。 Accept对应SelectionKey.OP_ACCEPT(值为1&lt;&lt;4)，表示channel可以接收传入的连接。 如果想要设置多个事件，则将对应的key进行与操作。如下： 1int interestSet = SelectionKey.OP_READ | SelectionKey.OP_WRITE; 5.2 SelectionKey上面注册channel时register方法会返回一个SelectionKey对象。这个SelectionKey对象包含以下属性： Interest SetInterest Set中是channel感兴趣的事件集合，你可以通过下面的方法获取Interest Set。 123456int interestSet = selectionKey.interestOps();boolean isInterestedInAccept = interestSet &amp; SelectionKey.OP_ACCEPT;boolean isInterestedInConnect = interestSet &amp; SelectionKey.OP_CONNECT;boolean isInterestedInRead = interestSet &amp; SelectionKey.OP_READ;boolean isInterestedInWrite = interestSet &amp; SelectionKey.OP_WRITE; Ready SetReady Set 表示的是channel已经准备好的事件集合。通常在选择一个channel之后来访问这个集合。 12345int readySet = selectionKey.readyOps();selectionKey.isAcceptable();selectionKey.isConnectable();selectionKey.isReadable();selectionKey.isWritable(); Channel + Selector获取channel和selector比较简单。 12Channel channel = selectionKey.channel();Selector selector = selectionKey.selector(); Attaching Objects可以将对象附加到SelectionKey对象上，这是识别channel或者将信息附加到channel上的方便方法。 123selectionKey.attach(theObject);Object attachedObj = selectionKey.attachment(); 也可以在register的时候附加对象。 1SelectionKey key = channel.register(selector, SelectionKey.OP_READ, theObject); 5.3 Select Channel通过Selector的select方法我们可以选择一个channel。select方法主要有三个： select()：这个方法会阻塞直到至少一个channel准备好。 select(long timeout)：和select()功能类似，只是制定了阻塞时间。 selectNow()：这个不会阻塞，不管有没有准备好的channel，都会立即返回。 上面select方法的返回值是一个int，表示有多少个通道准备好。如果没有对第一个准备好的通道做任何操作，那么会有两个准备好的通道，但是在每个select()调用之间只有一个通道准备好。 wakeUp()：这个方法是用来唤醒等待在 select() 和 select(timeout) 上的线程的。如果 wakeup() 先被调用，此时没有线程在 select 上阻塞，那么之后的一个 select() 或 select(timeout) 会立即返回，而不会阻塞，当然，它只会作用一次。 5.5 Full Selector Example1234567891011121314151617181920212223242526272829303132333435363738Selector selector = Selector.open();channel.configureBlocking(false);SelectionKey key = channel.register(selector, SelectionKey.OP_READ);while(true) &#123; int readyChannels = selector.select(); if(readyChannels == 0) continue; Set&lt;SelectionKey&gt; selectedKeys = selector.selectedKeys(); Iterator&lt;SelectionKey&gt; keyIterator = selectedKeys.iterator(); while(keyIterator.hasNext()) &#123; SelectionKey key = keyIterator.next(); if(key.isAcceptable()) &#123; // a connection was accepted by a ServerSocketChannel. &#125; else if (key.isConnectable()) &#123; // a connection was established with a remote server. &#125; else if (key.isReadable()) &#123; // a channel is ready for reading &#125; else if (key.isWritable()) &#123; // a channel is ready for writing &#125; keyIterator.remove(); &#125;&#125; 6.NIO PipeNIO Pipe是两个线程之间一个单向的数据连接。Pipe有一个source channel和一个sink channel。将数据写入sink channel，然后可以从source channel读取这些数据。123456789101112131415161718//open pipePipe pipe = Pipe.open();//write data to sink channelPipe.SinkChannel sinkChannel = pipe.sink();String newData = &quot;New String to write to file...&quot; + System.currentTimeMillis();ByteBuffer buf = ByteBuffer.allocate(48);buf.clear();buf.put(newData.getBytes());buf.flip();while(buf.hasRemaining()) &#123; sinkChannel.write(buf);&#125;//read data from source channelPipe.SourceChannel sourceChannel = pipe.source();ByteBuffer buf = ByteBuffer.allocate(48);int bytesRead = sourceChannel.read(buf);","categories":[{"name":"Java","slug":"Java","permalink":"http://yoursite.com/categories/Java/"}],"tags":[{"name":"nio","slug":"nio","permalink":"http://yoursite.com/tags/nio/"}],"keywords":[{"name":"Java","slug":"Java","permalink":"http://yoursite.com/categories/Java/"}]},{"title":"二叉搜索树Java实现","slug":"bst","date":"2018-10-23T12:16:13.000Z","updated":"2018-10-24T08:49:28.025Z","comments":true,"path":"数据结构和算法/bst/","link":"","permalink":"http://yoursite.com/数据结构和算法/bst/","excerpt":"二叉搜索树特性： 具有二叉树的所有特性。 左节点的值永远小于根结点。 有节点的值永远大于根结点。 具有较高的查找效率。 插入效率也高，比链表要高。","text":"二叉搜索树特性： 具有二叉树的所有特性。 左节点的值永远小于根结点。 有节点的值永远大于根结点。 具有较高的查找效率。 插入效率也高，比链表要高。 二叉搜索树的Java代码实现： insert方法：插入一个节点 getMin方法：获取最小节点 getMax方法：获取最大节点 search方法：查找一个节点 delete方法：删除一个节点 deleteMax方法：删除最小节点 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299public class BinarySearchTree&lt;E extends Comparable&lt;E&gt;&gt; &#123; private Node&lt;E&gt; root; static class Node&lt;E&gt; &#123; E item; Node&lt;E&gt; leftChild; Node&lt;E&gt; rightChild; public Node(E item) &#123; this.item = item; &#125; &#125; /** * 插入 * * @param e */ public void insert(E e) &#123; root = insertNode(root, e); &#125; /** * 插入节点 * * @param node * @param e * @return */ private Node&lt;E&gt; insertNode(Node&lt;E&gt; node, E e) &#123; if (node == null) &#123; return new Node&lt;&gt;(e); &#125; int cmp = e.compareTo(node.item); if (cmp &lt; 0) &#123; //要插入的节点值比当前节点值小，则向当前节点的左节点递归插入，插入后的值赋给当前节点的左节点 node.leftChild = insertNode(node.leftChild, e); &#125; else if (cmp &gt; 0) &#123; //要插入的节点值比当前节点值大，则向当前节点的右节点递归插入，插入后的值赋给当前节点的右节点 node.rightChild = insertNode(node.rightChild, e); &#125; return node; &#125; /** * 获取整个二叉树的最小节点 * * @return */ public Node&lt;E&gt; getMin() &#123; return getMin(root); &#125; /** * 获取以指定节点为根结点的子树中的最小节点 * 由二叉搜索树的特性可知道最小节点一定是最左的一个节点， * 所以一直找最左的节点 * * @param node * @return */ public Node&lt;E&gt; getMin(Node&lt;E&gt; node) &#123; //递归实现 if (node.leftChild == null) &#123; return node; &#125; return getMin(node.leftChild); //遍历实现 /*Node&lt;E&gt; min = node; while (min.leftChild != null) &#123; min = min.leftChild; &#125; return min;*/ &#125; /** * 获取整个二叉树的最大节点 * * @return */ public Node&lt;E&gt; getMax() &#123; return getMax(root); &#125; /** * 获取以指定节点为根结点的子树中的最大节点 * 由二叉搜索树的特性可知道最小节点一定是最右的一个节点， * 所以一直找最右的节点 * * @param node * @return */ public Node&lt;E&gt; getMax(Node&lt;E&gt; node) &#123; //递归实现 if (node.rightChild == null) &#123; return node; &#125; return getMax(node.rightChild); //遍历实现 /*Node&lt;E&gt; max = node; while (max.rightChild != null) &#123; max = max.rightChild; &#125; return max;*/ &#125; public Node&lt;E&gt; search(E e) &#123; return search(root, e); &#125; /** * 查找某个节点 * * @param node * @param e * @return */ public Node&lt;E&gt; search(Node&lt;E&gt; node, E e) &#123; //遍历实现 int count = 0; Node&lt;E&gt; current = node; while (current != null) &#123; count++; int cmp = current.item.compareTo(e); if (cmp &gt; 0) &#123; current = current.leftChild; &#125; else if (cmp &lt; 0) &#123; current = current.rightChild; &#125; else if (cmp == 0) &#123; System.out.println(&quot;查找次数为：&quot; + count); return current; &#125; &#125; return null; //递归实现 /*if (node == null) &#123; return null; &#125; int cmp = node.item.compareTo(e); if (cmp &gt; 0) &#123; return search(node.leftChild, e); &#125; else if (cmp &lt; 0) &#123; return search(node.rightChild, e); &#125; else &#123; return node; &#125;*/ &#125; /** * 删除值为e的节点 * * @param key */ public void delete(E key) &#123; root = delete(root, key); &#125; /** * 删除节点 * * @param node * @param key * @return */ public Node&lt;E&gt; delete(Node&lt;E&gt; node, E key) &#123; if (node == null) &#123; return null; &#125; else &#123; int cmp = key.compareTo(node.item); if (cmp &gt; 0) &#123; //判断删除节点的值比当前节点大，则向当前节点的右节点递归删除 node.rightChild = delete(node.rightChild, key); &#125; else if (cmp &lt; 0) &#123; node.leftChild = delete(node.leftChild, key); &#125; else &#123; if (node.rightChild == null) &#123; return node.leftChild; &#125; if (node.leftChild == null) &#123; return node.rightChild; &#125; Node&lt;E&gt; t = node; node = getMin(t.rightChild); node.rightChild = deleteMin(t.rightChild); node.leftChild = t.leftChild; &#125; &#125; return node; &#125; /** * 删除树中最小节点 */ public void deleteMin() &#123; root = deleteMin(root); &#125; /** * 删除最小节点 * * @param node * @return */ public Node&lt;E&gt; deleteMin(Node&lt;E&gt; node) &#123; //如果当前节点左节点为空，则当前节点为最小节点，将当前节点的右节点返回赋值给上一节点的左节点，则表示删除了改节点。 if (node.leftChild == null) &#123; return node.rightChild; &#125; //递归删除当前节点的左节点，并将返回值赋给左节点 node.leftChild = deleteMin(node.leftChild); return node; &#125; /** * 打印节点值 * * @param node */ private void printNode(Node&lt;E&gt; node) &#123; System.out.println(node.item); &#125; /** * 先序遍历 */ public void firstOrderTraversal() &#123; firstOrderTraversal(root); &#125; /** * 先序遍历 * * @param node */ public void firstOrderTraversal(Node&lt;E&gt; node) &#123; if (node != null) &#123; printNode(node); if (node.leftChild != null) &#123; firstOrderTraversal(node.leftChild); &#125; if (node.rightChild != null) &#123; firstOrderTraversal(node.rightChild); &#125; &#125; &#125; /** * 中序遍历 */ public void inOrderTraversal() &#123; inOrderTraversal(root); &#125; /** * 中序遍历 * * @param node */ public void inOrderTraversal(Node&lt;E&gt; node) &#123; if (node != null) &#123; if (node.leftChild != null) &#123; inOrderTraversal(node.leftChild); &#125; printNode(node); if (node.rightChild != null) &#123; inOrderTraversal(node.rightChild); &#125; &#125; &#125; /** * 后续遍历 */ public void postOrderTraversal() &#123; postOrderTraversal(root); &#125; /** * 后续遍历 * * @param node */ public void postOrderTraversal(Node&lt;E&gt; node) &#123; if (node != null) &#123; if (node.leftChild != null) &#123; postOrderTraversal(node.leftChild); &#125; if (node.rightChild != null) &#123; postOrderTraversal(node.rightChild); &#125; printNode(node); &#125; &#125;&#125;","categories":[{"name":"数据结构和算法","slug":"数据结构和算法","permalink":"http://yoursite.com/categories/数据结构和算法/"}],"tags":[{"name":"算法","slug":"算法","permalink":"http://yoursite.com/tags/算法/"}],"keywords":[{"name":"数据结构和算法","slug":"数据结构和算法","permalink":"http://yoursite.com/categories/数据结构和算法/"}]},{"title":"正则表达式","slug":"regular","date":"2018-10-15T10:17:26.000Z","updated":"2018-10-24T08:58:45.121Z","comments":true,"path":"其他/regular/","link":"","permalink":"http://yoursite.com/其他/regular/","excerpt":"常用正则表达式","text":"常用正则表达式 表达式 描述 . 匹配出换行符外任意字符 \\ 转义符，可以将一些有特殊含义的字符转化为本身含义，如\\.代表点本身的含义。 [ ] 匹配中括号中字符的一个，如[abc]表示匹配a、b、c中的一个字符。 &#124; 匹配两个字符中的一个，如a&#124;b表示匹配a或者b。 [0-9A-Za-z] 字符区间，[0-9]表示0-9中的一个数。 ^ 取非匹配，[^0-9]表示不是0-9中的一个字符。 \\d 匹配数字 \\D 匹配非数字 \\w 匹配字母 \\W 匹配非字母 + 匹配一个或多个字符，如\\d+表示匹配一个或多个数字。 * 匹配0个或多个字符。 ？ 匹配0个或一个字符。 {n} 匹配多次，如\\w{3}表示匹配3个字母。 {m,n} 匹配次数是一个区间，如\\d{2,4}表示匹配2-4个数字。 {n,} 匹配至少次数的字符。 () 标记一个子表达式开始和结束 ^ 放在外面表示匹配字符串开始位置，如果是在方括号内表示取非 $ 匹配字符串结束位置 \\f 匹配一个换页符 \\n 匹配一个换行符 \\r 匹配一个回车符 \\s 匹配任何空白字符，包括空格、制表符、换页符等等。等价于 [ \\f\\n\\r\\t\\v] \\S 匹配任何非空白字符，等价于[ ^\\f\\n\\r\\t\\v] \\t 匹配一个制表符 \\v 匹配一个垂直制表符 \\b 匹配一个单词边界，即字与空格间位置 \\B 匹配一个非单词边界 ?= 向前匹配，如?=:表示匹配:然后向前匹配，最后结果不包含: ?&lt;= 向前匹配，如(?&lt;=\\$)[0-9.]+表示匹配$然后向后匹配，最后结果不包含$ 防止过度匹配 * 和+ 都是所谓的“贪婪型”元字符，它们在进行匹配时的行为模式是多多益善而不是适可而止的。它们会尽可能地从一段文本的开头一直匹配到这段文本的末尾，而不是从这段文本的开头匹配到碰到第一个匹配时为止。 为了防止这种贪婪型匹配，我们需要使用对应字符的惰性版本，* 使用 *？，+ 使用 +？，{n,}使用{n,}? 回溯引用 回溯引用指的是模式的后半部分引用在前半部分中定义的子表达式。如 &lt;hH&gt;.*?&lt;/[hH]\\1&gt;，这其中最后的\\1表示前面第一个子表达式匹配的结果，即([1-6])，依此类推，\\2表示第二个子表达式，\\n表示第n个子表达式。 回溯引用在替换操作中也很有用，如(\\d{3})(-)(\\d{3})(-)(\\d{4})这个正则表达式，使用替换的表达式($1) $3-$5，可以将匹配到的字符替换成别的格式。其中$1,$3,$5分别表示第1，第3，第5个子表达式。","categories":[{"name":"其他","slug":"其他","permalink":"http://yoursite.com/categories/其他/"}],"tags":[{"name":"正则","slug":"正则","permalink":"http://yoursite.com/tags/正则/"}],"keywords":[{"name":"其他","slug":"其他","permalink":"http://yoursite.com/categories/其他/"}]},{"title":"Java原子操作类","slug":"concurrent2","date":"2018-10-07T14:38:14.000Z","updated":"2018-10-24T08:01:34.332Z","comments":true,"path":"Java/concurrent2/","link":"","permalink":"http://yoursite.com/Java/concurrent2/","excerpt":"","text":"","categories":[{"name":"Java","slug":"Java","permalink":"http://yoursite.com/categories/Java/"}],"tags":[{"name":"并发","slug":"并发","permalink":"http://yoursite.com/tags/并发/"}],"keywords":[{"name":"Java","slug":"Java","permalink":"http://yoursite.com/categories/Java/"}]},{"title":"Java内存模型","slug":"concurrent1","date":"2018-10-07T07:58:29.000Z","updated":"2018-10-24T08:17:49.737Z","comments":true,"path":"Java/concurrent1/","link":"","permalink":"http://yoursite.com/Java/concurrent1/","excerpt":"1、Java内存模型的抽象结构 Java内存模型就是Java Memory Model（以下简称JMM），是Java虚拟机规范的一部分。JMM规定：变量存储在主存中，每个线程有自己的工作内存，线程工作内存中保存了变量在主存的副本拷贝。主存是线程共享的，工作内存变量是各个线程独享的。线程工作时，从主存中复制变量到线程的工作内存，然后在工作内存中操作变量副本，最后再把变量副本写回到主内存。","text":"1、Java内存模型的抽象结构 Java内存模型就是Java Memory Model（以下简称JMM），是Java虚拟机规范的一部分。JMM规定：变量存储在主存中，每个线程有自己的工作内存，线程工作内存中保存了变量在主存的副本拷贝。主存是线程共享的，工作内存变量是各个线程独享的。线程工作时，从主存中复制变量到线程的工作内存，然后在工作内存中操作变量副本，最后再把变量副本写回到主内存。Java内存模型是一种共享内存模型： 线程只能操作工作内存，不能直接操作主存。 每个线程只能访问自己的工作内存，不能访问其他线程的工作内存。 线程之间的数据通信必须通过主存中完成。 2、并发三问题 重排序为了提高性能，编译器和处理器会对指令进行重排序，重排序主要有三种类型： 编译器重排序：编译器在不改变单线程程序语义的前提下，可以重新安排字节码的执行顺序；也就是编译生成的机器码顺序和源代码顺序不一样。 处理器重排序：现代处理器采用指令级并行技术将多条指令重叠执行，如果不存在数据依赖性，处理器可以改变语句对应机器指令的执行顺序；也就是CPU在执行字节码时，执行顺序可能和机器码顺序不一样。 内存重排序：由于处理器使用缓存和读/写缓冲区，这使得加载和存储操作看上去可能是在乱序执行。 123456789101112131415class ReorderExample &#123; int a = 0; boolean flag = false; public void writer() &#123; a = 1; // A1 flag = true; // A2 &#125; public void reader() &#123; if (flag) &#123; // B1 int i = a * a; // B2 &#125; &#125;&#125; 线程1执行writer()方法，线程2执行reader()方法，结果怎样？ 由于writer()方法中的A1和A2操作没有依赖关系，所以可能被重排序，先执行A2，再执行A1，这种情况下由于a=0，所以i=0；reader方法中的B1、B2虽然有依赖关系，但是仍然可以重排序，B2先执行a*a=0放在缓存，当flag为true时将i赋值为0。 内存可见性内存可见性问题是由于多核缓存引起的。现在的多核cpu都有自己的一级缓存和二级缓存。Java作为高级语言，屏蔽了底层这些细节，构建了JMM规范。JMM抽象了主存和工作内存的概念。由于线程可能不能及时将工作内存中变量刷到主存，造成其他线程读取到的变量可能是错误的，这就是内存可见性问题。 原子性原子性即一个操作不可拆分。JMM只保证像read/load/store/write这样很少的操作是原子性的，甚至在32位平台下，对64位数据的读取和赋值都不能保证其原子性（long变量赋值是需要通过两个操作来完成的）。简单说，int i=10; 是原子的；i = i + 1 不是原子的；甚至long v = 100L 也可能不是原子的。 3、volatile关键字volatile关键字有两个作用：一是保证内存可见性；二是防止指令重排序。 可见性：被volatile修饰的变量，如果一个线程修改了其的值，另一个线程能够立即读取到最新的值。 禁止指令重排序：被volatile修饰的变量，保证在它前面的代码先执行，在它后面的代码后执行。 volatile小结 volatile 修饰符适用于以下场景：某个属性被多个线程共享，其中有一个线程修改了此属性，其他线程可以立即得到修改后的值。在并发包的源码中，它使用得非常多。 volatile 属性的读写操作都是无锁的，它不能替代 synchronized，因为它没有提供原子性和互斥性。因为无锁，不需要花费时间在获取锁和释放锁上，所以说它是低成本的。 volatile 只能作用于属性，我们用 volatile 修饰属性，这样 compilers 就不会对这个属性做指令重排序。 volatile 提供了可见性，任何一个线程对其的修改将立马对其他线程可见。volatile 属性不会被线程缓存，始终从主存中读取。 4、happens-before规则 happens-before用来指定两个操作之间的顺序，这两个操作可以在一个线程内，也可以在不同线程之间。因此，JMM可以通过happens-before关系向程序员提供跨线程的内存可见性。 JSR-133定义了如下happens-before规则： 程序顺序规则：一个线程中的每个操作，happens-before于该线程的任意后续操作。 监视器锁规则：对一个锁的解锁，happens-before于随后对这个锁的加锁。 volatile变量规则：对一个volatile变量的写，happens-before于随后对这个volatile变量的读。 传递性：如果A happens-before于B，B happens-before于C，可以得出A happens-before于C。 start()规则：如果线程A执行操作ThreadB.start()（启动线程B），那么A线程的ThreadB.start()操作happens-before于线程B中的任意操作。 join()规则：如果线程A执行操作ThreadB.join()并成功返回，那么线程B中的任意操作happens-before于线程A从ThreadB.join()操作成功返回。 5、synchronized关键字synchronized关键字可以实现volatile的保证内存可见性以及禁止重排序，同时它还可以保证原子性操作。但是synchronized需要进行加锁操作，效率更低。 6、final关键字final关键字可以用来修饰类、方法、变量。用来修饰变量时可以在对象初始化完成前，不要将此对象的引用写入到其他线程可以访问到的地方（不要让引用在构造函数中逸出）。如果这个条件满足，当其他线程看到这个对象的时候，那个线程始终可以看到正确初始化后的对象的 final 属性。","categories":[{"name":"Java","slug":"Java","permalink":"http://yoursite.com/categories/Java/"}],"tags":[{"name":"并发","slug":"并发","permalink":"http://yoursite.com/tags/并发/"}],"keywords":[{"name":"Java","slug":"Java","permalink":"http://yoursite.com/categories/Java/"}]},{"title":"nginx详解","slug":"nginx","date":"2018-10-06T11:00:44.000Z","updated":"2018-10-24T08:18:22.460Z","comments":true,"path":"其他/nginx/","link":"","permalink":"http://yoursite.com/其他/nginx/","excerpt":"1、概述 nginx是一个跨平台的高性能web服务器。目前我们主要使用nginx用来做反向代理服务器。 为什么选择nginx：1、更快；2、高扩展性；3、高可靠性；4、低内存消耗；5、单机支持10w以上并发连接；6、热部署。","text":"1、概述 nginx是一个跨平台的高性能web服务器。目前我们主要使用nginx用来做反向代理服务器。 为什么选择nginx：1、更快；2、高扩展性；3、高可靠性；4、低内存消耗；5、单机支持10w以上并发连接；6、热部署。 2、安装和启动2.1、编译安装 从nginx官网获取nginx的源码，然后将源码解压到准备好的目录。然后进入安装目录执行三行代码：./configure、make、make install。 configure命令做了大量的“幕后”工作，包括检测操作系统内核和已经安装的软件，参数的解析，中间目录的生成以及根据各种参数生成一些C源码文件、Makefile文件等。 make命令根据configure命令生成的Makefile文件编译Nginx工程，并生成目标文件、最终的二进制文件。 make install命令根据configure执行时的参数将Nginx部署到指定的安装目录，包括相关目录的建立和二进制文件、配置文件的复制。2.2、命令行控制 默认方式启动：./nginx 会使用默认路径下的conf文件。 另指定配置文件启动：./nginx -c /tmp/nginx.conf 使用-c参数可以指定配置文件。 另指定安装目录启动：./nginx -p /usr/local/nginx 使用-p参数指定nginx的安装目录。 测试配置信息的正确性：./nginx -t 使用-t参数测试配置文件是否正确。 在测试阶段不输出非错误信息：./nginx -t -q 测试配置选项时，使用-q参数可以不把error级别以下的信息输出到屏幕。 显示版本信息：./nginx -v 使用-v参数显示Nginx的版本信息。 快速停止服务：./nginx -s stop 可以强制停止服务。nginx程序通过nginx.pid文件得到master进程的进程ID，再向master进程发送TERM信号快速的关闭服务。 优雅停止服务：./nginx -s quit 这个会先关闭端口，停止接受新的连接，然后将当前的任务全部处理完再关闭服务。 运行中重读配置文件并生效：./nginx -s reload 可以使运行中的nginx重新加载配置文件。 3、服务架构3.1、模块化架构 nginx其实就是由很多模块组成，每个模块实现特定的功能。主要分为核心模块、标准http模块、可选http模块、邮件模块以及第三方模块等五大类。3.2、web请求处理机制 实现并行处理请求工作主要有三种方式：多进程方式、多线程方式、异步方式。nginx主要采用的是多进程机制和异步机制，异步机制使用的是异步非阻塞。3.3、事件驱动模型 异步IO的实现机制主要有两种：一是工作进程不停的查询IO是否完成；二是IO调用完成后主动通知工作进程。nginx使用的是第二种，也就是事件驱动模型。 事件收集器–&gt;事件发送器–&gt;事件处理器 常用的事件驱动模型库有：select库、poll库、epoll库。 select库：首先创建读、写、异常三类事件描述符集合，其次调用底层select函数，等待事件发生，然后轮询三个集合中的每一个事件描述符，如果有事件发生就进行处理。 poll库：poll库和select库的基本工作方式是相同的，主要区别在于select库创建了三个集合，而poll库只需要创建一个集合，是select库的优化实现。 epoll库：epoll的实现方式是把描述符列表的管理交给内核负责，一旦有某种事件发生，内核就把事件发生的描述符列表通知给进程，这样避免了轮询整个描述符列表，所以它比select库和poll库更高效。 3.4、设计架构概览 nginx的主要架构是由一个主进程(master process)，多个工作进程(worker process)组成。主进程主要进行nginx配置文件解析、数据结构初始化、模块配置和注册、信号处理、网络监听生成、工作进程生成和管理等工作，工作进程主要进行进程初始化、模块调用和请求处理等工作，是nginx服务器提供服务的主体。 4.配置下面是nginx官网基本配置的一个完整例子，更多的配置可以去官网查询相关文档。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134#用户（组）user www www;#工作进程数worker_processes 2;#进程PID存放路径pid /var/run/nginx.pid;#错误日志存放路径# [ debug | info | notice | warn | error | crit ]error_log /var/log/nginx.error_log info;#events块events &#123; #配置最大连接数 worker_connections 2000; #事件驱动模型选择 # use [kqueue|epoll|/dev/poll|select|poll]; use kqueue;&#125;#http块http &#123; #定义MIME-Type include conf/mime.types; default_type application/octet-stream; #日志格式 log_format main &apos;$remote_addr - $remote_user [$time_local] &apos; &apos;&quot;$request&quot; $status $bytes_sent &apos; &apos;&quot;$http_referer&quot; &quot;$http_user_agent&quot; &apos; &apos;&quot;$gzip_ratio&quot;&apos;; log_format download &apos;$remote_addr - $remote_user [$time_local] &apos; &apos;&quot;$request&quot; $status $bytes_sent &apos; &apos;&quot;$http_referer&quot; &quot;$http_user_agent&quot; &apos; &apos;&quot;$http_range&quot; &quot;$sent_http_content_range&quot;&apos;; client_header_timeout 3m; client_body_timeout 3m; send_timeout 3m; client_header_buffer_size 1k; large_client_header_buffers 4 4k; gzip on; gzip_min_length 1100; gzip_buffers 4 8k; gzip_types text/plain; output_buffers 1 32k; postpone_output 1460; sendfile on; tcp_nopush on; tcp_nodelay on; send_lowat 12000; keepalive_timeout 75 20; #lingering_time 30; #lingering_timeout 10; #reset_timedout_connection on; server &#123; listen one.example.com; server_name one.example.com www.one.example.com; access_log /var/log/nginx.access_log main; location / &#123; proxy_pass http://127.0.0.1/; proxy_redirect off; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; #proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; client_max_body_size 10m; client_body_buffer_size 128k; client_body_temp_path /var/nginx/client_body_temp; proxy_connect_timeout 70; proxy_send_timeout 90; proxy_read_timeout 90; proxy_send_lowat 12000; proxy_buffer_size 4k; proxy_buffers 4 32k; proxy_busy_buffers_size 64k; proxy_temp_file_write_size 64k; proxy_temp_path /var/nginx/proxy_temp; charset koi8-r; &#125; error_page 404 /404.html; location = /404.html &#123; root /spool/www; &#125; location /old_stuff/ &#123; rewrite ^/old_stuff/(.*)$ /new_stuff/$1 permanent; &#125; location /download/ &#123; valid_referers none blocked server_names *.example.com; if ($invalid_referer) &#123; #rewrite ^/ http://www.example.com/; return 403; &#125; #rewrite_log on; # rewrite /download/*/mp3/*.any_ext to /download/*/mp3/*.mp3 rewrite ^/(download/.*)/mp3/(.*)\\..*$ /$1/mp3/$2.mp3 break; root /spool/www; #autoindex on; access_log /var/log/nginx-download.access_log download; &#125; location ~* \\.(jpg|jpeg|gif)$ &#123; root /spool/www; access_log off; expires 30d; &#125; &#125;&#125; 5.反向代理与负载均衡正向代理和反向代理： 简单说，正向代理用来让局域网客户机接入外网以访问外网资源，反向代理用来让外网的客户端接入局域网中的站点以访问站点中的资源。 正向代理 1234567server &#123; resolver 192.168.1.1; #指定DNS服务器IP地址 listen 8080; location / &#123; proxy_pass http://$http_host$request_uri; #设定代理服务器的协议和地址 &#125; &#125; 反向代理 123456789server &#123; listen 80; location /demo &#123; proxy_pass http://127.0.0.1:8081; &#125; location /demo1 &#123; proxy_pass http://127.0.0.1:8082; &#125;&#125; 负载均衡 nginx是一个非常高效的HTTP负载均衡器，将流量分配给多个应用服务器，并通过nginx提高web应用程序的性能、可伸缩性和可靠性。 nginx负载均衡使用的指令主要有upstream和proxy_pass，upstream块定义一个后端集群，proxy_pass用于location块中，表示对于所有符合要求的request交给某个集群处理。 常见的由以下几种实现负载均衡的方式。 轮询（round-robin）：默认方式 12345678910111213http &#123; upstream backend &#123; server srv1.example.com; server srv2.example.com; server srv3.example.com; &#125; server &#123; listen 80; location / &#123; proxy_pass http://backend; &#125; &#125;&#125; 加权轮询（weight-round-robin） 12345upstream backend &#123; server srv1.example.com weight=3; server srv2.example.com weight=2; server srv3.example.com;&#125; 最少连接（least-connected） 123456upstream backend &#123; least_conn; server srv1.example.com; server srv2.example.com; server srv3.example.com;&#125; ip-hash：每个请求按访问ip的hash结果分配，这样每个访客固定访问一个后端服务器，可以解决session的问题。 123456upstream backend &#123; ip_hash; server srv1.example.com; server srv2.example.com; server srv3.example.com;&#125; fair（第三方）: 按后端服务器的响应时间来分配请求，响应时间短的优先分配 123456upstream backend &#123; fair; server srv1.example.com; server srv2.example.com; server srv3.example.com;&#125;","categories":[{"name":"其他","slug":"其他","permalink":"http://yoursite.com/categories/其他/"}],"tags":[{"name":"nginx","slug":"nginx","permalink":"http://yoursite.com/tags/nginx/"}],"keywords":[{"name":"其他","slug":"其他","permalink":"http://yoursite.com/categories/其他/"}]},{"title":"springboot使用mybatis加载typealias的package问题","slug":"springboot2","date":"2018-09-30T10:02:32.000Z","updated":"2018-10-24T08:17:32.929Z","comments":true,"path":"web/springboot2/","link":"","permalink":"http://yoursite.com/web/springboot2/","excerpt":"springboot打成jar包后运行会造成mybatis设置的别名包找不到实体类的问题，这是由于mybatis默认使用DefaultVFS扫描包，在springboot中可以改成SpringBootVFS进行包扫描。具体见下面代码。","text":"springboot打成jar包后运行会造成mybatis设置的别名包找不到实体类的问题，这是由于mybatis默认使用DefaultVFS扫描包，在springboot中可以改成SpringBootVFS进行包扫描。具体见下面代码。 1234567891011@Bean public SqlSessionFactory db1SqlSessionFactory(DataSource dataSource) throws Exception &#123; SqlSessionFactoryBean sqlSessionFactoryBean = new SqlSessionFactoryBean(); sqlSessionFactoryBean.setDataSource(dataSource); //mybatis使用默认DefaultVFS扫描包会有问题，使用SpringBootVFS sqlSessionFactoryBean.setVfs(SpringBootVFS.class); PathMatchingResourcePatternResolver resolver = new PathMatchingResourcePatternResolver(); sqlSessionFactoryBean.setMapperLocations(resolver.getResources(&quot;classpath*:/mybatis/mapper/**.xml&quot;)); sqlSessionFactoryBean.setConfigLocation(new ClassPathResource(&quot;mybatis/mybatis-config.xml&quot;)); return sqlSessionFactoryBean.getObject(); &#125; 如果使用 mybatis autoconfigure生成的 SessionFactory可能就没有这个问题了。","categories":[{"name":"web","slug":"web","permalink":"http://yoursite.com/categories/web/"}],"tags":[{"name":"springboot","slug":"springboot","permalink":"http://yoursite.com/tags/springboot/"}],"keywords":[{"name":"web","slug":"web","permalink":"http://yoursite.com/categories/web/"}]},{"title":"JVM（5）：类加载机制","slug":"jvm5","date":"2018-09-27T09:41:42.000Z","updated":"2018-10-24T08:17:04.862Z","comments":true,"path":"Java/jvm5/","link":"","permalink":"http://yoursite.com/Java/jvm5/","excerpt":"JVM把class文件加载的内存，并对数据进行校验、转换解析和初始化，最终形成JVM可以直接使用的Java类型的过程就是加载机制。 类加载生命周期 加载（Loading） 验证（Verifycation） 准备（Preparation） 解析（Resolution） 初始化（Initialization） 使用（Using） 卸载（Unloading）","text":"JVM把class文件加载的内存，并对数据进行校验、转换解析和初始化，最终形成JVM可以直接使用的Java类型的过程就是加载机制。 类加载生命周期 加载（Loading） 验证（Verifycation） 准备（Preparation） 解析（Resolution） 初始化（Initialization） 使用（Using） 卸载（Unloading） 其中验证、准备、解析这三个阶段统称为连接。加载、验证、准备、初始化、卸载这五个阶段顺序是确定的。 加载在加载阶段，虚拟机需要完成三件事情： 通过一个类的全限定名来获取定义此类的二进制字节流。 将这个字节流所代表的静态存储结构转化为方法区的运行时数据结构。 在内存中生成一个代表这个类的java.lang.class的对象，作为方法区这个类的各种数据的访问入口。 验证验证是连接阶段的第一步，这一阶段的目的是为了确保Class文件字节流中包含的信息符合当前虚拟机的要求，并且不回危害虚拟机的安全。验证阶段一共包含四步：文件格式验证、愿数据验证、字节码验证、符号引用验证。 准备准备阶段是为类变量分配内存并设置初始值的阶段，这些变量所使用的内存都在方法区中。public static int value=123；这个变量在准备阶段会初始化为0而不是123，因为这个时候尚未执行任何java方法，将value赋值为123是在putstatic指令被程序编译之后。public static final int value=123；而这个会在准备阶段之后value就被初始化为123。 解析解析阶段是将常量池中的符号引用替换成直接引用的过程。 初始化初始化阶段是真正开始执行类中定义的java代码。在准备阶段，类变量已经赋值了一次系统要求的初始值，而在初始化阶段，则根据具体实际的值去初始化。 类加载器 Bootstrap ClassLoader Extension ClassLoader Application ClassLoader Custom ClassLoader 双亲委派模型 双亲委派模型要求除了顶层的启动类加载器外，其余的类加载器都应该有自己的父类加载器。这些父子类加载器之间的关系不会以继承来实现，而是使用组合来实现。 双亲委派模型的工作过程是：如果一个类加载器收到了类加载的请求，它首先不会自己去尝试加载这个类，而是把这个请求委派给父类加载器去完成，每一个层次的类加载器都是如此，因此所有的加载请求最终都应该传送到顶层的启动类加载器中，只有当父加载器反馈自己无法完成这个加载请求（它的搜索范围中没有找到所需的类）时，子加载器才会尝试自己去加载。","categories":[{"name":"Java","slug":"Java","permalink":"http://yoursite.com/categories/Java/"}],"tags":[{"name":"JVM虚拟机","slug":"JVM虚拟机","permalink":"http://yoursite.com/tags/JVM虚拟机/"}],"keywords":[{"name":"Java","slug":"Java","permalink":"http://yoursite.com/categories/Java/"}]},{"title":"springboot线程池优雅关闭","slug":"springboot1","date":"2018-09-27T08:46:18.000Z","updated":"2018-10-24T08:17:20.736Z","comments":true,"path":"web/springboot1/","link":"","permalink":"http://yoursite.com/web/springboot1/","excerpt":"在我们停止springboot项目时，我们希望线程池中的任务能够继续执行完再完全停掉服务。一般有两种做法： 线程池配置参数在spring应用中，如果需要停止服务，而线程池没有优雅的关闭，就会造成线程池中的任务被强行停止，导致部分任务执行失败。我们只需要在配置线程池时增加两个参数即可： waitForTasksToCompleteOnShutdown awaitTerminationSeconds","text":"在我们停止springboot项目时，我们希望线程池中的任务能够继续执行完再完全停掉服务。一般有两种做法： 线程池配置参数在spring应用中，如果需要停止服务，而线程池没有优雅的关闭，就会造成线程池中的任务被强行停止，导致部分任务执行失败。我们只需要在配置线程池时增加两个参数即可： waitForTasksToCompleteOnShutdown awaitTerminationSeconds 具体代码如下： 12345678910111213@Beanpublic ThreadPoolTaskExecutor treadPool() &#123; ThreadPoolTaskExecutor executor = new ThreadPoolTaskExecutor(); executor.setCorePoolSize(10); executor.setMaxPoolSize(20); executor.setQueueCapacity(10); executor.setKeepAliveSeconds(60); executor.setWaitForTasksToCompleteOnShutdown(true); executor.setAwaitTerminationSeconds(30); executor.setRejectedExecutionHandler(new ThreadPoolExecutor.CallerRunsPolicy()); executor.initialize(); return executor;&#125; 使用ApplicationListener监听关闭事件12345678910111213141516171819202122232425262728@Componentpublic class MyContextClosedHandler implements ApplicationListener&lt;ContextClosedEvent&gt;&#123; @Autowired private ThreadPoolTaskExecutor executor; @Override public void onApplicationEvent(ContextClosedEvent event) &#123; shutdownAndAwaitTermination(executor.getThreadPoolExecutor()); &#125; private void shutdownAndAwaitTermination(ExecutorService pool) &#123; pool.shutdown(); // Disable new tasks from being submitted try &#123; // Wait a while for existing tasks to terminate if (!pool.awaitTermination(30, TimeUnit.SECONDS)) &#123; pool.shutdownNow(); // Cancel currently executing tasks // Wait a while for tasks to respond to being cancelled if (!pool.awaitTermination(30, TimeUnit.SECONDS)) System.err.println(&quot;Pool did not terminate&quot;); &#125; &#125; catch (InterruptedException ie) &#123; // (Re-)Cancel if current thread also interrupted pool.shutdownNow(); // Preserve interrupt status Thread.currentThread().interrupt(); &#125; &#125;&#125;","categories":[{"name":"web","slug":"web","permalink":"http://yoursite.com/categories/web/"}],"tags":[{"name":"springboot","slug":"springboot","permalink":"http://yoursite.com/tags/springboot/"}],"keywords":[{"name":"web","slug":"web","permalink":"http://yoursite.com/categories/web/"}]},{"title":"JVM（4）：虚拟机性能监控","slug":"jvm4","date":"2018-09-26T07:12:08.000Z","updated":"2018-11-08T09:42:23.032Z","comments":true,"path":"Java/jvm4/","link":"","permalink":"http://yoursite.com/Java/jvm4/","excerpt":"要进行虚拟机性能监控光有理论还不够，还需要实践。JDK为我们提供了一些命令行工具以及图形化洁面工具进行虚拟机性能监控实践。","text":"要进行虚拟机性能监控光有理论还不够，还需要实践。JDK为我们提供了一些命令行工具以及图形化洁面工具进行虚拟机性能监控实践。 命令行工具 jps：虚拟机进程状况工具用于列出正在执行的虚拟机进程。命令格式：jps ［options］［hostid］主要选项：-q 只输出LVMID，省略主类的名称 -l 输出主类的全名，如果执行的是jar包，输出jar的包路径 -m 输出虚拟机进程启动时传给主类main函数的参数 -v 输出虚拟机进程启动时的JVM参数jps可以通过RMI协议查询开启了RMI服务的远程虚拟机进程状态，hostid为RMI注册表中注册的主机名。 jstat：虚拟机统计信息监视工具用于监视虚拟机各种运行状态信息。命令格式： jstat -&lt;option> [-t] [-h &lt;lines>] &lt;vmid> [&lt;interval> [&lt;count>]] jstat -gc 2764 250 20 每250ms查看一次进程ID2764的gc情况，一共查看20次主要选项：-class 监视类装载、卸载、总空间以及所耗费时间 -gc 监视java堆gc状况，包括Eden区、两个Survivor区、、老年代、永久带等的容量、已用空间、GC时间合计等信息 jinfo：Java配置信息工具实时查看和调整虚拟机各项参数。命令格式：jinfo [ option ] vmid jmap：Java 内存映像工具用于生成堆转储快照，一般是headdump文件或者dump文件。命令格式：jmap [ option ] vmid主要选项：-dump 生成Java堆转储快照 -heap 显示Java堆详细信息。 jhat：虚拟机堆转储快照分析工具jhat与jmap搭配使用，来分析jmap生成的堆转储快照。 jstack：Java堆栈跟踪工具用于生成虚拟机当前的线程快照，一般是threaddump文件或者javacore文件。命令格式：jstack [ option ] vmid 图形化工具 JConsole：Java监视与管理控制台 VisualVM：多合一故障处理工具","categories":[{"name":"Java","slug":"Java","permalink":"http://yoursite.com/categories/Java/"}],"tags":[{"name":"JVM虚拟机","slug":"JVM虚拟机","permalink":"http://yoursite.com/tags/JVM虚拟机/"}],"keywords":[{"name":"Java","slug":"Java","permalink":"http://yoursite.com/categories/Java/"}]},{"title":"JVM（3）：垃圾收集GC","slug":"jvm3","date":"2018-09-26T06:09:37.000Z","updated":"2018-10-24T08:16:28.419Z","comments":true,"path":"Java/jvm3/","link":"","permalink":"http://yoursite.com/Java/jvm3/","excerpt":"Java内存结构中程序计数器、虚拟机栈、本地方法栈都是线程私有的，随着方法的结束或者线程的结束，内存会被回收。所以垃圾收集主要针对Java堆和方法区。 判断对象是否可以回收 引用计数法 每个对象有一个引用计数器，每当有一个地方引用，计数器就加1，当引用失效，计数器就减1，计数器为0的对象会被回收。引用计数不能解决循环引用的问题。","text":"Java内存结构中程序计数器、虚拟机栈、本地方法栈都是线程私有的，随着方法的结束或者线程的结束，内存会被回收。所以垃圾收集主要针对Java堆和方法区。 判断对象是否可以回收 引用计数法 每个对象有一个引用计数器，每当有一个地方引用，计数器就加1，当引用失效，计数器就减1，计数器为0的对象会被回收。引用计数不能解决循环引用的问题。 可达性分析法 通过一系列称为“GC ROOTS”的节点作为起点，开始向下搜索，搜素所走的路径称为引用链，当一个对象到GC ROOTS没有任何引用链相连的话，就说明该对象不可用，可以被回收。 可以作为GC ROOTS的对象包含以下几种：虚拟机栈（栈帧中的本地变量表）中引用的对象、方法区中类静态属性引用的对象、方法区中常量引用的对象、本地方法中JNI引用的对象。 四种引用类型： 强引用：指在程序代码之中普遍存在的，类似“Object obj=new Object（）”这类的引用，只要强引用还存在，垃圾收集器永远不会回收掉被引用的对象。 软引用：用来描述一些还有用但是非必需的对象。在系统内存不足时进行垃圾收集会对软引用进行回收。（SoftReference） 弱引用：也是用来描述非必需的对象，但是它的强度比软引用更弱。发生GC时，不管内存是否足够都会对其进行回收。（WeakReference） 虚引用：也称为幽灵引用或者幻影引用，它是最弱的一种引用关系。一个对象是否有虚引用的存在，完全不会对其生存时间构成影响，也无法通过虚引用来取得一个对象实例。为一个对象设置虚引用关联的唯一目的就是能在这个对象被收集器回收时收到一个系统通知。（PhantomReference） 垃圾收集算法 标记清除算法 复制算法 标记整理算法 分代收集算法 算法实现 枚举根结点 在可达性分析过程中为了防止对象的引用关系发生变化，所以在执行GC时需要停顿所有java执行线程（Stop The World）。 由于目前的主流Java虚拟机使用的都是准确式GC，所以当执行系统停顿下来后，并不需要一个不漏地检查完所有执行上下文和全局的引用位置，虚拟机应当是有办法直接得知哪些地方存放着对象引用。在HotSpot的实现中，是使用一组称为OopMap的数据结构来达到这个目的的，在类加载完成的时候，HotSpot就把对象内什么偏移量上是什么类型的数据计算出来，在JIT编译过程中，也会在特定的位置记录下栈和寄存器中哪些位置是引用。这样，GC在扫描时就可以直接得知这些信息了。 安全点 HotSpot并没有为每条指令都生成OopMap，只有在特定的位置记录这个信息，这些位置称为安全点（SaftPoint）。安全点的选定基本上是以程序“是否具有让程序长时间执行的特征”为标准进行选定的。长时间执行的最明显特征就是指令序列复用，例如方法调用、循环跳转、异常跳转等。 GC停顿有两种方案：抢先式中断（基本不用）和主动式中断。主动式中断是当需要中断线程时，设置一个中断标志，各个线程去轮询这个标志，当为真的就中断挂起。 安全区域 程序不执行的时候，也就是没有分配CPU的时候，典型的就是线程sleep或者blocked状态时，这个时候不能响应中断请求。JVM不太可能等到线程重新分配CPU然后走到安全点。这样就需要安全区域解决这个问题。 安全区域是指在一段区域内引用关系不会发生变化，在这中间任何一个地方GC都是安全的。我们可以把Safe Region看成是扩展的safe point。 垃圾收集器 Serial收集器：单线程收集器，client模式下默认的新生代收集器。 ParNew收集器：Serial收集器的多线程版本。server模式首选的新生代收集器。 Parallel Scavenge收集器：并行的多线程垃圾收集器，目标是达到一个可控制的吞吐量。提供了两个参数用于精确控制吞吐量，分别是控制最大垃圾收集停顿时间的-XX：MaxGCPauseMillis参数以及直接设置吞吐量大小的-XX：GCTimeRatio参数。无法与CMS配合。 Serial Old收集器 ：Serial收集器的老年代版本，client模式下默认的老年代收集器。 Parallel Old收集器：Parallel Scavenge收集器的老年代版本。 CMS收集器：基于标记清除算法。目标是降低GC停顿时间，一共有四个步骤：初始标记、并发标记、重新标记、并发清除。这之中最耗时的并发标记和并发清除可以和用户线程一起运行，所以可以看成是并行的垃圾收集器。三个缺点：对CPU资源敏感、无法处理浮动垃圾、标记清除算法会产生内存碎片。 G1收集器：特点：并行与并发、分代收集、可预测的停顿。使用G1收集器时，Java堆的内存布局就与其他收集器有很大差别，它将整个Java堆划分为多个大小相等的独立区域（Region），虽然还保留有新生代和老年代的概念，但新生代和老年代不再是物理隔离的了，它们都是一部分Region（不需要连续）的集合。G1跟踪各个Region里面的垃圾堆积的价值大小，在后台维护一个优先列表，每次根据允许的收集时间，优先回收价值最大的Region。四个步骤：初始标记、并发标记、最终标记、筛选回收。 内存分配回收策略 对象优先在Eden区分配 大对象直接进入老年代 长期存活对象进入老年代 动态对象年龄判定 空间分配担保","categories":[{"name":"Java","slug":"Java","permalink":"http://yoursite.com/categories/Java/"}],"tags":[{"name":"JVM虚拟机","slug":"JVM虚拟机","permalink":"http://yoursite.com/tags/JVM虚拟机/"}],"keywords":[{"name":"Java","slug":"Java","permalink":"http://yoursite.com/categories/Java/"}]},{"title":"JVM（2）：虚拟机对象探秘","slug":"jvm2","date":"2018-09-25T06:00:36.000Z","updated":"2018-10-24T08:16:09.627Z","comments":true,"path":"Java/jvm2/","link":"","permalink":"http://yoursite.com/Java/jvm2/","excerpt":"对象的创建对象的创建一般有四种方式：new关键字、反射、clone、序列化。对象创建主要分三步： 检查类是否加载 虚拟机遇到一条new指令时，首先将去检查这个指令的参数是否能在常量池中定位到一个类的符号引用，并且检查这个符号引用代表的类是否已被加载、解析和初始化过。如果没有，那必须先执行相应的类加载过程。","text":"对象的创建对象的创建一般有四种方式：new关键字、反射、clone、序列化。对象创建主要分三步： 检查类是否加载 虚拟机遇到一条new指令时，首先将去检查这个指令的参数是否能在常量池中定位到一个类的符号引用，并且检查这个符号引用代表的类是否已被加载、解析和初始化过。如果没有，那必须先执行相应的类加载过程。 分配内存 主要有指针碰撞和空闲列表两种方式。指针碰撞是把内存指针向空闲空间移动与对象大小相等的距离来分配内存，这种主要适用于带有整理的垃圾收集器。空闲列表是维护一个列表记录哪些内存区域可以使用，在分配的时候从列表中找出一块分配，这种适用于不带整理功能的垃圾收集器。 分配过程中还要考虑多个线程同时分配内存出现并发的问题。这个一般有两种方案：一是使用CAS机制保证更新操作的原子性；二是使用本地线程分配缓冲（TLAB）。 对象设置 分配完内存之后需要进行对象设置，主要是把这个对象是哪个类的实例、对象的哈希码、对象的GC分代年龄、对象的锁信息等存放在对象的对象头里。 对象的内存布局 对象在内存中存储的布局可以分为3块区域：对象头（Header）、实例数据（Instance Data）和对齐填充（Padding）。 对象头分成两部分：第一部分用于存储对象自身的运行时数据，如对象的哈希码、GC分代年龄、锁状态标志等，官方称之为‘MarkWord’。另外一部分是类型指针，即对象指向它的类元数据的指针，虚拟机通过这个指针来确定这个对象是哪个类的实例。 实例数据部分是对象真正存储的有效信息，也是在程序代码中所定义的各种类型的字段内容。无论是从父类继承下来的，还是在子类中定义的，都需要记录起来。 第三部分对象填充不是必须的，仅仅是占位的作用，用来保证对象的大小是８字节的整数倍。 对象的访问定位对象的访问主要两种方式： 句柄访问 Java堆中会划出一块内存作为句柄池，reference中存储的就是对象的句柄地址，而句柄中包含了对象实例数据和类型数据各自的具体地址信息。好处是对象移动时只用改动句柄中的实例数据地址，不用改变reference。 直接指针访问 reference中存储的就是对象的地址。好处就是访问快，节省了一次指针定位的开销。hotspot使用直接指针访问。","categories":[{"name":"Java","slug":"Java","permalink":"http://yoursite.com/categories/Java/"}],"tags":[{"name":"JVM虚拟机","slug":"JVM虚拟机","permalink":"http://yoursite.com/tags/JVM虚拟机/"}],"keywords":[{"name":"Java","slug":"Java","permalink":"http://yoursite.com/categories/Java/"}]},{"title":"JVM（1）：内存结构","slug":"jvm1","date":"2018-09-25T03:38:43.000Z","updated":"2018-10-24T08:15:03.063Z","comments":true,"path":"Java/jvm1/","link":"","permalink":"http://yoursite.com/Java/jvm1/","excerpt":"程序计数器 程序计数器是内存结构中很小的一块，属于线程私有的。字节码解释器工作时就是通过改变这个计数器的值来选取下一条需要执行的指令，分支、循环、跳转、异常处理、线程恢复都要依赖这个计数器来实现。程序计数器是内存结构中唯一一个没有定义OOM的区域。","text":"程序计数器 程序计数器是内存结构中很小的一块，属于线程私有的。字节码解释器工作时就是通过改变这个计数器的值来选取下一条需要执行的指令，分支、循环、跳转、异常处理、线程恢复都要依赖这个计数器来实现。程序计数器是内存结构中唯一一个没有定义OOM的区域。 虚拟机栈 虚拟机栈也是线程私有的，主要用于存储局部变量表、操作数栈、动态链接、方法出口等信息。每一个方法的调用对应着一个栈帧在虚拟机中的入栈出栈过程。 虚拟机栈中定义了StackOverflowError和OutOfMemeryError。当线程请求的栈深度大于虚拟机允许的最大深度，就会抛出SOF异常。如果虚拟机栈可以动态扩展，扩展时无法申请足够的内存，就会抛出OOM异常。 本地方法栈 本地方法栈和虚拟机栈一样，只不过本地方法栈是为native方法服务的。hotspot虚拟机把本地方法栈和虚拟机栈合二为一了。 JAVA堆 Java堆时内存结构中最大的一块区域，它是线程共享的，主要用于存储对象的实例。Java堆可以细分为年轻代和老年代，年轻代又可以分成Eden区，From Survivor区和To Survivor区。Java堆是垃圾收集器管理的主要区域，现在的收集器基本都采用分代收集的策略。当内存不足时，Java堆中也会出现OOM异常。 方法区 方法区也是线程共享的，主要用于存储被加载的类信息、常量、静态变量、即时编译器编译后的代码等数据。方法区中也会出现OOM异常。 直接内存 直接内存并不是虚拟机内存结构中的一块，但是这部分内存也被频繁使用，也会导致ＯＯＭ异常。JDK1.4中引入的NIO就使用了直接内存。","categories":[{"name":"Java","slug":"Java","permalink":"http://yoursite.com/categories/Java/"}],"tags":[{"name":"JVM虚拟机","slug":"JVM虚拟机","permalink":"http://yoursite.com/tags/JVM虚拟机/"}],"keywords":[{"name":"Java","slug":"Java","permalink":"http://yoursite.com/categories/Java/"}]},{"title":"Java代码优化","slug":"code-optimization","date":"2018-08-22T09:17:31.000Z","updated":"2018-10-24T08:18:30.450Z","comments":true,"path":"Java/code-optimization/","link":"","permalink":"http://yoursite.com/Java/code-optimization/","excerpt":"代码优化目标：减少代码体积，提高代码的运行效率","text":"代码优化目标：减少代码体积，提高代码的运行效率 代码优化具体细节 尽量指定类、方法的final修饰符：如果一个类是final的，则它的所有方法也是final的，java编译器会寻找机会内内联的所有final方法，可以提高50%的性能。 尽量重用对象：特别是String对象。Java虚拟机创建对象需要花费时间和空间，后期还要进行垃圾回收。 尽可能使用局部变量：局部变量存储于栈中，速度较快，而且随着方法的结束会消失。 及时关闭流和连接等：对于IO流以及数据库连接、线程池连接，在finally 中一定要将其关闭。 尽量使用懒加载策略：在使用时创建（单例模式最好使用懒汉模式）。 不要在循环中使用try…catch…：在循环外使用。 乘法和除法使用移位操作：&gt;&gt;1表示除以2，&lt;&lt;1表示乘以2。 当有大量数据复制时，使用System.arrayCopy()命令。 循环内不要不断的创建对象。","categories":[{"name":"Java","slug":"Java","permalink":"http://yoursite.com/categories/Java/"}],"tags":[{"name":"java基础","slug":"java基础","permalink":"http://yoursite.com/tags/java基础/"}],"keywords":[{"name":"Java","slug":"Java","permalink":"http://yoursite.com/categories/Java/"}]},{"title":"关于","slug":"about","date":"2018-05-17T09:03:49.000Z","updated":"2018-05-17T09:05:37.000Z","comments":true,"path":"uncategorized/about/","link":"","permalink":"http://yoursite.com/uncategorized/about/","excerpt":"","text":"不善言辞的宅男码农一枚","categories":[],"tags":[],"keywords":[]}]}