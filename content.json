{"meta":{"title":"Xiao's Blog","subtitle":"生命太短暂，不要去做一些根本没有人想要的东西。","description":"当你选择了一种语言，意味着你还选择了一组技术、一个社区","author":"任重道远","url":"http://yoursite.com"},"pages":[{"title":"关于","date":"2018-05-17T09:03:49.000Z","updated":"2019-12-23T03:05:01.450Z","comments":true,"path":"about/index.html","permalink":"http://yoursite.com/about/index.html","excerpt":"","text":"不善言辞的宅男码农一枚"},{"title":"分类","date":"2018-10-24T07:17:04.000Z","updated":"2018-10-24T07:18:21.919Z","comments":true,"path":"categories/index.html","permalink":"http://yoursite.com/categories/index.html","excerpt":"","text":""},{"title":"标签","date":"2018-10-24T07:20:20.000Z","updated":"2018-10-24T07:23:31.193Z","comments":true,"path":"tags/index.html","permalink":"http://yoursite.com/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"Mysql explain 详解","slug":"explain","date":"2020-01-03T10:02:33.000Z","updated":"2020-01-06T08:40:50.318Z","comments":true,"path":"Mysql/explain.html","link":"","permalink":"http://yoursite.com/Mysql/explain.html","excerpt":"","text":"explain可以提供Mysql执行语句的信息，根据这些信息，我们可以对执行语句进行优化，比如调整索引和连接顺序。explain可以用于select，insert，update，delete，replace语句。 explain输出项1. id列","categories":[{"name":"Mysql","slug":"Mysql","permalink":"http://yoursite.com/categories/Mysql/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"http://yoursite.com/tags/mysql/"}],"keywords":[{"name":"Mysql","slug":"Mysql","permalink":"http://yoursite.com/categories/Mysql/"}]},{"title":"Rocketmq源码解析-2.Namesrv","slug":"rocketmq-namesrv","date":"2019-12-19T12:10:25.000Z","updated":"2019-12-20T09:42:43.188Z","comments":true,"path":"middleware/rocketmq-namesrv.html","link":"","permalink":"http://yoursite.com/middleware/rocketmq-namesrv.html","excerpt":"Namesrv简介Namesrv可以理解为一个注册中心，类似于kafka的zookeeper，但是比zk更加轻量，主要包含两块功能： 管理一些KV配置信息。 管理broker和topic的注册信息。","text":"Namesrv简介Namesrv可以理解为一个注册中心，类似于kafka的zookeeper，但是比zk更加轻量，主要包含两块功能： 管理一些KV配置信息。 管理broker和topic的注册信息。 Namesrv启动过程 启动过程主要涉及NamesrvStartup和NamesrvController两个类。 执行sh mqnamesrv命令会启动NamesrvStartup类中的main方法，首先会执行createNamesrvController方法，解析命令行中的参数到各种config对象中（主要是NettyServerConfig和NamesrvConfig）。然后会使用这两个config对象创建NamesrvController实例对象。接下来执行NamesrvController 对象的initialize()、start()方法，并且配置ShutdownHook。initialize()方法中会依次执行加载所有kv配置、创建NettyServer、创建processor线程池、注册processor、使用scheduledExecutorService启动各种scheduled task（包括broker的心跳检测）。start()方法会执行启动NettyServer。 不仅Namesrv的启动过程是这样，其他的组件启动过程也是startup/config/controller这样一个流程。 Namesrv主要组件 KVConfigManager 定义一个HashMap configTable存储配置信息。键为namespace，值为真正存储kv信息的map，这样就可以将同样namespace的配置放入同一个map。 12private final HashMap&lt;String/* Namespace */, HashMap&lt;String/* Key */, String/* Value */&gt;&gt; configTable = new HashMap&lt;String, HashMap&lt;String, String&gt;&gt;(); 使用读写锁控制配置信息的加载和读取。 1private final ReadWriteLock lock = new ReentrantReadWriteLock(); KVConfigManager类中load()方法用于启动namesrv时通过configpath读取配置文件，再将配置存入map，另外还提供添加，删除，获取配置方法用于后续操作 RouteInfoManager 定义五个map分别存储topic、broker、cluster、brokerliveinfo、filter信息。 123456private final ReadWriteLock lock = new ReentrantReadWriteLock();private final HashMap&lt;String/* topic */, List&lt;QueueData&gt;&gt; topicQueueTable;private final HashMap&lt;String/* brokerName */, BrokerData&gt; brokerAddrTable;private final HashMap&lt;String/* clusterName */, Set&lt;String/* brokerName */&gt;&gt; clusterAddrTable;private final HashMap&lt;String/* brokerAddr */, BrokerLiveInfo&gt; brokerLiveTable;private final HashMap&lt;String/* brokerAddr */, List&lt;String&gt;/* Filter Server */&gt; filterServerTable; DefaultRequestProcessor namesrv启动时会注册processor 1234567private void registerProcessor() &#123; if (namesrvConfig.isClusterTest()) &#123; this.remotingServer.registerDefaultProcessor(new ClusterTestRequestProcessor(this, namesrvConfig.getProductEnvName()), this.remotingExecutor); &#125; else &#123; this.remotingServer.registerDefaultProcessor(new DefaultRequestProcessor(this), this.remotingExecutor); &#125; &#125; 当namesrv有请求过来时，会使用DefaultRequestProcessor去处理请求，处理过程会在线程池this.remotingExecutor中执行，通过processRequest方法处理请求，根据request中不同code进行不同处理。 123456789101112131415161718192021222324252627282930313233343536373839404142switch (request.getCode()) &#123; case RequestCode.PUT_KV_CONFIG: return this.putKVConfig(ctx, request); case RequestCode.GET_KV_CONFIG: return this.getKVConfig(ctx, request); case RequestCode.DELETE_KV_CONFIG: return this.deleteKVConfig(ctx, request); case RequestCode.REGISTER_BROKER: Version brokerVersion = MQVersion.value2Version(request.getVersion()); if (brokerVersion.ordinal() &gt;= MQVersion.Version.V3_0_11.ordinal()) &#123; return this.registerBrokerWithFilterServer(ctx, request); &#125; else &#123; return this.registerBroker(ctx, request); &#125; case RequestCode.UNREGISTER_BROKER: return this.unregisterBroker(ctx, request); case RequestCode.GET_ROUTEINTO_BY_TOPIC: return this.getRouteInfoByTopic(ctx, request); case RequestCode.GET_BROKER_CLUSTER_INFO: return this.getBrokerClusterInfo(ctx, request); case RequestCode.WIPE_WRITE_PERM_OF_BROKER: return this.wipeWritePermOfBroker(ctx, request); case RequestCode.GET_ALL_TOPIC_LIST_FROM_NAMESERVER: return getAllTopicListFromNameserver(ctx, request); case RequestCode.DELETE_TOPIC_IN_NAMESRV: return deleteTopicInNamesrv(ctx, request); case RequestCode.GET_KVLIST_BY_NAMESPACE: return this.getKVListByNamespace(ctx, request); case RequestCode.GET_TOPICS_BY_CLUSTER: return this.getTopicsByCluster(ctx, request); case RequestCode.GET_SYSTEM_TOPIC_LIST_FROM_NS: return this.getSystemTopicListFromNs(ctx, request); case RequestCode.GET_UNIT_TOPIC_LIST: return this.getUnitTopicList(ctx, request); case RequestCode.GET_HAS_UNIT_SUB_TOPIC_LIST: return this.getHasUnitSubTopicList(ctx, request); case RequestCode.GET_HAS_UNIT_SUB_UNUNIT_TOPIC_LIST: return this.getHasUnitSubUnUnitTopicList(ctx, request); default: break; &#125; 其他 namesrv是无状态的，可以任意水平扩展，每一个broker都与所有namesrv保持长链接(有个scheduled task会按一定频率给所有namesrv做register broker的操作)，所以namesrv之间没有主从关系，他们之间也不需要复制数据。client(producer/consumer)会随机选择一个namesrv进行连接。 client和broker中的namesrv地址有以下四种获取方式： 通过命令行或者配置文件设置namesrv地址。 在启动之前通过指定java选项rocketmq.namesrv.addr。 设置NAMESRV_ADDR环境变量，brokers和clients会去读取这个环境变量。 通过一个定时任务每两分钟去一个web服务中获取并更新namesrvaddr的列表。","categories":[{"name":"middleware","slug":"middleware","permalink":"http://yoursite.com/categories/middleware/"}],"tags":[{"name":"rocketmq","slug":"rocketmq","permalink":"http://yoursite.com/tags/rocketmq/"}],"keywords":[{"name":"middleware","slug":"middleware","permalink":"http://yoursite.com/categories/middleware/"}]},{"title":"Rocketmq源码解析-1.Rocketmq介绍","slug":"rocketmq-structure","date":"2019-12-18T12:16:13.000Z","updated":"2019-12-19T09:19:57.412Z","comments":true,"path":"middleware/rocketmq-structure.html","link":"","permalink":"http://yoursite.com/middleware/rocketmq-structure.html","excerpt":"Rocketmq优势： rocketmq原生就支持分布式，而activemq原生存在单点性。 rocketmq可以严格的保证消息的顺序，而activemq不能保证。 rocketmq可以提供亿级消息的堆积能力，不过这不是重点，重点是堆积了亿级消息还能保持低延迟写入。","text":"Rocketmq优势： rocketmq原生就支持分布式，而activemq原生存在单点性。 rocketmq可以严格的保证消息的顺序，而activemq不能保证。 rocketmq可以提供亿级消息的堆积能力，不过这不是重点，重点是堆积了亿级消息还能保持低延迟写入。 丰富的消息推拉模式（push和pull）：push好理解，在消费者端设置消息listener回调；pull需要应用主动的调用拉消息的方法从broker拉取消息，这里存在一个记录消费位置的问题，如果不记录会存在重复消费的问题。 一般mq分布式协调使用zookeeper，rocketmq自己实现了一个nameserver，更加轻量级，性能更好。 消息失败重试机制、高效的订阅者水平扩展能力、强大的api、事务机制等等。 rocketmq有group的概念，通过group机制可以实现天然的消息负载均衡。 Rocketmq部署模式： 单master模式：无需多言，一旦单个broker重启或宕机，一切都结束了！显然，线上不可以使用。 多master模式：全是master，没有slave。一个broker宕机了，应用没有影响，缺点在于宕机的master上未被消费的消息在master没有恢复之前不可以订阅。 多master多slave模式（异步复制）：高可用，采用异步复制的方式，主备之间短暂延迟，ms级别。master宕机，消费者可以从slave上消费，但是master的宕机会导致丢失掉极少量的消息。 多master多slave模式（同步双写）：和上面的区别在于采用的是同步方式，也就是master、slave都写成功才会向应用返回成功。可见不论是数据，还是服务都没有单点，都非常可靠！缺点在于同步的性能比异步稍低。 Rocketmq项目结构： acl：访问权限控制模块 broker：消息代理模块，串联 Producer/Consumer 和 Store client：客户端模块，包含producer和consumer，负责消息的发送和消费 common：公共模块，供其他模块使用 distribution：包含一些 sh 脚本和 配置，主要供部署时使用 example：一些rocketmq使用的示例代码 filter：过滤器模块 logappender：接入日志需要的appender模块 logging：日志模块 namesrv：rocketmq的注册中心，broker，produce，consumer以及topic信息会在namesrv中注册 openmessaging：忽略，没了解过 remoting：远程调用模块，基于Netty实现，produer，consumer，broker之间通过这个模块通信。 srvutil：解析命令行的工具类ServerUtil store：消息存储模块 test：测试用例模块 tools：一些工具类，基于它们可以写一些 sh 工具来管理、查看MQ系统的一些信息 对于这些模块我们不需要都去研究源码，只需要挑几个重点去关注。这里面比较重要的是broker，client，common，namesrv，remoting，store这几个模块。 Rocketmq逻辑部署架构 这是 Rocketmq 的逻辑部署结构(参考《RocketMQ原理简介 v3.1.1》)，包括 producer/broker/namesrv/consumer 四大部分。namesrv 起到注册中心的作用，部署的时候会用到 rocketmq-namesrv/rocketmq-common/rocketmq-remoting 三个模块的代码；broker 部署的时候会用到 rocketmq-broker/rocketmq-store/rocketmq-common/rocketmq-remoting 四个模块的代码；producer 和 consumer 会用到 rocketmq-client/rocketmq-common/rocketmq-remoting 三个模块的代码，这里虽然将它们分开画了，但实际上一个应用往往既是producer又是consumer。","categories":[{"name":"middleware","slug":"middleware","permalink":"http://yoursite.com/categories/middleware/"}],"tags":[{"name":"rocketmq","slug":"rocketmq","permalink":"http://yoursite.com/tags/rocketmq/"}],"keywords":[{"name":"middleware","slug":"middleware","permalink":"http://yoursite.com/categories/middleware/"}]},{"title":"Rocketmq安装部署","slug":"rocketmq-install","date":"2019-12-17T11:34:20.000Z","updated":"2019-12-20T10:47:49.148Z","comments":true,"path":"middleware/rocketmq-install.html","link":"","permalink":"http://yoursite.com/middleware/rocketmq-install.html","excerpt":"获取源码,打包编译 从github下载源码，git clone https://github.com/apache/rocketmq.git 编译源码，进入到主目录，然后执行命令： mvn -Prelease-all -DskipTests clean install -U 编译完之后我们只需要下图红框之内的目录进行部署。","text":"获取源码,打包编译 从github下载源码，git clone https://github.com/apache/rocketmq.git 编译源码，进入到主目录，然后执行命令： mvn -Prelease-all -DskipTests clean install -U 编译完之后我们只需要下图红框之内的目录进行部署。 上图中bin目录是存放部署启动的脚本，conf目录存放的是配置文件，lib目录是打包好之后的所有jar包。 启动Namesrv首先设置好系统JAVA_HOME变量（必须使用64位JDK），然后在主目录下执行nohup sh bin/mqnamesrv &amp;，启动成功之后可以查看到进程，端口默认是9876。(启动默认指定的堆内存是4G，我们自己测试时可以通过修改runserver.sh文件中参数适当改小) 启动broker&nbsp;&nbsp;&nbsp;broker集群主要有四种配置方式：单master，多master，多master多slave同步双写，多master多slave异步复制。（现在好像多了一种dledger的方式，暂时还没研究，不太明白）。&nbsp;&nbsp;&nbsp;Master和Slave的配置文件参考conf目录下的配置文件。Master与Slave通过指定相同的brokerName参数来配对，Master的BrokerId必须是0，Slave的BrokerId必须是大于0的数。&nbsp;&nbsp;&nbsp;启动命令：nohup sh bin/mqbroker -n localhost:9876 -c conf/2m-2s-async/broker-a.properties &amp; 其他 查看日志namesrv和broker的日志默认存在下面所示目录中：tail -f ~/logs/rocketmqlogs/namesrv.logtail -f ~/logs/rocketmqlogs/broker.log 关闭服务器分别关闭broker和namesrv:sh bin/mqshutdown brokersh bin/mqshutdown namesrv 其他命令查看集群情况： ./bin/mqadmin clusterList -n localhost:9876查看broker状态： ./bin/mqadmin brokerStatus -n localhost:9876 -b localhost:10911查看topic列表： ./bin/mqadmin topicList -n localhost9876查看topic状态： ./bin/mqadmin topicStatus -n localhost:9876 -t MyTopic (换成想查询的 topic)查看topic路由： ./bin/mqadmin topicRoute -n localhost:9876 -t MyTopic Rocketmq-Console安装 使用git命令下载项目源码，由于我们仅需要rocketmq-console，故下载此项目对应分支即可。git clone -b release-rocketmq-console-1.0.0 https://github.com/apache/rocketmq-externals.git 进入项目文件夹并修改配置文件 cd rocketmq-externals/rocketmq-console/ vi src/main/resources/application.properties (可以修改rocketmq.config.namesrvAddr，当然也可以后面启动时通过参数指定) 执行maven命令打成jar包：mvn clean package -Dmaven.test.skip=true 启动： java -jar -n localhost:9876 rocketmq-console-ng-1.0.0.jar &amp; 浏览器访问http://localhost:8080就可以查看管理界面。","categories":[{"name":"middleware","slug":"middleware","permalink":"http://yoursite.com/categories/middleware/"}],"tags":[{"name":"rocketmq","slug":"rocketmq","permalink":"http://yoursite.com/tags/rocketmq/"}],"keywords":[{"name":"middleware","slug":"middleware","permalink":"http://yoursite.com/categories/middleware/"}]},{"title":"Java锁介绍","slug":"lock","date":"2019-11-07T14:38:14.000Z","updated":"2020-01-15T03:25:09.421Z","comments":true,"path":"Java/lock.html","link":"","permalink":"http://yoursite.com/Java/lock.html","excerpt":"&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;锁是用来控制多个线程访问共享资源的方式，一般来说，一个锁能够防止多个线程同时访问共享资源（但是有些锁可以允许多个线程并发的访问共享资源，比如读写锁）。在Lock接口出现之前，Java程序是靠synchronized关键字实现锁功能的，而Java SE 5之后，并发包中新增了Lock接口（以及相关实现类）用来实现锁功能，它提供了与synchronized关键字类似的同步功能，只是在使用时需要显式地获取和释放锁。虽然它缺少了（通过synchronized块或者方法所提供的）隐式获取释放锁的便捷性，但是却拥有了锁获取与释放的可操作性、可中断的获取锁以及超时获取锁等多种synchronized关键字所不具备的同步特性。","text":"&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;锁是用来控制多个线程访问共享资源的方式，一般来说，一个锁能够防止多个线程同时访问共享资源（但是有些锁可以允许多个线程并发的访问共享资源，比如读写锁）。在Lock接口出现之前，Java程序是靠synchronized关键字实现锁功能的，而Java SE 5之后，并发包中新增了Lock接口（以及相关实现类）用来实现锁功能，它提供了与synchronized关键字类似的同步功能，只是在使用时需要显式地获取和释放锁。虽然它缺少了（通过synchronized块或者方法所提供的）隐式获取释放锁的便捷性，但是却拥有了锁获取与释放的可操作性、可中断的获取锁以及超时获取锁等多种synchronized关键字所不具备的同步特性。 synchronized锁&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;JVM基于进入和退出Monitor对象来实现方法同步和代码块同步。代码块同步是使用monitorenter和monitorexit指令实现的，monitorenter指令是在编译后插入到同步代码块的开始位置，而monitorexit是插入到方法结束处和异常处。任何对象都有一个monitor与之关联，当且一个monitor被持有后，它将处于锁定状态。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;根据虚拟机规范的要求，在执行monitorenter指令时，首先要去尝试获取对象的锁，如果这个对象没被锁定，或者当前线程已经拥有了那个对象的锁，把锁的计数器加1；相应地，在执行monitorexit指令时会将锁计数器减1，当计数器被减到0时，锁就释放了。如果获取对象锁失败了，那当前线程就要阻塞等待，直到对象锁被另一个线程释放为止。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;synchronized与java.util.concurrent包中的ReentrantLock相比，由于JDK1.6中加入了针对锁的优化措施（见后面），使得synchronized与ReentrantLock的性能基本持平。ReentrantLock只是提供了synchronized更丰富的功能，而不一定有更优的性能，所以在synchronized能实现需求的情况下，优先考虑使用synchronized来进行同步 Java对象头&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;synchronized用的锁是存在Java对象头里的。如果对象是数组类型，则虚拟机用3个字宽（Word）存储对象头，如果对象是非数组类型，则用2字宽存储对象头。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Java对象头里的Mark Word里默认存储对象的HashCode、分代年龄和锁标记位。在运行期间，Mark Word里存储的数据会随着锁标志位的变化而变化。Mark Word可能变化为存储以下4种数据，如下所示 锁优化&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Java SE 1.6为了减少获得锁和释放锁带来的性能消耗，引入了“偏向锁”和“轻量级锁”：锁一共有4种状态，级别从低到高依次是：无锁状态、偏向锁状态、轻量级锁状态和重量级锁状态。锁可以升级但不能降级。 无锁&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;无锁没有对资源进行锁定，所有的线程都能访问并修改同一个资源，但同时只有一个线程能修改成功。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;无锁的特点就是修改操作在循环内进行，线程会不断的尝试修改共享资源。如果没有冲突就修改成功并退出，否则就会继续循环尝试。如果有多个线程修改同一个值，必定会有一个线程能修改成功，而其他修改失败的线程会不断重试直到修改成功。上面我们介绍的CAS原理及应用即是无锁的实现。无锁无法全面代替有锁，但无锁在某些场合下的性能是非常高的。 偏向锁&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;大多数情况下，锁不仅不存在多线程竞争，而且总是由同一线程多次获得，为了让线程获得锁的代价更低而引入了偏向锁。当一个线程访问同步块并获取锁时，会在对象头和栈帧中的锁记录里存储锁偏向的线程ID，以后该线程在进入和退出同步块时不需要进行CAS操作来加锁和解锁，只需简单地测试一下对象头的Mark Word里是否存储着指向当前线程的偏向锁。如果测试成功，表示线程已经获得了锁。如果测试失败，则需要再测试一下Mark Word中偏向锁的标识是否设置成1（表示当前是偏向锁）：如果没有设置，则使用CAS竞争锁；如果设置了，则尝试使用CAS将对象头的偏向锁指向当前线程。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;偏向锁使用了一种等到竞争出现才释放锁的机制，所以当其他线程尝试竞争偏向锁时，持有偏向锁的线程才会释放锁。偏向锁的撤销，需要等待全局安全点。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;偏向锁在Java 6和Java 7里是默认启用的，但是它在应用程序启动几秒钟之后才激活，如有必要可以使用JVM参数来关闭延迟：-XX:BiasedLockingStartupDelay=0。如果你确定应用程序里所有的锁通常情况下处于竞争状态，可以通过JVM参数关闭偏向锁：-XX:-UseBiasedLocking=false，那么程序默认会进入轻量级锁状态。 轻量级锁&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;当锁是偏向锁的时候，被另外的线程所访问，偏向锁就会升级为轻量级锁，其他线程会通过自旋的形式尝试获取锁，不会阻塞，从而提高性能。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;线程在执行同步块之前，JVM会先在当前线程的栈桢中创建用于存储锁记录的空间，并将对象头中的Mark Word复制到锁记录中，官方称为Displaced Mark Word。然后线程尝试使用CAS将对象头中的Mark Word替换为指向锁记录的指针。如果成功，当前线程获得锁，如果失败，表示其他线程竞争锁，当前线程便尝试使用自旋来获取锁。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;轻量级解锁时，会使用原子的CAS操作将Displaced Mark Word替换回到对象头，如果成功，则表示没有竞争发生。如果失败，表示当前锁存在竞争，锁就会膨胀成重量级锁。下图是两个线程同时争夺锁，导致锁膨胀的流程图。 重量级锁&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;升级为重量级锁时，锁标志的状态值变为“10”，此时Mark Word中存储的是指向重量级锁的指针，此时等待锁的线程都会进入阻塞状态。 综上，偏向锁通过对比Mark Word解决加锁问题，避免执行CAS操作。而轻量级锁是通过用CAS操作和自旋来解决加锁问题，避免线程阻塞和唤醒而影响性能。重量级锁是将除了拥有锁的线程以外的线程都阻塞。 其他锁优化（锁消除和锁粗化） 锁消除&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;锁消除即删除不必要的加锁操作。虚拟机即时编辑器在运行时，对一些“代码上要求同步，但是被检测到不可能存在共享数据竞争”的锁进行消除。根据代码逃逸技术，如果判断到一段代码中，堆上的数据不会逃逸出当前线程，那么可以认为这段代码是线程安全的，不必要加锁。 看下面这段程序： 1234567891011121314public class SynchronizedTest &#123; public static void main(String[] args) &#123; SynchronizedTest test = new SynchronizedTest(); for (int i = 0; i &lt; 100000000; i++) &#123; test.append(&quot;abc&quot;, &quot;def&quot;); &#125; &#125; public void append(String str1, String str2) &#123; StringBuffer sb = new StringBuffer(); sb.append(str1).append(str2); &#125;&#125; 虽然StringBuffer的append是一个同步方法，但是这段程序中的StringBuffer属于一个局部变量，并且不会从该方法中逃逸出去（即StringBuffer sb的引用没有传递到该方法外，不可能被其他线程拿到该引用），所以其实这过程是线程安全的，可以将锁消除。 锁粗化&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;如果一系列的连续操作都对同一个对象反复加锁和解锁，甚至加锁操作是出现在循环体中的，那即使没有出现线程竞争，频繁地进行互斥同步操作也会导致不必要的性能损耗。如果虚拟机检测到有一串零碎的操作都是对同一对象的加锁，将会把加锁同步的范围扩展（粗化）到整个操作序列的外部。 举个例子： 123456789public class StringBufferTest &#123; StringBuffer stringBuffer = new StringBuffer(); public void append()&#123; stringBuffer.append(&quot;a&quot;); stringBuffer.append(&quot;b&quot;); stringBuffer.append(&quot;c&quot;); &#125;&#125; 这里每次调用stringBuffer.append方法都需要加锁和解锁，如果虚拟机检测到有一系列连串的对同一个对象加锁和解锁操作，就会将其合并成一次范围更大的加锁和解锁操作，即在第一次append方法时进行加锁，最后一次append方法结束后进行解锁。 自旋锁与自适应自旋锁 引入自旋锁的原因：互斥同步对性能最大的影响是阻塞的实现，因为挂起线程和恢复线程的操作都需要转入内核态中完成，这些操作给系统的并发性能带来很大的压力。同时虚拟机的开发团队也注意到在许多应用上面，共享数据的锁定状态只会持续很短一段时间，为了这一段很短的时间频繁地阻塞和唤醒线程是非常不值得的。 自旋锁：让该线程执行一段无意义的忙循环（自旋）等待一段时间，不会被立即挂起（自旋不放弃处理器额执行时间），看持有锁的线程是否会很快释放锁。自旋锁在JDK 1.4.2中引入，默认关闭，但是可以使用-XX:+UseSpinning开开启；在JDK1.6中默认开启。 自旋锁的缺点：自旋等待不能替代阻塞，虽然它可以避免线程切换带来的开销，但是它占用了处理器的时间。如果持有锁的线程很快就释放了锁，那么自旋的效率就非常好；反之，自旋的线程就会白白消耗掉处理器的资源，它不会做任何有意义的工作，这样反而会带来性能上的浪费。所以说，自旋等待的时间（自旋的次数）必须要有一个限度，例如让其循环10次，如果自旋超过了定义的时间仍然没有获取到锁，则应该被挂起（进入阻塞状态）。通过参数-XX:PreBlockSpin可以调整自旋次数，默认的自旋次数为10。 自适应的自旋锁：JDK1.6引入自适应的自旋锁，自适应就意味着自旋的次数不再是固定的，它是由前一次在同一个锁上的自旋时间及锁的拥有者的状态来决定：如果在同一个锁的对象上，自旋等待刚刚成功获得过锁，并且持有锁的线程正在运行中，那么虚拟机就会认为这次自旋也很有可能再次成功，进而它将允许自旋等待持续相对更长的时间。如果对于某个锁，自旋很少成功获得过，那在以后要获取这个锁时将可能省略掉自旋过程，以避免浪费处理器资源。简单来说，就是线程如果自旋成功了，则下次自旋的次数会更多，如果自旋失败了，则自旋的次数就会减少。 自旋锁使用场景：从轻量级锁获取的流程中我们知道，当线程在获取轻量级锁的过程中执行CAS操作失败时，是要通过自旋来获取重量级锁的。 公平锁和非公平锁&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;公平锁是指多个线程按照申请锁的顺序来获取锁，线程直接进入队列中排队，队列中的第一个线程才能获得锁。公平锁的优点是等待锁的线程不会饿死。缺点是整体吞吐效率相对非公平锁要低，等待队列中除第一个线程以外的所有线程都会阻塞，CPU唤醒阻塞线程的开销比非公平锁大。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;非公平锁是多个线程加锁时直接尝试获取锁，获取不到才会到等待队列的队尾等待。但如果此时锁刚好可用，那么这个线程可以无需阻塞直接获取到锁，所以非公平锁有可能出现后申请锁的线程先获取锁的场景。非公平锁的优点是可以减少唤起线程的开销，整体的吞吐效率高，因为线程有几率不阻塞直接获得锁，CPU不必唤醒所有线程。缺点是处于等待队列中的线程可能会饿死，或者等很久才会获得锁 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;synchronized锁实现是非公平锁，当我们需要使用公平锁的时候，我们可以使用ReentrantLock。根据代码可知，ReentrantLock里面有一个内部类Sync，Sync继承AQS，添加锁和释放锁的大部分操作实际上都是在Sync中实现的。它有公平锁FairSync和非公平锁NonfairSync两个子类。ReentrantLock默认使用非公平锁，也可以通过构造器来显示的指定使用公平锁。 可重入锁和非可重入锁&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;可重入锁是是指当一个线程在外层方法中获取了一把锁，进入到内层方法再次遇到同样一把锁时可以直接获取该锁，而不需要阻塞。synchronized和ReentrantLock都是可重入锁。可重入锁的一个优点是可一定程度避免死锁。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;ReentrantLock实现可重入锁是基于它定义的一个int型变量state，当一个线程来获取锁时，判断state是否为0，是0的话代表没有线程获取锁，线程就可以通过CAS将state自增+1。如果state不为0，表示已经有线程获取了锁，此时判断获取锁的线程是不是当前线程，是当前线程的话也可以获取锁（这个就实现了可重入锁），同样通过CAS将state自增+1。释放锁的过程刚好相反，每次通过CAS将state减1。加了多少次锁，就需要解多少次锁，不然很容易造成死锁。 独享锁和共享锁&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;独享锁也叫排他锁，是指该锁一次只能被一个线程所持有。如果线程T对数据A加上排它锁后，则其他线程不能再对A加任何类型的锁。获得排它锁的线程即能读数据又能修改数据。JDK中的synchronized和JUC中ReentrantLock就是互斥锁。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;共享锁是指该锁可被多个线程所持有。如果线程T对数据A加上共享锁后，则其他线程只能对A再加共享锁，不能加排它锁。获得共享锁的线程只能读数据，不能修改数据。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; ReentrantReadWriteLock包含一个readLock和一个writeLock，readLock是共享锁，writeLock是独享锁。ReentrantLock的实现是通过AQS中的state变量(int类型，32位)，而ReentrantReadWriteLock包含读写两把锁，如果在state一个整型变量上维护多种状态，就一定需要“按位切割使用”这个变量，读写锁将变量切分成了两个部分，高16位表示读，低16位表示写，划分方式如下图所示 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 锁降级指的是写锁降级成为读锁。如果当前线程拥有写锁，然后将其释放，最后再获取读锁，这种分段完成的过程不能称之为锁降级。锁降级是指把持住（当前拥有的）写锁，再获取到读锁，随后释放（先前拥有的）写锁的过程。反之由读锁升级到写锁是不允许的。 参考资料 《java并发编程的艺术》 不可不说的Java“锁”事 Java synchronized原理总结","categories":[{"name":"Java","slug":"Java","permalink":"http://yoursite.com/categories/Java/"}],"tags":[{"name":"并发","slug":"concurrent","permalink":"http://yoursite.com/tags/concurrent/"},{"name":"lock","slug":"lock","permalink":"http://yoursite.com/tags/lock/"}],"keywords":[{"name":"Java","slug":"Java","permalink":"http://yoursite.com/categories/Java/"}]},{"title":"分布式锁介绍及其实现方式","slug":"distributedLock","date":"2019-01-15T03:15:14.000Z","updated":"2020-01-15T10:39:54.525Z","comments":true,"path":"distributed/distributedLock.html","link":"","permalink":"http://yoursite.com/distributed/distributedLock.html","excerpt":"&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;提到锁，我们最先想到的是Java的synchronized关键字和JUC包中的ReentrantLock，这两个锁可以满足我们在多线程中对共享资源的安全访问，但是随着分布式的发展，本地锁已经没办法满足我们的需求了。为了在分布式环境也能对一个共享资源进行安全访问，我们需要引入分布式锁。","text":"&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;提到锁，我们最先想到的是Java的synchronized关键字和JUC包中的ReentrantLock，这两个锁可以满足我们在多线程中对共享资源的安全访问，但是随着分布式的发展，本地锁已经没办法满足我们的需求了。为了在分布式环境也能对一个共享资源进行安全访问，我们需要引入分布式锁。 分布式锁特点 互斥性：和本地锁一样，必须保证只有一个线程能够获取到锁。 可重入性：同一个节点的同一个线程获取到锁之后可以再次获取同一把锁。 锁超时：分布式锁应该有一个超时时间，这样可以防止死锁。 高效，高可用：加锁和解锁必须性能高效，同时也需要保证高可用防止分布式锁失效。 支持阻塞和非阻塞(可选)：和ReentrantLock一样支持lock和trylock以及tryLock(long timeOut)。 支持公平锁和非公平锁(可选)：公平锁的意思是按照请求加锁的顺序获得锁，非公平锁就相反是无序的。这个一般可以不用实现。 分布式锁实现方式分布式锁的实现方式有很多种，一般主要有以下几种： 基于数据库实现 基于Redis实现 基于Zookeeper实现 自研分布式锁(如谷歌的Chubby) 基于数据库实现基于数据库实现分布式锁主要有两张方案，但是他们也都有一些缺陷。 利用主键唯一规则： 利用数据库主键唯一规则，当有多个插入请求同时提交到数据库时，数据库可以保证只有一条数据能插入成功，这样可以认为插入数据成功的那个线程获取到了锁，当方法执行完毕后，删除这条数据库记录即可释放锁。 这种方式依赖数据库的可用性，所以要保证高可用就必须部署数据库集群。其次这把锁没有失效时间，一旦解锁失败，会导致锁一直存在，其他线程不能再次获取锁，解决方案是有定时任务一直去删除过期的锁。另外要保证阻塞的话，需要我们手动去循环获取锁。这把锁是非重入的，同一个线程在没有释放锁之前无法再次获得该锁。因为数据中数据已经存在了，要解决这个需要记录获取锁的主机信息以及线程信息，并同时用一个count字段记录获取锁的次数。最后这把锁是非公平锁，所有等待锁的线程凭运气去争夺锁，要实现成公平锁需要另外建一张表顺序记录获取锁的线程。 利用数据库行锁特性： 在查询语句后面显示加for update，这样可以利用行级锁的排他性来实现分布式锁，需要释放锁的时候直接commit就可以了。 这种方式有两个比较大的问题：一是利用事务进行加锁的时候，query需要占用数据库连接，在行锁的时候连接不释放，这就会导致连接池爆满。二是mysql使用行锁时默认要走索引，但是有时mysql根据执行计划认为全表扫描效率更高的时候就会将行锁升级为表锁，解决这个问题的话需要我们查询的时候显式制定索引。 基于Redis实现基于redis来实现分布式锁主要方案就是： 加锁： 使用SET key value [EX seconds] [PX milliseconds] [NX] 命令来实现加锁。这个命令一共五个参数：第一个为key，我们使用key来当锁，因为key是唯一的；第二个为value，我们传的是requestId，这个requestId在解锁时需要用到，保证解锁的是加锁的那个线程；第三四个代表设置过期时间；最后一个参数需要使用NX，代表当key不存在的时候写入。 有些人会使用setnx和expire两个命令代替上面的方式，但是这样会有一个问题，由于这两个操作不是原子的，如果在setnx之后expire失败了，就会导致锁没有过期时间，这样会造成死锁。 解锁： 我们使用Lua脚本来实现解锁操作 12String script = &quot;if redis.call(&apos;get&apos;, KEYS[1]) == ARGV[1] then return redis.call(&apos;del&apos;, KEYS[1]) else return 0 end&quot;;Object result = jedis.eval(script, Collections.singletonList(lockKey), Collections.singletonList(requestId)); 解锁操作使用eval命令执行一段Lua脚本，首先获取锁对应的value值，检查是否与requestId相等，如果相等则删除锁（解锁）。使用Lua脚本可以保证原子性； 基于redis实现分布式还有其他方式，比如基于Redlock和基于redisson来实现，这两种方式没做研究，这里不做过多介绍。 基于Zookeeper实现Zookeeper是一个分布式一致性协调框架，主要可以实现选主、配置管理和分布式锁等常用功能，因为Zookeeper的写入都是顺序的，在一个节点创建之后，其他请求再次创建便会失败，同时可以对这个节点进行Watch，如果节点删除会通知其他节点抢占锁。Zookeeper实现分布式锁虽然是比较重量级的，但实现的锁功能十分健全。 总结基于数据库实现的方式还是比较复杂，而且性能也不高，不推荐使用。 基于redis实现的方式比较简单，性能也比较好，引入redis集群可以保证高可用，推荐大家使用redis的方式实现。 基于Zookeeper实现的方式比较重，同时还需要维护Zookeeper集群，实现起来还是比较复杂的，实现不好的话还会引起“羊群效应”。如果不是原有系统就依赖Zookeeper，同时压力不大的情况下。一般不使用Zookeeper实现分布式锁。","categories":[{"name":"分布式","slug":"distributed","permalink":"http://yoursite.com/categories/distributed/"}],"tags":[{"name":"distributed","slug":"distributed","permalink":"http://yoursite.com/tags/distributed/"},{"name":"lock","slug":"lock","permalink":"http://yoursite.com/tags/lock/"}],"keywords":[{"name":"分布式","slug":"distributed","permalink":"http://yoursite.com/categories/distributed/"}]},{"title":"一文详解Redis","slug":"redis","date":"2019-01-10T10:03:34.000Z","updated":"2020-01-15T03:09:14.372Z","comments":true,"path":"middleware/redis.html","link":"","permalink":"http://yoursite.com/middleware/redis.html","excerpt":"Redis是一个开源的，基于内存的，也可进行持久化的，基于C语言编写的存储数据库。Redis能达到11w的QPS。Redis这么快的原因主要有以下几点: 完全基于内存，数据全部存储在内存中，读取时没有磁盘IO，所以速度非常快。 Redis采用单线程的模型，没有上下文切换的开销，也没有竞态条件，不用去考虑各种锁的问题，不存在加锁释放锁操作，没有因为可能出现死锁而导致的性能消耗。","text":"Redis是一个开源的，基于内存的，也可进行持久化的，基于C语言编写的存储数据库。Redis能达到11w的QPS。Redis这么快的原因主要有以下几点: 完全基于内存，数据全部存储在内存中，读取时没有磁盘IO，所以速度非常快。 Redis采用单线程的模型，没有上下文切换的开销，也没有竞态条件，不用去考虑各种锁的问题，不存在加锁释放锁操作，没有因为可能出现死锁而导致的性能消耗。 Redis项目中使用的数据结构都是专门设计的，例如SDS(简单动态字符串)是对C语言中的字符串频繁修改时，会频繁地进行内存分配，十分消耗性能，而SDS会使用空间预分配和惰性空间释放来避免这些问题的出现。 采用多路复用IO模型，可以同时监测多个流的IO事件能力，在空闲时，会把当前线程阻塞掉，当有一个或多个流有I/O事件时，就从阻塞态唤醒，轮询那些真正发出了事件的流，并只依次顺序的处理就绪的流。可以让单个线程高效的处理多个连接请求（尽量减少网络 I/O 的时间消耗)。 Redis使用场景 取最新N个数据的操作：可以将数据存在redis的list中。 排行榜应用，取TOP N操作：这个可以将数据存入sorted set中，把排序值设为score，根据score进行排序。 需要精准设定过期时间的应用： 计数器应用：redis的命令都是原子性的，你可以轻松的利用incr，decr命令来构建计数器系统。 unique操作，获取所有数据的排重值：可以使用redis的set pub/sub构建实时消息系统 构建队列系统 缓存 Redis和Memcached的区别 数据类型支持不同Memcached仅支持简单的key-value结构的数据记录不同，Redis支持的数据类型要丰富得多。最为常用的数据类型主要由五种：String、Hash、List、Set和Sorted Set。Memcached单个key-value大小有限，一个value最大只支持1MB，而Redis最大支持512MB 内存管理机制不同在Redis中，并不是所有的数据都一直存储在内存中的。这是和Memcached相比一个最大的区别。当物理内存用完时，Redis可以将一些很久没用到的value交换到磁盘。Redis只会缓存所有的key的信息，如果Redis发现内存的使用量超过了某一个阀值，将触发swap的操作.Redis和Memcached虽然都是基于C语言开发的，但是为了提高内存的管理效率，高效的内存管理方案都不会直接使用malloc/free调用。Redis和Memcached均使用了自身设计的内存管理机制，但是实现方法存在很大的差异。Memcached默认使用Slab Allocation机制管理内存，其主要思想是按照预先规定的大小，将分配的内存分割成特定长度的块以存储相应长度的key-value数据记录，以完全解决内存碎片问题。Redis每一个数据块都是根据数据类型和大小进行分配的，这一块数据的元数据（比如数据块大小）会存入内存块的头部。Redis使用现场申请内存的方式来存储数据，并且很少使用free-list等方式来优化内存分配，会在一定程度上存在内存碎片，Redis跟据存储命令参数，会把带过期时间的数据单独存放在一起，并把它们称为临时数据，非临时数据是永远不会被剔除的，即便物理内存不够，导致swap也不会剔除任何非临时数据（但会尝试剔除部分临时数据），这点上Redis更适合作为存储而不是cache。 数据持久化支持Redis虽然是基于内存的存储系统，但是它本身是支持内存数据的持久化的，而且提供两种主要的持久化策略：RDB快照和AOF日志。而Memcached是不支持数据持久化操作的。 集群管理的不同Memcached本身并不支持分布式，因此只能在客户端通过像一致性哈希这样的分布式算法来实现Memcached的分布式存储。当客户端向Memcached集群发送数据之前，首先会通过内置的分布式算法计算出该条数据的目标节点，然后数据会直接发送到该节点上存储。但客户端查询数据时，同样要计算出查询数据所在的节点，然后直接向该节点发送查询请求以获取数据。Redis Cluster是一个实现了分布式且允许单点故障的Redis高级版本，它没有中心节点，具有线性可伸缩的功能。为了保证单点故障下的数据可用性，Redis Cluster引入了Master节点和Slave节点。在Redis Cluster中，每个Master节点都会有对应的两个用于冗余的Slave节点。这样在整个集群中，任意两个节点的宕机都不会导致数据的不可用。当Master节点退出后，集群会自动选择一个Slave节点成为新的Master节点。 Redis数据结构Redis共有5种数据结构：string，list，set，zset，hash。 Redis内部使用一个redisObject对象来表示所有的key和value。redisObject的源码如下所示： 1234567891011121314 typedef struct redisObject &#123; // 类型 unsigned type:4; // 编码 unsigned encoding:4; // 指向底层实现数据结构的指针 void *ptr; // ...&#125; robj; type字段对应redis的5种数据结构。 encoding字段记录对象使用的编码(数据结构)，可以通过命令 object encoding key 来查看redis对象中的encoding。redis主要有以下11种encoding。 stringstring是Redis最常用的数据结构，应用场景也比较广泛，可以用于缓存，计数器，用户session共享等。 listList 是有序列表，和java的list很像，我们可以通过 List 存储一些列表型的数据结构，类似首页推荐列表、文章的评论列表之类的东西。通过 lrange 命令，读取某个闭区间内的元素，可以基于 List 实现分页查询，这个是很棒的一个功能，基于 Redis 实现简单的高性能分页，可以做类似微博那种下拉不断分页的东西，性能高。 setSet 是无序集合，类似java的set，也可以去重。set可以存储一些需要去重的数据，虽然java的HashSet可以做到，但是我们的项目一般都是分布式的，需要全局去重，这时使用Redis的set再好不过了。Set可以用来存储好友列表，这样可以通过set的取交集，差集等操作获取共同好友等。 Sorted setSorted set 是排序的 Set，去重但可以排序，写进去的时候给一个分数，自动根据分数排序。有序集合的使用场景与集合类似，但是set集合不是自动有序的，而Sorted set可以利用分数进行成员间的排序，而且是插入时就排序好。所以当你需要一个有序且不重复的集合列表时，就可以选择Sorted set数据结构作为选择方案。排行榜：有序集合经典使用场景。例如视频网站需要对用户上传的视频做排行榜，榜单维护可能是多方面：按照时间、按照播放量、按照获得的赞数等。用Sorted Sets来做带权重的队列，比如普通消息的score为1，重要消息的score为2，然后工作线程可以选择按score的倒序来获取工作任务。让重要的任务优先执行。 hash这个是类似 Map 的一种结构，这个一般就是可以将结构化的数据，比如一个对象（前提是这个对象没嵌套其他的对象）给缓存在 Redis 里，然后每次读写缓存的时候，可以就操作 Hash 里的某个字段。一般可以使用hash存储用户的信息。 Redis持久化Redis 提供了 RDB 和 AOF 两种持久化方式，RDB 是把内存中的数据集以快照形式写入磁盘，实际操作是通过 fork 子进程执行，采用二进制压缩存储；AOF 是以文本日志的形式记录 Redis 处理的每一个写入或删除操作。RDB持久化的特点是：文件小，恢复快，不影响性能，实时性低。AOF持久化的特点是：文件大，恢复慢，性能影响大，实时性高。 对于两种方式的选择，如果可以接受丢失十几分钟及更长时间的数据，可以选择RDB持久化，对性能影响小，如果只能接受秒级的数据丢失，只能选择AOF持久化。 AOF如果配置是everysec那么会每秒执行fsync操作，调用write写入磁盘一次，但是如果硬盘负载过高，fsync操作可能会超过1s，Redis主线程持续高速向aof_buf写入命令，硬盘的负载可能会越来越大，IO资源消耗更快，所以Redis的处理逻辑是会对比上次fsync成功的时间，如果超过2s，则主线程阻塞直到fsync同步完成，所以最多可能丢失2s的数据，而不是1s。 为了防止AOF文件越来越大，可以通过执行BGREWRITEAOF命令，会fork子进程出来，读取当前数据库的键值对信息，生成所需的写命令，写入新的AOF文件。在生成期间，父进程继续正常处理请求，执行修改命令后，不仅会将命令写入aof_buf缓冲区，还会写入重写aof_buf缓冲区。当新的AOF文件生成完毕后，子进程父进程发送信号，父进程将重写aof_buf缓冲区的修改命令写入新的AOF文件，写入完毕后，对新的AOF文件进行改名，原子的地替换旧的AOF文件。 Redis过期策略 惰性清除：在访问key时，如果发现key已经过期，那么会将key删除。 过期清理：Redis有定时任务会对过期的key进行清理(这个不会扫描所有过期的key)。 内存淘汰：当执行写入命令时，如果发现内存不够，那么就会按照配置的淘汰策略清理内存，淘汰策略主要由以下几种： noeviction：不删除，达到内存限制时，直接不执行命令返回错误信息。 allkeys-lru：在所有key中，使用LRU算法，优先删除最近没有使用的key。 allkeys-random：在所有key中，随机删除一部分key。 volatile-lru：在设置了过期时间的key中，使用LRU算法，优先删除最近没有使用的key。 volatile-random：在设置了过期时间的key中，随机删除一部分key。 volatile-ttl：在设置了过期时间的key中，优先删除过期时间短的key。 allkeys-lfu：在所有key中，使用LFU算法，优先删除最少使用的key。 volatile-lfu：在设置了过期时间的key中，使用LFU算法，优先删除最少使用的key。 Redis部署方式Redis主要有四种部署方式：单点（Standalone），主从（Master-Slave），哨兵（Sentinel），集群（Cluster）。 单点最简单的部署方式，采用单个redis节点进行部署。不能保证高可用，也不能实现读写分离，一般生产环境不会采用这种方式。 主从采用多个redis节点进行部署，其中一个为master节点，其他为slave节点，主从节点一般部署在不同机器上。主从模式同样不能保证高可用，主节点挂了之后需手动将从节点切换成主节点，但是可以实现读写分离，一定程度上提高吞吐量。 哨兵Redis Sentinel是社区版本推出的原生高可用解决方案，其部署架构主要包括两部分：Redis Sentinel集群和Redis数据集群。其中Redis Sentinel集群是由若干Sentinel节点组成的分布式集群，可以实现故障发现、故障自动转移、配置中心和客户端通知。Redis Sentinel的节点数量要满足2n+1（n&gt;=1）的奇数个。哨兵模式工作原理： 认定主节点主观下线：哨兵节点会定时向主节点发送ping命令，如果没有回复，代表主节点主观下线。 认定主节点客观下线：哨兵节点认定主节点主观下线后，会向其他哨兵节点发送sentinel is-master-down-by-addr命令，获取其他哨兵节点对该主节点的状态，当认定主节点下线的哨兵数量超过半数时，就认定主节点客观下线。 进行领导者哨兵选举：认定主节点客观下线后,各个哨兵之间相互通信，选举出一个领导者哨兵，由它来对主节点进行故障转移操作。 领导者哨兵进行故障转移：领导者哨兵节点首先会从从节点中选出一个节点作为新的主节点，向这个从节点发送slaveof no one命令，让其成为主节点，通过slaveof 命令让其他从节点成为它的从节点，将已下线的主节点更新为新的主节点的从节点。 集群Redis Cluster是社区版推出的Redis分布式集群解决方案，主要解决Redis分布式方面的需求，比如，当遇到单机内存，并发和流量等瓶颈的时候，Redis Cluster能起到很好的负载均衡的目的。Redis Cluster集群节点最小配置6个节点以上（3主3从），其中主节点提供读写操作，从节点作为备用节点，不提供请求，只作为故障转移使用。Redis Cluster没有使用一致性hash，而是采用虚拟槽分区，所有的键根据哈希函数映射到0～16383个整数槽内，每个节点负责维护一部分槽以及槽所印映射的键值数据。Redis Cluster并不支持处理多个keys的命令，因为这需要在不同的节点间移动数据，从而达不到像Redis那样的性能，在高负载的情况下可能会导致不可预料的错误。","categories":[{"name":"middleware","slug":"middleware","permalink":"http://yoursite.com/categories/middleware/"}],"tags":[{"name":"redis","slug":"redis","permalink":"http://yoursite.com/tags/redis/"}],"keywords":[{"name":"middleware","slug":"middleware","permalink":"http://yoursite.com/categories/middleware/"}]},{"title":"Java NIO详解","slug":"nio","date":"2018-10-24T10:26:20.000Z","updated":"2018-10-27T06:32:32.604Z","comments":true,"path":"Java/nio.html","link":"","permalink":"http://yoursite.com/Java/nio.html","excerpt":"1.NIO概念 NIO与传统IO相比最大的特点就是非阻塞。IO是阻塞的，当一个线程调用read或write方法时，线程必须等待文件读取完或者写完才能去执行其他任务；而NIO是非阻塞的，它允许线程请求从通道中读取数据，如果当前没有可用数据，线程可以继续执行其他操作，而不是一直阻塞。","text":"1.NIO概念 NIO与传统IO相比最大的特点就是非阻塞。IO是阻塞的，当一个线程调用read或write方法时，线程必须等待文件读取完或者写完才能去执行其他任务；而NIO是非阻塞的，它允许线程请求从通道中读取数据，如果当前没有可用数据，线程可以继续执行其他操作，而不是一直阻塞。 2.NIO主要组件NIO包含三个主要的类： Buffer Channel Selector NIO有许多类组成，但是buffer，channel和selector构成了核心的API。所以接下来会主要介绍这三个类。通常，NIO中的所有IO都是以channel开始。Channel其实和IO中的stream差不多。通过channel数据能被写入buffer中，同样数据能从buffer中写入channel。如下图： Buffer和Channel的主要子类如下所示： ByteBuffer -&gt;MappedByteBuffer(实现内存映射文件) CharBuffer ShortBuffer IntBuffer FloatBuffer DoubleBuffer LongBuffer FileChannel DatagramChannel SocketChannel ServerSocketChannel Selector允许一个线程操作多个Channel。如果你的应用程序打开了很多连接（Channel），但是每个连接上的通信量很低，那么这时候Selector就很方便。比如聊天服务器。下图说明了selector和channel的关系： 3.Buffer 3.1 Capacity、Position、Limitbuffer主要有三个属性：capacity、position和limit。 capacity：buffer的容量，我们在分配buffer时会指定一个容量。当buffer达到容量之后需要清除数据才能继续向buffer中写入数据。 position：buffer中数据写入的位置。初始为0，往buffer写入或读取一字节数据，position就会加1，当清除buffer 中数据或者由写模式切换为读模式时，position会重新置0，postion最大为capacity-1。 limit：在写模式中，limit就等于buffer的capacity。在读模式中，limit是指可以从buffer中读取的数据量的限制。 3.2 Allocating a Buffer想要得到一个buffer首先必须分配它，每个Buffer类中都提供了一个静态方法allocate()来分配buffer。 12ByteBuffer buf = ByteBuffer.allocate(2048);CharBuffer buf = CharBuffer.allocate(1024); 3.3 Writing Data to a Buffer往buffer中写入数据有两种方式： 一是调用buffer的put方法写入数据，如buf.put(127)； 二是将数据通过channel写入buffer，如int num = channel.read(buf);flip()方法是将buffer从写模式切换到读模式，这个会重新设置position和limit的值。 3.4 Reading Data from a Buffer从buffer中读取数据也有两种方式： 一是调用buffer的get方式读取数据，如buf.get()； 二是读取buffer数据到channel中，如int bytesWritten = inChannel.write(buf); 3.5 rewind()、clear()、compact() rewind()可以将position值重新置为0，这样就可以重新读取buffer中的数据。 clear()方法将设置poistion为0，设置limit为capacity，clear虽然不会清除buffer中的数据，但是后续写入的数据会覆盖之前的数据，相当于清空了buffer数据。 compact()和clear不同，它会将之前的数据移向左边，将position设置为最后一个未读数据，从这个基础上再开始写入。 3.6 mark()、reset()调用mark()方法可以标记当前buffer中的position，执行一些操作之后调用reset()可以可以将position回到刚才标记的位置。12345buffer.mark();//call buffer.get() a couple of times, e.g. during parsing.buffer.reset(); //set position back to mark. 4.Channel所有的NIO操作都是始于channel，数据的读取和写入都会经过channel。 4.1 FileChannel(文件通道，用于文件的读和写)不能设置为非阻塞模式，只能是阻塞模式 Open a FileChannel使用一个FileChannel之前必须先打开它，但是不可能直接打开FileChannel，必须通过InputStream，OutputStream或者RandomAccessFile来获取一个FileChannel。RandomAccessFile aFile = new RandomAccessFile(&quot;data/nio-data.txt&quot;, &quot;rw&quot;);FileChannel inChannel = aFile.getChannel(); Read Data from a FileChannelByteBuffer buf = ByteBuffer.allocate(48);int bytesRead = inChannel.read(buf);上面bytesRead如果返回-1，说明读取完了 Write Data to a FileChannelString newData = &quot;New String to write to file...&quot; + System.currentTimeMillis();ByteBuffer buf = ByteBuffer.allocate(48);buf.clear();buf.put(newData.getBytes());buf.flip();while(buf.hasRemaining()) {channel.write(buf);} Close a FileChannelchannel.close() FileChannel Position当你想在一个特定位置读取或写入FileChannel，你可以通过position()方法获取FileChannel的当前位置，然后你可以通过position(long newPosition)方法设置新的postiion。long pos=channel.position();channel.position(pos + 123); FileChannel SizeFileChannel对象的size()方法返回通道连接的文件的文件大小。 FileChannel Truncate调用FileChannel.truncate()方法来截断文件。当您截断一个文件时，您将它以给定的长度截断。channel.truncate(1024); FileChannel Forceforce()方法将所有未写入的数据从通道刷新到磁盘。force()方法以一个布尔值作为参数，告诉文件元数据(权限等)是否也应该刷新。 4.2 SocketChannel(用于通过TCP读写数据)SocketChannel是连接到TCP网络套接字的通道。它相当于Java NIO的Java网络套接字。打开一个SocketChannel的代码如下：SocketChannel socketChannel = SocketChannel.open();socketChannel.connect(new InetSocketAddress(&quot;http://xxx.com&quot;, 80));SocketChannel的读写和FileChannel没什么区别。 4.3 ServerSocketChannel(TCP对应的服务端，用来某个端口进来的请求)ServerSocketChannel可以用来监听进来的tcp连接，就像java标准网络中的ServerSocket。 12345678910//实例化ServerSocketChannel serverSocketChannel = ServerSocketChannel.open();//监听端口serverSocketChannel.socket().bind(new InetSocketAddress(9999));while(true)&#123; //监听进来的tcp连接，创建SocketChannel SocketChannel socketChannel = serverSocketChannel.accept(); //do something with socketChannel...&#125; 4.4 DatagramChannel(用于通过UDP从网络上读写数据)DatagramChannel是一个能够发送和接收UDP包的通道，由于UDP是无连接的，所以在默认情况下，您不能像从其他通道那样读写DatagramChannel。你只可以发送和接收数据包。监听端口 12DatagramChannel channel = DatagramChannel.open();channel.socket().bind(new InetSocketAddress(9999)); 接收数据123ByteBuffer buf = ByteBuffer.allocate(48);buf.clear();channel.receive(buf); 发送数据 123456String newData = &quot;New String to write to file...&quot;+ System.currentTimeMillis();ByteBuffer buf = ByteBuffer.allocate(48);buf.clear();buf.put(newData.getBytes());buf.flip();int bytesSent = channel.send(buf, new InetSocketAddress(&quot;xxx.com&quot;, 80)); 4.5 Channel Transfers在NIO中，如果其中一个channel是FileChannel时，则可以将数据直接从一个通道传到另一个通道。FileChannel中的transferFrom()方法能够将数据从一个源通道传送到FileChannel中。1234567RandomAccessFile fromFile = new RandomAccessFile(&quot;fromFile.txt&quot;, &quot;rw&quot;);FileChannel fromChannel = fromFile.getChannel();RandomAccessFile toFile = new RandomAccessFile(&quot;toFile.txt&quot;, &quot;rw&quot;);FileChannel toChannel = toFile.getChannel();long position = 0;long count = fromChannel.size();toChannel.transferFrom(fromChannel, position, count); FileChannel中的transferTo()方法可以将数据从FileChannel中传送到其他通道。1234567RandomAccessFile fromFile = new RandomAccessFile(&quot;fromFile.txt&quot;, &quot;rw&quot;);FileChannel fromChannel = fromFile.getChannel();RandomAccessFile toFile = new RandomAccessFile(&quot;toFile.txt&quot;, &quot;rw&quot;);FileChannel toChannel = toFile.getChannel();long position = 0;long count = fromChannel.size();fromChannel.transferTo(position, count, toChannel); 5.SelectorSelector可以检查一个或多个channel，并确定哪些channel准备就绪。通过这种方式，一个线程可以管理多个channel，从而管理多个网络连接。 5.1 创建Selector和注册Channel到Selector1234Selector selector = Selector.open();//设置为非阻塞模式channel.configureBlocking(false);SelectionKey key = channel.register(selector, SelectionKey.OP_READ); 上面第二行用于设置非阻塞模式，由于Selector必须工作在非阻塞模式中，所以FileChannel不能使用Selector。register方法的第二个参数是一个int型参数（使用二进制标记位，叫interest set），用于表明channel需要监听哪些感兴趣的事件，共有以下四种事件。 Read对应SelectionKey.OP_READ(值为1&lt;&lt;0)，表示channel可以读取数据。 Write对应SelectionKey.OP_WRITE(值为1&lt;&lt;2)，表示channel可以写入数据。 Connect对应SelectionKey.OP_CONNECT(值为1&lt;&lt;3)，表示channel建立连接。 Accept对应SelectionKey.OP_ACCEPT(值为1&lt;&lt;4)，表示channel可以接收传入的连接。 如果想要设置多个事件，则将对应的key进行与操作。如下： 1int interestSet = SelectionKey.OP_READ | SelectionKey.OP_WRITE; 5.2 SelectionKey上面注册channel时register方法会返回一个SelectionKey对象。这个SelectionKey对象包含以下属性： Interest SetInterest Set中是channel感兴趣的事件集合，你可以通过下面的方法获取Interest Set。 123456int interestSet = selectionKey.interestOps();boolean isInterestedInAccept = interestSet &amp; SelectionKey.OP_ACCEPT;boolean isInterestedInConnect = interestSet &amp; SelectionKey.OP_CONNECT;boolean isInterestedInRead = interestSet &amp; SelectionKey.OP_READ;boolean isInterestedInWrite = interestSet &amp; SelectionKey.OP_WRITE; Ready SetReady Set 表示的是channel已经准备好的事件集合。通常在选择一个channel之后来访问这个集合。 12345int readySet = selectionKey.readyOps();selectionKey.isAcceptable();selectionKey.isConnectable();selectionKey.isReadable();selectionKey.isWritable(); Channel + Selector获取channel和selector比较简单。 12Channel channel = selectionKey.channel();Selector selector = selectionKey.selector(); Attaching Objects可以将对象附加到SelectionKey对象上，这是识别channel或者将信息附加到channel上的方便方法。 123selectionKey.attach(theObject);Object attachedObj = selectionKey.attachment(); 也可以在register的时候附加对象。 1SelectionKey key = channel.register(selector, SelectionKey.OP_READ, theObject); 5.3 Select Channel通过Selector的select方法我们可以选择一个channel。select方法主要有三个： select()：这个方法会阻塞直到至少一个channel准备好。 select(long timeout)：和select()功能类似，只是制定了阻塞时间。 selectNow()：这个不会阻塞，不管有没有准备好的channel，都会立即返回。 上面select方法的返回值是一个int，表示有多少个通道准备好。如果没有对第一个准备好的通道做任何操作，那么会有两个准备好的通道，但是在每个select()调用之间只有一个通道准备好。 wakeUp()：这个方法是用来唤醒等待在 select() 和 select(timeout) 上的线程的。如果 wakeup() 先被调用，此时没有线程在 select 上阻塞，那么之后的一个 select() 或 select(timeout) 会立即返回，而不会阻塞，当然，它只会作用一次。 5.5 Full Selector Example1234567891011121314151617181920212223242526272829303132333435363738Selector selector = Selector.open();channel.configureBlocking(false);SelectionKey key = channel.register(selector, SelectionKey.OP_READ);while(true) &#123; int readyChannels = selector.select(); if(readyChannels == 0) continue; Set&lt;SelectionKey&gt; selectedKeys = selector.selectedKeys(); Iterator&lt;SelectionKey&gt; keyIterator = selectedKeys.iterator(); while(keyIterator.hasNext()) &#123; SelectionKey key = keyIterator.next(); if(key.isAcceptable()) &#123; // a connection was accepted by a ServerSocketChannel. &#125; else if (key.isConnectable()) &#123; // a connection was established with a remote server. &#125; else if (key.isReadable()) &#123; // a channel is ready for reading &#125; else if (key.isWritable()) &#123; // a channel is ready for writing &#125; keyIterator.remove(); &#125;&#125; 6.NIO PipeNIO Pipe是两个线程之间一个单向的数据连接。Pipe有一个source channel和一个sink channel。将数据写入sink channel，然后可以从source channel读取这些数据。123456789101112131415161718//open pipePipe pipe = Pipe.open();//write data to sink channelPipe.SinkChannel sinkChannel = pipe.sink();String newData = &quot;New String to write to file...&quot; + System.currentTimeMillis();ByteBuffer buf = ByteBuffer.allocate(48);buf.clear();buf.put(newData.getBytes());buf.flip();while(buf.hasRemaining()) &#123; sinkChannel.write(buf);&#125;//read data from source channelPipe.SourceChannel sourceChannel = pipe.source();ByteBuffer buf = ByteBuffer.allocate(48);int bytesRead = sourceChannel.read(buf);","categories":[{"name":"Java","slug":"Java","permalink":"http://yoursite.com/categories/Java/"}],"tags":[{"name":"nio","slug":"nio","permalink":"http://yoursite.com/tags/nio/"}],"keywords":[{"name":"Java","slug":"Java","permalink":"http://yoursite.com/categories/Java/"}]},{"title":"二叉搜索树Java实现","slug":"bst","date":"2018-10-23T12:16:13.000Z","updated":"2018-10-24T08:49:28.025Z","comments":true,"path":"data-struct/bst.html","link":"","permalink":"http://yoursite.com/data-struct/bst.html","excerpt":"二叉搜索树特性： 具有二叉树的所有特性。 左节点的值永远小于根结点。 有节点的值永远大于根结点。 具有较高的查找效率。 插入效率也高，比链表要高。","text":"二叉搜索树特性： 具有二叉树的所有特性。 左节点的值永远小于根结点。 有节点的值永远大于根结点。 具有较高的查找效率。 插入效率也高，比链表要高。 二叉搜索树的Java代码实现： insert方法：插入一个节点 getMin方法：获取最小节点 getMax方法：获取最大节点 search方法：查找一个节点 delete方法：删除一个节点 deleteMax方法：删除最小节点 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299public class BinarySearchTree&lt;E extends Comparable&lt;E&gt;&gt; &#123; private Node&lt;E&gt; root; static class Node&lt;E&gt; &#123; E item; Node&lt;E&gt; leftChild; Node&lt;E&gt; rightChild; public Node(E item) &#123; this.item = item; &#125; &#125; /** * 插入 * * @param e */ public void insert(E e) &#123; root = insertNode(root, e); &#125; /** * 插入节点 * * @param node * @param e * @return */ private Node&lt;E&gt; insertNode(Node&lt;E&gt; node, E e) &#123; if (node == null) &#123; return new Node&lt;&gt;(e); &#125; int cmp = e.compareTo(node.item); if (cmp &lt; 0) &#123; //要插入的节点值比当前节点值小，则向当前节点的左节点递归插入，插入后的值赋给当前节点的左节点 node.leftChild = insertNode(node.leftChild, e); &#125; else if (cmp &gt; 0) &#123; //要插入的节点值比当前节点值大，则向当前节点的右节点递归插入，插入后的值赋给当前节点的右节点 node.rightChild = insertNode(node.rightChild, e); &#125; return node; &#125; /** * 获取整个二叉树的最小节点 * * @return */ public Node&lt;E&gt; getMin() &#123; return getMin(root); &#125; /** * 获取以指定节点为根结点的子树中的最小节点 * 由二叉搜索树的特性可知道最小节点一定是最左的一个节点， * 所以一直找最左的节点 * * @param node * @return */ public Node&lt;E&gt; getMin(Node&lt;E&gt; node) &#123; //递归实现 if (node.leftChild == null) &#123; return node; &#125; return getMin(node.leftChild); //遍历实现 /*Node&lt;E&gt; min = node; while (min.leftChild != null) &#123; min = min.leftChild; &#125; return min;*/ &#125; /** * 获取整个二叉树的最大节点 * * @return */ public Node&lt;E&gt; getMax() &#123; return getMax(root); &#125; /** * 获取以指定节点为根结点的子树中的最大节点 * 由二叉搜索树的特性可知道最小节点一定是最右的一个节点， * 所以一直找最右的节点 * * @param node * @return */ public Node&lt;E&gt; getMax(Node&lt;E&gt; node) &#123; //递归实现 if (node.rightChild == null) &#123; return node; &#125; return getMax(node.rightChild); //遍历实现 /*Node&lt;E&gt; max = node; while (max.rightChild != null) &#123; max = max.rightChild; &#125; return max;*/ &#125; public Node&lt;E&gt; search(E e) &#123; return search(root, e); &#125; /** * 查找某个节点 * * @param node * @param e * @return */ public Node&lt;E&gt; search(Node&lt;E&gt; node, E e) &#123; //遍历实现 int count = 0; Node&lt;E&gt; current = node; while (current != null) &#123; count++; int cmp = current.item.compareTo(e); if (cmp &gt; 0) &#123; current = current.leftChild; &#125; else if (cmp &lt; 0) &#123; current = current.rightChild; &#125; else if (cmp == 0) &#123; System.out.println(&quot;查找次数为：&quot; + count); return current; &#125; &#125; return null; //递归实现 /*if (node == null) &#123; return null; &#125; int cmp = node.item.compareTo(e); if (cmp &gt; 0) &#123; return search(node.leftChild, e); &#125; else if (cmp &lt; 0) &#123; return search(node.rightChild, e); &#125; else &#123; return node; &#125;*/ &#125; /** * 删除值为e的节点 * * @param key */ public void delete(E key) &#123; root = delete(root, key); &#125; /** * 删除节点 * * @param node * @param key * @return */ public Node&lt;E&gt; delete(Node&lt;E&gt; node, E key) &#123; if (node == null) &#123; return null; &#125; else &#123; int cmp = key.compareTo(node.item); if (cmp &gt; 0) &#123; //判断删除节点的值比当前节点大，则向当前节点的右节点递归删除 node.rightChild = delete(node.rightChild, key); &#125; else if (cmp &lt; 0) &#123; node.leftChild = delete(node.leftChild, key); &#125; else &#123; if (node.rightChild == null) &#123; return node.leftChild; &#125; if (node.leftChild == null) &#123; return node.rightChild; &#125; Node&lt;E&gt; t = node; node = getMin(t.rightChild); node.rightChild = deleteMin(t.rightChild); node.leftChild = t.leftChild; &#125; &#125; return node; &#125; /** * 删除树中最小节点 */ public void deleteMin() &#123; root = deleteMin(root); &#125; /** * 删除最小节点 * * @param node * @return */ public Node&lt;E&gt; deleteMin(Node&lt;E&gt; node) &#123; //如果当前节点左节点为空，则当前节点为最小节点，将当前节点的右节点返回赋值给上一节点的左节点，则表示删除了改节点。 if (node.leftChild == null) &#123; return node.rightChild; &#125; //递归删除当前节点的左节点，并将返回值赋给左节点 node.leftChild = deleteMin(node.leftChild); return node; &#125; /** * 打印节点值 * * @param node */ private void printNode(Node&lt;E&gt; node) &#123; System.out.println(node.item); &#125; /** * 先序遍历 */ public void firstOrderTraversal() &#123; firstOrderTraversal(root); &#125; /** * 先序遍历 * * @param node */ public void firstOrderTraversal(Node&lt;E&gt; node) &#123; if (node != null) &#123; printNode(node); if (node.leftChild != null) &#123; firstOrderTraversal(node.leftChild); &#125; if (node.rightChild != null) &#123; firstOrderTraversal(node.rightChild); &#125; &#125; &#125; /** * 中序遍历 */ public void inOrderTraversal() &#123; inOrderTraversal(root); &#125; /** * 中序遍历 * * @param node */ public void inOrderTraversal(Node&lt;E&gt; node) &#123; if (node != null) &#123; if (node.leftChild != null) &#123; inOrderTraversal(node.leftChild); &#125; printNode(node); if (node.rightChild != null) &#123; inOrderTraversal(node.rightChild); &#125; &#125; &#125; /** * 后续遍历 */ public void postOrderTraversal() &#123; postOrderTraversal(root); &#125; /** * 后续遍历 * * @param node */ public void postOrderTraversal(Node&lt;E&gt; node) &#123; if (node != null) &#123; if (node.leftChild != null) &#123; postOrderTraversal(node.leftChild); &#125; if (node.rightChild != null) &#123; postOrderTraversal(node.rightChild); &#125; printNode(node); &#125; &#125;&#125;","categories":[{"name":"数据结构和算法","slug":"data-struct","permalink":"http://yoursite.com/categories/data-struct/"}],"tags":[{"name":"算法","slug":"algorithms","permalink":"http://yoursite.com/tags/algorithms/"}],"keywords":[{"name":"数据结构和算法","slug":"data-struct","permalink":"http://yoursite.com/categories/data-struct/"}]},{"title":"正则表达式","slug":"regular","date":"2018-10-15T10:17:26.000Z","updated":"2018-10-24T08:58:45.121Z","comments":true,"path":"other/regular.html","link":"","permalink":"http://yoursite.com/other/regular.html","excerpt":"常用正则表达式","text":"常用正则表达式 表达式 描述 . 匹配出换行符外任意字符 \\ 转义符，可以将一些有特殊含义的字符转化为本身含义，如\\.代表点本身的含义。 [ ] 匹配中括号中字符的一个，如[abc]表示匹配a、b、c中的一个字符。 &#124; 匹配两个字符中的一个，如a&#124;b表示匹配a或者b。 [0-9A-Za-z] 字符区间，[0-9]表示0-9中的一个数。 ^ 取非匹配，[^0-9]表示不是0-9中的一个字符。 \\d 匹配数字 \\D 匹配非数字 \\w 匹配字母 \\W 匹配非字母 + 匹配一个或多个字符，如\\d+表示匹配一个或多个数字。 * 匹配0个或多个字符。 ？ 匹配0个或一个字符。 {n} 匹配多次，如\\w{3}表示匹配3个字母。 {m,n} 匹配次数是一个区间，如\\d{2,4}表示匹配2-4个数字。 {n,} 匹配至少次数的字符。 () 标记一个子表达式开始和结束 ^ 放在外面表示匹配字符串开始位置，如果是在方括号内表示取非 $ 匹配字符串结束位置 \\f 匹配一个换页符 \\n 匹配一个换行符 \\r 匹配一个回车符 \\s 匹配任何空白字符，包括空格、制表符、换页符等等。等价于 [ \\f\\n\\r\\t\\v] \\S 匹配任何非空白字符，等价于[ ^\\f\\n\\r\\t\\v] \\t 匹配一个制表符 \\v 匹配一个垂直制表符 \\b 匹配一个单词边界，即字与空格间位置 \\B 匹配一个非单词边界 ?= 向前匹配，如?=:表示匹配:然后向前匹配，最后结果不包含: ?&lt;= 向前匹配，如(?&lt;=\\$)[0-9.]+表示匹配$然后向后匹配，最后结果不包含$ 防止过度匹配 * 和+ 都是所谓的“贪婪型”元字符，它们在进行匹配时的行为模式是多多益善而不是适可而止的。它们会尽可能地从一段文本的开头一直匹配到这段文本的末尾，而不是从这段文本的开头匹配到碰到第一个匹配时为止。 为了防止这种贪婪型匹配，我们需要使用对应字符的惰性版本，* 使用 *？，+ 使用 +？，{n,}使用{n,}? 回溯引用 回溯引用指的是模式的后半部分引用在前半部分中定义的子表达式。如 &lt;hH&gt;.*?&lt;/[hH]\\1&gt;，这其中最后的\\1表示前面第一个子表达式匹配的结果，即([1-6])，依此类推，\\2表示第二个子表达式，\\n表示第n个子表达式。 回溯引用在替换操作中也很有用，如(\\d{3})(-)(\\d{3})(-)(\\d{4})这个正则表达式，使用替换的表达式($1) $3-$5，可以将匹配到的字符替换成别的格式。其中$1,$3,$5分别表示第1，第3，第5个子表达式。","categories":[{"name":"其他","slug":"other","permalink":"http://yoursite.com/categories/other/"}],"tags":[{"name":"正则","slug":"regular","permalink":"http://yoursite.com/tags/regular/"}],"keywords":[{"name":"其他","slug":"other","permalink":"http://yoursite.com/categories/other/"}]},{"title":"Java原子操作类","slug":"concurrent2","date":"2018-10-07T14:38:14.000Z","updated":"2018-10-24T08:01:34.332Z","comments":true,"path":"Java/concurrent2.html","link":"","permalink":"http://yoursite.com/Java/concurrent2.html","excerpt":"","text":"","categories":[{"name":"Java","slug":"Java","permalink":"http://yoursite.com/categories/Java/"}],"tags":[{"name":"并发","slug":"concurrent","permalink":"http://yoursite.com/tags/concurrent/"}],"keywords":[{"name":"Java","slug":"Java","permalink":"http://yoursite.com/categories/Java/"}]},{"title":"Java内存模型","slug":"concurrent1","date":"2018-10-07T07:58:29.000Z","updated":"2018-10-24T08:17:49.737Z","comments":true,"path":"Java/concurrent1.html","link":"","permalink":"http://yoursite.com/Java/concurrent1.html","excerpt":"1、Java内存模型的抽象结构 Java内存模型就是Java Memory Model（以下简称JMM），是Java虚拟机规范的一部分。JMM规定：变量存储在主存中，每个线程有自己的工作内存，线程工作内存中保存了变量在主存的副本拷贝。主存是线程共享的，工作内存变量是各个线程独享的。线程工作时，从主存中复制变量到线程的工作内存，然后在工作内存中操作变量副本，最后再把变量副本写回到主内存。","text":"1、Java内存模型的抽象结构 Java内存模型就是Java Memory Model（以下简称JMM），是Java虚拟机规范的一部分。JMM规定：变量存储在主存中，每个线程有自己的工作内存，线程工作内存中保存了变量在主存的副本拷贝。主存是线程共享的，工作内存变量是各个线程独享的。线程工作时，从主存中复制变量到线程的工作内存，然后在工作内存中操作变量副本，最后再把变量副本写回到主内存。Java内存模型是一种共享内存模型： 线程只能操作工作内存，不能直接操作主存。 每个线程只能访问自己的工作内存，不能访问其他线程的工作内存。 线程之间的数据通信必须通过主存中完成。 2、并发三问题 重排序为了提高性能，编译器和处理器会对指令进行重排序，重排序主要有三种类型： 编译器重排序：编译器在不改变单线程程序语义的前提下，可以重新安排字节码的执行顺序；也就是编译生成的机器码顺序和源代码顺序不一样。 处理器重排序：现代处理器采用指令级并行技术将多条指令重叠执行，如果不存在数据依赖性，处理器可以改变语句对应机器指令的执行顺序；也就是CPU在执行字节码时，执行顺序可能和机器码顺序不一样。 内存重排序：由于处理器使用缓存和读/写缓冲区，这使得加载和存储操作看上去可能是在乱序执行。 123456789101112131415class ReorderExample &#123; int a = 0; boolean flag = false; public void writer() &#123; a = 1; // A1 flag = true; // A2 &#125; public void reader() &#123; if (flag) &#123; // B1 int i = a * a; // B2 &#125; &#125;&#125; 线程1执行writer()方法，线程2执行reader()方法，结果怎样？ 由于writer()方法中的A1和A2操作没有依赖关系，所以可能被重排序，先执行A2，再执行A1，这种情况下由于a=0，所以i=0；reader方法中的B1、B2虽然有依赖关系，但是仍然可以重排序，B2先执行a*a=0放在缓存，当flag为true时将i赋值为0。 内存可见性内存可见性问题是由于多核缓存引起的。现在的多核cpu都有自己的一级缓存和二级缓存。Java作为高级语言，屏蔽了底层这些细节，构建了JMM规范。JMM抽象了主存和工作内存的概念。由于线程可能不能及时将工作内存中变量刷到主存，造成其他线程读取到的变量可能是错误的，这就是内存可见性问题。 原子性原子性即一个操作不可拆分。JMM只保证像read/load/store/write这样很少的操作是原子性的，甚至在32位平台下，对64位数据的读取和赋值都不能保证其原子性（long变量赋值是需要通过两个操作来完成的）。简单说，int i=10; 是原子的；i = i + 1 不是原子的；甚至long v = 100L 也可能不是原子的。 3、volatile关键字volatile关键字有两个作用：一是保证内存可见性；二是防止指令重排序。 可见性：被volatile修饰的变量，如果一个线程修改了其的值，另一个线程能够立即读取到最新的值。 禁止指令重排序：被volatile修饰的变量，保证在它前面的代码先执行，在它后面的代码后执行。 volatile小结 volatile 修饰符适用于以下场景：某个属性被多个线程共享，其中有一个线程修改了此属性，其他线程可以立即得到修改后的值。在并发包的源码中，它使用得非常多。 volatile 属性的读写操作都是无锁的，它不能替代 synchronized，因为它没有提供原子性和互斥性。因为无锁，不需要花费时间在获取锁和释放锁上，所以说它是低成本的。 volatile 只能作用于属性，我们用 volatile 修饰属性，这样 compilers 就不会对这个属性做指令重排序。 volatile 提供了可见性，任何一个线程对其的修改将立马对其他线程可见。volatile 属性不会被线程缓存，始终从主存中读取。 4、happens-before规则 happens-before用来指定两个操作之间的顺序，这两个操作可以在一个线程内，也可以在不同线程之间。因此，JMM可以通过happens-before关系向程序员提供跨线程的内存可见性。 JSR-133定义了如下happens-before规则： 程序顺序规则：一个线程中的每个操作，happens-before于该线程的任意后续操作。 监视器锁规则：对一个锁的解锁，happens-before于随后对这个锁的加锁。 volatile变量规则：对一个volatile变量的写，happens-before于随后对这个volatile变量的读。 传递性：如果A happens-before于B，B happens-before于C，可以得出A happens-before于C。 start()规则：如果线程A执行操作ThreadB.start()（启动线程B），那么A线程的ThreadB.start()操作happens-before于线程B中的任意操作。 join()规则：如果线程A执行操作ThreadB.join()并成功返回，那么线程B中的任意操作happens-before于线程A从ThreadB.join()操作成功返回。 5、synchronized关键字synchronized关键字可以实现volatile的保证内存可见性以及禁止重排序，同时它还可以保证原子性操作。但是synchronized需要进行加锁操作，效率更低。 6、final关键字final关键字可以用来修饰类、方法、变量。用来修饰变量时可以在对象初始化完成前，不要将此对象的引用写入到其他线程可以访问到的地方（不要让引用在构造函数中逸出）。如果这个条件满足，当其他线程看到这个对象的时候，那个线程始终可以看到正确初始化后的对象的 final 属性。","categories":[{"name":"Java","slug":"Java","permalink":"http://yoursite.com/categories/Java/"}],"tags":[{"name":"并发","slug":"concurrent","permalink":"http://yoursite.com/tags/concurrent/"}],"keywords":[{"name":"Java","slug":"Java","permalink":"http://yoursite.com/categories/Java/"}]},{"title":"nginx详解","slug":"nginx","date":"2018-10-06T11:00:44.000Z","updated":"2018-10-24T08:18:22.460Z","comments":true,"path":"other/nginx.html","link":"","permalink":"http://yoursite.com/other/nginx.html","excerpt":"1、概述 nginx是一个跨平台的高性能web服务器。目前我们主要使用nginx用来做反向代理服务器。 为什么选择nginx：1、更快；2、高扩展性；3、高可靠性；4、低内存消耗；5、单机支持10w以上并发连接；6、热部署。","text":"1、概述 nginx是一个跨平台的高性能web服务器。目前我们主要使用nginx用来做反向代理服务器。 为什么选择nginx：1、更快；2、高扩展性；3、高可靠性；4、低内存消耗；5、单机支持10w以上并发连接；6、热部署。 2、安装和启动2.1、编译安装 从nginx官网获取nginx的源码，然后将源码解压到准备好的目录。然后进入安装目录执行三行代码：./configure、make、make install。 configure命令做了大量的“幕后”工作，包括检测操作系统内核和已经安装的软件，参数的解析，中间目录的生成以及根据各种参数生成一些C源码文件、Makefile文件等。 make命令根据configure命令生成的Makefile文件编译Nginx工程，并生成目标文件、最终的二进制文件。 make install命令根据configure执行时的参数将Nginx部署到指定的安装目录，包括相关目录的建立和二进制文件、配置文件的复制。2.2、命令行控制 默认方式启动：./nginx 会使用默认路径下的conf文件。 另指定配置文件启动：./nginx -c /tmp/nginx.conf 使用-c参数可以指定配置文件。 另指定安装目录启动：./nginx -p /usr/local/nginx 使用-p参数指定nginx的安装目录。 测试配置信息的正确性：./nginx -t 使用-t参数测试配置文件是否正确。 在测试阶段不输出非错误信息：./nginx -t -q 测试配置选项时，使用-q参数可以不把error级别以下的信息输出到屏幕。 显示版本信息：./nginx -v 使用-v参数显示Nginx的版本信息。 快速停止服务：./nginx -s stop 可以强制停止服务。nginx程序通过nginx.pid文件得到master进程的进程ID，再向master进程发送TERM信号快速的关闭服务。 优雅停止服务：./nginx -s quit 这个会先关闭端口，停止接受新的连接，然后将当前的任务全部处理完再关闭服务。 运行中重读配置文件并生效：./nginx -s reload 可以使运行中的nginx重新加载配置文件。 3、服务架构3.1、模块化架构 nginx其实就是由很多模块组成，每个模块实现特定的功能。主要分为核心模块、标准http模块、可选http模块、邮件模块以及第三方模块等五大类。3.2、web请求处理机制 实现并行处理请求工作主要有三种方式：多进程方式、多线程方式、异步方式。nginx主要采用的是多进程机制和异步机制，异步机制使用的是异步非阻塞。3.3、事件驱动模型 异步IO的实现机制主要有两种：一是工作进程不停的查询IO是否完成；二是IO调用完成后主动通知工作进程。nginx使用的是第二种，也就是事件驱动模型。 事件收集器–&gt;事件发送器–&gt;事件处理器 常用的事件驱动模型库有：select库、poll库、epoll库。 select库：首先创建读、写、异常三类事件描述符集合，其次调用底层select函数，等待事件发生，然后轮询三个集合中的每一个事件描述符，如果有事件发生就进行处理。 poll库：poll库和select库的基本工作方式是相同的，主要区别在于select库创建了三个集合，而poll库只需要创建一个集合，是select库的优化实现。 epoll库：epoll的实现方式是把描述符列表的管理交给内核负责，一旦有某种事件发生，内核就把事件发生的描述符列表通知给进程，这样避免了轮询整个描述符列表，所以它比select库和poll库更高效。 3.4、设计架构概览 nginx的主要架构是由一个主进程(master process)，多个工作进程(worker process)组成。主进程主要进行nginx配置文件解析、数据结构初始化、模块配置和注册、信号处理、网络监听生成、工作进程生成和管理等工作，工作进程主要进行进程初始化、模块调用和请求处理等工作，是nginx服务器提供服务的主体。 4.配置下面是nginx官网基本配置的一个完整例子，更多的配置可以去官网查询相关文档。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134#用户（组）user www www;#工作进程数worker_processes 2;#进程PID存放路径pid /var/run/nginx.pid;#错误日志存放路径# [ debug | info | notice | warn | error | crit ]error_log /var/log/nginx.error_log info;#events块events &#123; #配置最大连接数 worker_connections 2000; #事件驱动模型选择 # use [kqueue|epoll|/dev/poll|select|poll]; use kqueue;&#125;#http块http &#123; #定义MIME-Type include conf/mime.types; default_type application/octet-stream; #日志格式 log_format main &apos;$remote_addr - $remote_user [$time_local] &apos; &apos;&quot;$request&quot; $status $bytes_sent &apos; &apos;&quot;$http_referer&quot; &quot;$http_user_agent&quot; &apos; &apos;&quot;$gzip_ratio&quot;&apos;; log_format download &apos;$remote_addr - $remote_user [$time_local] &apos; &apos;&quot;$request&quot; $status $bytes_sent &apos; &apos;&quot;$http_referer&quot; &quot;$http_user_agent&quot; &apos; &apos;&quot;$http_range&quot; &quot;$sent_http_content_range&quot;&apos;; client_header_timeout 3m; client_body_timeout 3m; send_timeout 3m; client_header_buffer_size 1k; large_client_header_buffers 4 4k; gzip on; gzip_min_length 1100; gzip_buffers 4 8k; gzip_types text/plain; output_buffers 1 32k; postpone_output 1460; sendfile on; tcp_nopush on; tcp_nodelay on; send_lowat 12000; keepalive_timeout 75 20; #lingering_time 30; #lingering_timeout 10; #reset_timedout_connection on; server &#123; listen one.example.com; server_name one.example.com www.one.example.com; access_log /var/log/nginx.access_log main; location / &#123; proxy_pass http://127.0.0.1/; proxy_redirect off; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; #proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; client_max_body_size 10m; client_body_buffer_size 128k; client_body_temp_path /var/nginx/client_body_temp; proxy_connect_timeout 70; proxy_send_timeout 90; proxy_read_timeout 90; proxy_send_lowat 12000; proxy_buffer_size 4k; proxy_buffers 4 32k; proxy_busy_buffers_size 64k; proxy_temp_file_write_size 64k; proxy_temp_path /var/nginx/proxy_temp; charset koi8-r; &#125; error_page 404 /404.html; location = /404.html &#123; root /spool/www; &#125; location /old_stuff/ &#123; rewrite ^/old_stuff/(.*)$ /new_stuff/$1 permanent; &#125; location /download/ &#123; valid_referers none blocked server_names *.example.com; if ($invalid_referer) &#123; #rewrite ^/ http://www.example.com/; return 403; &#125; #rewrite_log on; # rewrite /download/*/mp3/*.any_ext to /download/*/mp3/*.mp3 rewrite ^/(download/.*)/mp3/(.*)\\..*$ /$1/mp3/$2.mp3 break; root /spool/www; #autoindex on; access_log /var/log/nginx-download.access_log download; &#125; location ~* \\.(jpg|jpeg|gif)$ &#123; root /spool/www; access_log off; expires 30d; &#125; &#125;&#125; 5.反向代理与负载均衡正向代理和反向代理： 简单说，正向代理用来让局域网客户机接入外网以访问外网资源，反向代理用来让外网的客户端接入局域网中的站点以访问站点中的资源。 正向代理 1234567server &#123; resolver 192.168.1.1; #指定DNS服务器IP地址 listen 8080; location / &#123; proxy_pass http://$http_host$request_uri; #设定代理服务器的协议和地址 &#125; &#125; 反向代理 123456789server &#123; listen 80; location /demo &#123; proxy_pass http://127.0.0.1:8081; &#125; location /demo1 &#123; proxy_pass http://127.0.0.1:8082; &#125;&#125; 负载均衡 nginx是一个非常高效的HTTP负载均衡器，将流量分配给多个应用服务器，并通过nginx提高web应用程序的性能、可伸缩性和可靠性。 nginx负载均衡使用的指令主要有upstream和proxy_pass，upstream块定义一个后端集群，proxy_pass用于location块中，表示对于所有符合要求的request交给某个集群处理。 常见的由以下几种实现负载均衡的方式。 轮询（round-robin）：默认方式 12345678910111213http &#123; upstream backend &#123; server srv1.example.com; server srv2.example.com; server srv3.example.com; &#125; server &#123; listen 80; location / &#123; proxy_pass http://backend; &#125; &#125;&#125; 加权轮询（weight-round-robin） 12345upstream backend &#123; server srv1.example.com weight=3; server srv2.example.com weight=2; server srv3.example.com;&#125; 最少连接（least-connected） 123456upstream backend &#123; least_conn; server srv1.example.com; server srv2.example.com; server srv3.example.com;&#125; ip-hash：每个请求按访问ip的hash结果分配，这样每个访客固定访问一个后端服务器，可以解决session的问题。 123456upstream backend &#123; ip_hash; server srv1.example.com; server srv2.example.com; server srv3.example.com;&#125; fair（第三方）: 按后端服务器的响应时间来分配请求，响应时间短的优先分配 123456upstream backend &#123; fair; server srv1.example.com; server srv2.example.com; server srv3.example.com;&#125;","categories":[{"name":"其他","slug":"other","permalink":"http://yoursite.com/categories/other/"}],"tags":[{"name":"nginx","slug":"nginx","permalink":"http://yoursite.com/tags/nginx/"}],"keywords":[{"name":"其他","slug":"other","permalink":"http://yoursite.com/categories/other/"}]},{"title":"springboot使用mybatis加载typealias的package问题","slug":"springboot2","date":"2018-09-30T10:02:32.000Z","updated":"2018-10-24T08:17:32.929Z","comments":true,"path":"web/springboot2.html","link":"","permalink":"http://yoursite.com/web/springboot2.html","excerpt":"springboot打成jar包后运行会造成mybatis设置的别名包找不到实体类的问题，这是由于mybatis默认使用DefaultVFS扫描包，在springboot中可以改成SpringBootVFS进行包扫描。具体见下面代码。","text":"springboot打成jar包后运行会造成mybatis设置的别名包找不到实体类的问题，这是由于mybatis默认使用DefaultVFS扫描包，在springboot中可以改成SpringBootVFS进行包扫描。具体见下面代码。 1234567891011@Bean public SqlSessionFactory db1SqlSessionFactory(DataSource dataSource) throws Exception &#123; SqlSessionFactoryBean sqlSessionFactoryBean = new SqlSessionFactoryBean(); sqlSessionFactoryBean.setDataSource(dataSource); //mybatis使用默认DefaultVFS扫描包会有问题，使用SpringBootVFS sqlSessionFactoryBean.setVfs(SpringBootVFS.class); PathMatchingResourcePatternResolver resolver = new PathMatchingResourcePatternResolver(); sqlSessionFactoryBean.setMapperLocations(resolver.getResources(&quot;classpath*:/mybatis/mapper/**.xml&quot;)); sqlSessionFactoryBean.setConfigLocation(new ClassPathResource(&quot;mybatis/mybatis-config.xml&quot;)); return sqlSessionFactoryBean.getObject(); &#125; 如果使用 mybatis autoconfigure生成的 SessionFactory可能就没有这个问题了。","categories":[{"name":"web","slug":"web","permalink":"http://yoursite.com/categories/web/"}],"tags":[{"name":"springboot","slug":"springboot","permalink":"http://yoursite.com/tags/springboot/"}],"keywords":[{"name":"web","slug":"web","permalink":"http://yoursite.com/categories/web/"}]},{"title":"JVM（5）：类加载机制","slug":"jvm-classloader","date":"2018-09-27T09:41:42.000Z","updated":"2018-10-24T08:17:04.862Z","comments":true,"path":"Java/jvm-classloader.html","link":"","permalink":"http://yoursite.com/Java/jvm-classloader.html","excerpt":"JVM把class文件加载的内存，并对数据进行校验、转换解析和初始化，最终形成JVM可以直接使用的Java类型的过程就是加载机制。 类加载生命周期 加载（Loading） 验证（Verifycation） 准备（Preparation） 解析（Resolution） 初始化（Initialization） 使用（Using） 卸载（Unloading）","text":"JVM把class文件加载的内存，并对数据进行校验、转换解析和初始化，最终形成JVM可以直接使用的Java类型的过程就是加载机制。 类加载生命周期 加载（Loading） 验证（Verifycation） 准备（Preparation） 解析（Resolution） 初始化（Initialization） 使用（Using） 卸载（Unloading） 其中验证、准备、解析这三个阶段统称为连接。加载、验证、准备、初始化、卸载这五个阶段顺序是确定的。 加载在加载阶段，虚拟机需要完成三件事情： 通过一个类的全限定名来获取定义此类的二进制字节流。 将这个字节流所代表的静态存储结构转化为方法区的运行时数据结构。 在内存中生成一个代表这个类的java.lang.class的对象，作为方法区这个类的各种数据的访问入口。 验证验证是连接阶段的第一步，这一阶段的目的是为了确保Class文件字节流中包含的信息符合当前虚拟机的要求，并且不回危害虚拟机的安全。验证阶段一共包含四步：文件格式验证、愿数据验证、字节码验证、符号引用验证。 准备准备阶段是为类变量分配内存并设置初始值的阶段，这些变量所使用的内存都在方法区中。public static int value=123；这个变量在准备阶段会初始化为0而不是123，因为这个时候尚未执行任何java方法，将value赋值为123是在putstatic指令被程序编译之后。public static final int value=123；而这个会在准备阶段之后value就被初始化为123。 解析解析阶段是将常量池中的符号引用替换成直接引用的过程。 初始化初始化阶段是真正开始执行类中定义的java代码。在准备阶段，类变量已经赋值了一次系统要求的初始值，而在初始化阶段，则根据具体实际的值去初始化。 类加载器 Bootstrap ClassLoader Extension ClassLoader Application ClassLoader Custom ClassLoader 双亲委派模型 双亲委派模型要求除了顶层的启动类加载器外，其余的类加载器都应该有自己的父类加载器。这些父子类加载器之间的关系不会以继承来实现，而是使用组合来实现。 双亲委派模型的工作过程是：如果一个类加载器收到了类加载的请求，它首先不会自己去尝试加载这个类，而是把这个请求委派给父类加载器去完成，每一个层次的类加载器都是如此，因此所有的加载请求最终都应该传送到顶层的启动类加载器中，只有当父加载器反馈自己无法完成这个加载请求（它的搜索范围中没有找到所需的类）时，子加载器才会尝试自己去加载。","categories":[{"name":"Java","slug":"Java","permalink":"http://yoursite.com/categories/Java/"}],"tags":[{"name":"JVM虚拟机","slug":"jvm","permalink":"http://yoursite.com/tags/jvm/"}],"keywords":[{"name":"Java","slug":"Java","permalink":"http://yoursite.com/categories/Java/"}]},{"title":"springboot线程池优雅关闭","slug":"springboot1","date":"2018-09-27T08:46:18.000Z","updated":"2018-10-24T08:17:20.736Z","comments":true,"path":"web/springboot1.html","link":"","permalink":"http://yoursite.com/web/springboot1.html","excerpt":"在我们停止springboot项目时，我们希望线程池中的任务能够继续执行完再完全停掉服务。一般有两种做法： 线程池配置参数在spring应用中，如果需要停止服务，而线程池没有优雅的关闭，就会造成线程池中的任务被强行停止，导致部分任务执行失败。我们只需要在配置线程池时增加两个参数即可： waitForTasksToCompleteOnShutdown awaitTerminationSeconds","text":"在我们停止springboot项目时，我们希望线程池中的任务能够继续执行完再完全停掉服务。一般有两种做法： 线程池配置参数在spring应用中，如果需要停止服务，而线程池没有优雅的关闭，就会造成线程池中的任务被强行停止，导致部分任务执行失败。我们只需要在配置线程池时增加两个参数即可： waitForTasksToCompleteOnShutdown awaitTerminationSeconds 具体代码如下： 12345678910111213@Beanpublic ThreadPoolTaskExecutor treadPool() &#123; ThreadPoolTaskExecutor executor = new ThreadPoolTaskExecutor(); executor.setCorePoolSize(10); executor.setMaxPoolSize(20); executor.setQueueCapacity(10); executor.setKeepAliveSeconds(60); executor.setWaitForTasksToCompleteOnShutdown(true); executor.setAwaitTerminationSeconds(30); executor.setRejectedExecutionHandler(new ThreadPoolExecutor.CallerRunsPolicy()); executor.initialize(); return executor;&#125; 使用ApplicationListener监听关闭事件12345678910111213141516171819202122232425262728@Componentpublic class MyContextClosedHandler implements ApplicationListener&lt;ContextClosedEvent&gt;&#123; @Autowired private ThreadPoolTaskExecutor executor; @Override public void onApplicationEvent(ContextClosedEvent event) &#123; shutdownAndAwaitTermination(executor.getThreadPoolExecutor()); &#125; private void shutdownAndAwaitTermination(ExecutorService pool) &#123; pool.shutdown(); // Disable new tasks from being submitted try &#123; // Wait a while for existing tasks to terminate if (!pool.awaitTermination(30, TimeUnit.SECONDS)) &#123; pool.shutdownNow(); // Cancel currently executing tasks // Wait a while for tasks to respond to being cancelled if (!pool.awaitTermination(30, TimeUnit.SECONDS)) System.err.println(&quot;Pool did not terminate&quot;); &#125; &#125; catch (InterruptedException ie) &#123; // (Re-)Cancel if current thread also interrupted pool.shutdownNow(); // Preserve interrupt status Thread.currentThread().interrupt(); &#125; &#125;&#125;","categories":[{"name":"web","slug":"web","permalink":"http://yoursite.com/categories/web/"}],"tags":[{"name":"springboot","slug":"springboot","permalink":"http://yoursite.com/tags/springboot/"}],"keywords":[{"name":"web","slug":"web","permalink":"http://yoursite.com/categories/web/"}]},{"title":"JVM（4）：虚拟机性能监控","slug":"jvm-tools","date":"2018-09-26T07:12:08.000Z","updated":"2018-11-08T09:42:23.032Z","comments":true,"path":"Java/jvm-tools.html","link":"","permalink":"http://yoursite.com/Java/jvm-tools.html","excerpt":"要进行虚拟机性能监控光有理论还不够，还需要实践。JDK为我们提供了一些命令行工具以及图形化洁面工具进行虚拟机性能监控实践。","text":"要进行虚拟机性能监控光有理论还不够，还需要实践。JDK为我们提供了一些命令行工具以及图形化洁面工具进行虚拟机性能监控实践。 命令行工具 jps：虚拟机进程状况工具用于列出正在执行的虚拟机进程。命令格式：jps ［options］［hostid］主要选项：-q 只输出LVMID，省略主类的名称 -l 输出主类的全名，如果执行的是jar包，输出jar的包路径 -m 输出虚拟机进程启动时传给主类main函数的参数 -v 输出虚拟机进程启动时的JVM参数jps可以通过RMI协议查询开启了RMI服务的远程虚拟机进程状态，hostid为RMI注册表中注册的主机名。 jstat：虚拟机统计信息监视工具用于监视虚拟机各种运行状态信息。命令格式： jstat -&lt;option> [-t] [-h &lt;lines>] &lt;vmid> [&lt;interval> [&lt;count>]] jstat -gc 2764 250 20 每250ms查看一次进程ID2764的gc情况，一共查看20次主要选项：-class 监视类装载、卸载、总空间以及所耗费时间 -gc 监视java堆gc状况，包括Eden区、两个Survivor区、、老年代、永久带等的容量、已用空间、GC时间合计等信息 jinfo：Java配置信息工具实时查看和调整虚拟机各项参数。命令格式：jinfo [ option ] vmid jmap：Java 内存映像工具用于生成堆转储快照，一般是headdump文件或者dump文件。命令格式：jmap [ option ] vmid主要选项：-dump 生成Java堆转储快照 -heap 显示Java堆详细信息。 jhat：虚拟机堆转储快照分析工具jhat与jmap搭配使用，来分析jmap生成的堆转储快照。 jstack：Java堆栈跟踪工具用于生成虚拟机当前的线程快照，一般是threaddump文件或者javacore文件。命令格式：jstack [ option ] vmid 图形化工具 JConsole：Java监视与管理控制台 VisualVM：多合一故障处理工具","categories":[{"name":"Java","slug":"Java","permalink":"http://yoursite.com/categories/Java/"}],"tags":[{"name":"JVM虚拟机","slug":"jvm","permalink":"http://yoursite.com/tags/jvm/"}],"keywords":[{"name":"Java","slug":"Java","permalink":"http://yoursite.com/categories/Java/"}]},{"title":"JVM（3）：垃圾收集GC","slug":"jvm-gc","date":"2018-09-26T06:09:37.000Z","updated":"2018-10-24T08:16:28.419Z","comments":true,"path":"Java/jvm-gc.html","link":"","permalink":"http://yoursite.com/Java/jvm-gc.html","excerpt":"Java内存结构中程序计数器、虚拟机栈、本地方法栈都是线程私有的，随着方法的结束或者线程的结束，内存会被回收。所以垃圾收集主要针对Java堆和方法区。 判断对象是否可以回收 引用计数法 每个对象有一个引用计数器，每当有一个地方引用，计数器就加1，当引用失效，计数器就减1，计数器为0的对象会被回收。引用计数不能解决循环引用的问题。","text":"Java内存结构中程序计数器、虚拟机栈、本地方法栈都是线程私有的，随着方法的结束或者线程的结束，内存会被回收。所以垃圾收集主要针对Java堆和方法区。 判断对象是否可以回收 引用计数法 每个对象有一个引用计数器，每当有一个地方引用，计数器就加1，当引用失效，计数器就减1，计数器为0的对象会被回收。引用计数不能解决循环引用的问题。 可达性分析法 通过一系列称为“GC ROOTS”的节点作为起点，开始向下搜索，搜素所走的路径称为引用链，当一个对象到GC ROOTS没有任何引用链相连的话，就说明该对象不可用，可以被回收。 可以作为GC ROOTS的对象包含以下几种：虚拟机栈（栈帧中的本地变量表）中引用的对象、方法区中类静态属性引用的对象、方法区中常量引用的对象、本地方法中JNI引用的对象。 四种引用类型： 强引用：指在程序代码之中普遍存在的，类似“Object obj=new Object（）”这类的引用，只要强引用还存在，垃圾收集器永远不会回收掉被引用的对象。 软引用：用来描述一些还有用但是非必需的对象。在系统内存不足时进行垃圾收集会对软引用进行回收。（SoftReference） 弱引用：也是用来描述非必需的对象，但是它的强度比软引用更弱。发生GC时，不管内存是否足够都会对其进行回收。（WeakReference） 虚引用：也称为幽灵引用或者幻影引用，它是最弱的一种引用关系。一个对象是否有虚引用的存在，完全不会对其生存时间构成影响，也无法通过虚引用来取得一个对象实例。为一个对象设置虚引用关联的唯一目的就是能在这个对象被收集器回收时收到一个系统通知。（PhantomReference） 垃圾收集算法 标记清除算法 复制算法 标记整理算法 分代收集算法 算法实现 枚举根结点 在可达性分析过程中为了防止对象的引用关系发生变化，所以在执行GC时需要停顿所有java执行线程（Stop The World）。 由于目前的主流Java虚拟机使用的都是准确式GC，所以当执行系统停顿下来后，并不需要一个不漏地检查完所有执行上下文和全局的引用位置，虚拟机应当是有办法直接得知哪些地方存放着对象引用。在HotSpot的实现中，是使用一组称为OopMap的数据结构来达到这个目的的，在类加载完成的时候，HotSpot就把对象内什么偏移量上是什么类型的数据计算出来，在JIT编译过程中，也会在特定的位置记录下栈和寄存器中哪些位置是引用。这样，GC在扫描时就可以直接得知这些信息了。 安全点 HotSpot并没有为每条指令都生成OopMap，只有在特定的位置记录这个信息，这些位置称为安全点（SaftPoint）。安全点的选定基本上是以程序“是否具有让程序长时间执行的特征”为标准进行选定的。长时间执行的最明显特征就是指令序列复用，例如方法调用、循环跳转、异常跳转等。 GC停顿有两种方案：抢先式中断（基本不用）和主动式中断。主动式中断是当需要中断线程时，设置一个中断标志，各个线程去轮询这个标志，当为真的就中断挂起。 安全区域 程序不执行的时候，也就是没有分配CPU的时候，典型的就是线程sleep或者blocked状态时，这个时候不能响应中断请求。JVM不太可能等到线程重新分配CPU然后走到安全点。这样就需要安全区域解决这个问题。 安全区域是指在一段区域内引用关系不会发生变化，在这中间任何一个地方GC都是安全的。我们可以把Safe Region看成是扩展的safe point。 垃圾收集器 Serial收集器：单线程收集器，client模式下默认的新生代收集器。 ParNew收集器：Serial收集器的多线程版本。server模式首选的新生代收集器。 Parallel Scavenge收集器：并行的多线程垃圾收集器，目标是达到一个可控制的吞吐量。提供了两个参数用于精确控制吞吐量，分别是控制最大垃圾收集停顿时间的-XX：MaxGCPauseMillis参数以及直接设置吞吐量大小的-XX：GCTimeRatio参数。无法与CMS配合。 Serial Old收集器 ：Serial收集器的老年代版本，client模式下默认的老年代收集器。 Parallel Old收集器：Parallel Scavenge收集器的老年代版本。 CMS收集器：基于标记清除算法。目标是降低GC停顿时间，一共有四个步骤：初始标记、并发标记、重新标记、并发清除。这之中最耗时的并发标记和并发清除可以和用户线程一起运行，所以可以看成是并行的垃圾收集器。三个缺点：对CPU资源敏感、无法处理浮动垃圾、标记清除算法会产生内存碎片。 G1收集器：特点：并行与并发、分代收集、可预测的停顿。使用G1收集器时，Java堆的内存布局就与其他收集器有很大差别，它将整个Java堆划分为多个大小相等的独立区域（Region），虽然还保留有新生代和老年代的概念，但新生代和老年代不再是物理隔离的了，它们都是一部分Region（不需要连续）的集合。G1跟踪各个Region里面的垃圾堆积的价值大小，在后台维护一个优先列表，每次根据允许的收集时间，优先回收价值最大的Region。四个步骤：初始标记、并发标记、最终标记、筛选回收。 内存分配回收策略 对象优先在Eden区分配 大对象直接进入老年代 长期存活对象进入老年代 动态对象年龄判定 空间分配担保","categories":[{"name":"Java","slug":"Java","permalink":"http://yoursite.com/categories/Java/"}],"tags":[{"name":"JVM虚拟机","slug":"jvm","permalink":"http://yoursite.com/tags/jvm/"}],"keywords":[{"name":"Java","slug":"Java","permalink":"http://yoursite.com/categories/Java/"}]},{"title":"JVM（2）：虚拟机对象探秘","slug":"jvm-object","date":"2018-09-25T06:00:36.000Z","updated":"2018-10-24T08:16:09.627Z","comments":true,"path":"Java/jvm-object.html","link":"","permalink":"http://yoursite.com/Java/jvm-object.html","excerpt":"对象的创建对象的创建一般有四种方式：new关键字、反射、clone、序列化。对象创建主要分三步： 检查类是否加载 虚拟机遇到一条new指令时，首先将去检查这个指令的参数是否能在常量池中定位到一个类的符号引用，并且检查这个符号引用代表的类是否已被加载、解析和初始化过。如果没有，那必须先执行相应的类加载过程。","text":"对象的创建对象的创建一般有四种方式：new关键字、反射、clone、序列化。对象创建主要分三步： 检查类是否加载 虚拟机遇到一条new指令时，首先将去检查这个指令的参数是否能在常量池中定位到一个类的符号引用，并且检查这个符号引用代表的类是否已被加载、解析和初始化过。如果没有，那必须先执行相应的类加载过程。 分配内存 主要有指针碰撞和空闲列表两种方式。指针碰撞是把内存指针向空闲空间移动与对象大小相等的距离来分配内存，这种主要适用于带有整理的垃圾收集器。空闲列表是维护一个列表记录哪些内存区域可以使用，在分配的时候从列表中找出一块分配，这种适用于不带整理功能的垃圾收集器。 分配过程中还要考虑多个线程同时分配内存出现并发的问题。这个一般有两种方案：一是使用CAS机制保证更新操作的原子性；二是使用本地线程分配缓冲（TLAB）。 对象设置 分配完内存之后需要进行对象设置，主要是把这个对象是哪个类的实例、对象的哈希码、对象的GC分代年龄、对象的锁信息等存放在对象的对象头里。 对象的内存布局 对象在内存中存储的布局可以分为3块区域：对象头（Header）、实例数据（Instance Data）和对齐填充（Padding）。 对象头分成两部分：第一部分用于存储对象自身的运行时数据，如对象的哈希码、GC分代年龄、锁状态标志等，官方称之为‘MarkWord’。另外一部分是类型指针，即对象指向它的类元数据的指针，虚拟机通过这个指针来确定这个对象是哪个类的实例。 实例数据部分是对象真正存储的有效信息，也是在程序代码中所定义的各种类型的字段内容。无论是从父类继承下来的，还是在子类中定义的，都需要记录起来。 第三部分对象填充不是必须的，仅仅是占位的作用，用来保证对象的大小是８字节的整数倍。 对象的访问定位对象的访问主要两种方式： 句柄访问 Java堆中会划出一块内存作为句柄池，reference中存储的就是对象的句柄地址，而句柄中包含了对象实例数据和类型数据各自的具体地址信息。好处是对象移动时只用改动句柄中的实例数据地址，不用改变reference。 直接指针访问 reference中存储的就是对象的地址。好处就是访问快，节省了一次指针定位的开销。hotspot使用直接指针访问。","categories":[{"name":"Java","slug":"Java","permalink":"http://yoursite.com/categories/Java/"}],"tags":[{"name":"JVM虚拟机","slug":"jvm","permalink":"http://yoursite.com/tags/jvm/"}],"keywords":[{"name":"Java","slug":"Java","permalink":"http://yoursite.com/categories/Java/"}]},{"title":"JVM（1）：内存结构","slug":"jvm-memory","date":"2018-09-25T03:38:43.000Z","updated":"2018-10-24T08:15:03.063Z","comments":true,"path":"Java/jvm-memory.html","link":"","permalink":"http://yoursite.com/Java/jvm-memory.html","excerpt":"程序计数器 程序计数器是内存结构中很小的一块，属于线程私有的。字节码解释器工作时就是通过改变这个计数器的值来选取下一条需要执行的指令，分支、循环、跳转、异常处理、线程恢复都要依赖这个计数器来实现。程序计数器是内存结构中唯一一个没有定义OOM的区域。","text":"程序计数器 程序计数器是内存结构中很小的一块，属于线程私有的。字节码解释器工作时就是通过改变这个计数器的值来选取下一条需要执行的指令，分支、循环、跳转、异常处理、线程恢复都要依赖这个计数器来实现。程序计数器是内存结构中唯一一个没有定义OOM的区域。 虚拟机栈 虚拟机栈也是线程私有的，主要用于存储局部变量表、操作数栈、动态链接、方法出口等信息。每一个方法的调用对应着一个栈帧在虚拟机中的入栈出栈过程。 虚拟机栈中定义了StackOverflowError和OutOfMemeryError。当线程请求的栈深度大于虚拟机允许的最大深度，就会抛出SOF异常。如果虚拟机栈可以动态扩展，扩展时无法申请足够的内存，就会抛出OOM异常。 本地方法栈 本地方法栈和虚拟机栈一样，只不过本地方法栈是为native方法服务的。hotspot虚拟机把本地方法栈和虚拟机栈合二为一了。 JAVA堆 Java堆时内存结构中最大的一块区域，它是线程共享的，主要用于存储对象的实例。Java堆可以细分为年轻代和老年代，年轻代又可以分成Eden区，From Survivor区和To Survivor区。Java堆是垃圾收集器管理的主要区域，现在的收集器基本都采用分代收集的策略。当内存不足时，Java堆中也会出现OOM异常。 方法区 方法区也是线程共享的，主要用于存储被加载的类信息、常量、静态变量、即时编译器编译后的代码等数据。方法区中也会出现OOM异常。 直接内存 直接内存并不是虚拟机内存结构中的一块，但是这部分内存也被频繁使用，也会导致ＯＯＭ异常。JDK1.4中引入的NIO就使用了直接内存。","categories":[{"name":"Java","slug":"Java","permalink":"http://yoursite.com/categories/Java/"}],"tags":[{"name":"JVM虚拟机","slug":"jvm","permalink":"http://yoursite.com/tags/jvm/"}],"keywords":[{"name":"Java","slug":"Java","permalink":"http://yoursite.com/categories/Java/"}]},{"title":"Java代码优化","slug":"code-optimization","date":"2018-08-22T09:17:31.000Z","updated":"2018-10-24T08:18:30.450Z","comments":true,"path":"Java/code-optimization.html","link":"","permalink":"http://yoursite.com/Java/code-optimization.html","excerpt":"代码优化目标：减少代码体积，提高代码的运行效率","text":"代码优化目标：减少代码体积，提高代码的运行效率 代码优化具体细节 尽量指定类、方法的final修饰符：如果一个类是final的，则它的所有方法也是final的，java编译器会寻找机会内内联的所有final方法，可以提高50%的性能。 尽量重用对象：特别是String对象。Java虚拟机创建对象需要花费时间和空间，后期还要进行垃圾回收。 尽可能使用局部变量：局部变量存储于栈中，速度较快，而且随着方法的结束会消失。 及时关闭流和连接等：对于IO流以及数据库连接、线程池连接，在finally 中一定要将其关闭。 尽量使用懒加载策略：在使用时创建（单例模式最好使用懒汉模式）。 不要在循环中使用try…catch…：在循环外使用。 乘法和除法使用移位操作：&gt;&gt;1表示除以2，&lt;&lt;1表示乘以2。 当有大量数据复制时，使用System.arrayCopy()命令。 循环内不要不断的创建对象。","categories":[{"name":"Java","slug":"Java","permalink":"http://yoursite.com/categories/Java/"}],"tags":[{"name":"java基础","slug":"java-base","permalink":"http://yoursite.com/tags/java-base/"}],"keywords":[{"name":"Java","slug":"Java","permalink":"http://yoursite.com/categories/Java/"}]}]}